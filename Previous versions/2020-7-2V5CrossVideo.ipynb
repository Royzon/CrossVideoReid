{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.nn.Module.dump_patches = True\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from yacs.config import CfgNode as CN\n",
    "import sys\n",
    "import torch\n",
    "import copy\n",
    "import queue\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import threading\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import LoadStreams,LoadImages\n",
    "from utils.utils import torch_utils,google_utils,non_max_suppression,Path,scale_coords,plot_one_box,platform,xyxy2xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self,bbox):\n",
    "        (x,y,w,h)=bbox\n",
    "        self.x,self.y=0,0\n",
    "        self.last_measurement = self.current_measurement = np.array((2,1),np.float32)\n",
    "        np_bbox=np.asarray([x,y]).astype(np.float32)\n",
    "        self.last_predicition = self.current_prediction = np_bbox.resize((2,1))#np.zeros((2,1),np.float32)\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        #设置测量矩阵\n",
    "        self.kalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)\n",
    "        #设置转移矩阵\n",
    "        self.kalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)\n",
    "        #设置过程噪声协方差矩阵\n",
    "        self.kalman.processNoiseCov = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32)*0.003\n",
    "    def move(self,x,y):\n",
    "        #初始化\n",
    "        self.last_measurement = self.current_measurement\n",
    "        self.last_prediction = self.current_prediction\n",
    "        #传递当前测量坐标值\n",
    "        self.current_measurement = np.array([[np.float32(x)],[np.float32(y)]])\n",
    "        #用来修正卡尔曼滤波的预测结果\n",
    "        self.kalman.correct(self.current_measurement)\n",
    "        # 调用kalman这个类的predict方法得到状态的预测值矩阵，用来估算目标位置\n",
    "        current_prediction = self.kalman.predict()\n",
    "        #上一次测量值\n",
    "        lmx,lmy = self.last_measurement[0],self.last_measurement[1]\n",
    "        #当前测量值\n",
    "        cmx,cmy = self.current_measurement[0],self.current_measurement[1]\n",
    "        #上一次预测值\n",
    "        #lpx,lpy = last_prediction[0],last_prediction[1]\n",
    "        #当前预测值\n",
    "        cpx,cpy = current_prediction[0],current_prediction[1]\n",
    "        return cpx,cpy\n",
    "    def update(self,bbox):\n",
    "        (x,y,w,h)=bbox\n",
    "        self.x,self.y = self.move(x,y)\n",
    "    def get(self):\n",
    "        return self.x,self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "# 任务分配类\n",
    "class TaskAssignment(object):         \n",
    "    # 全排列方法\n",
    "    def all_permutation(self, task_matrix):\n",
    "        number_of_choice = len(task_matrix)\n",
    "        solutions = []\n",
    "        values = []\n",
    "        for each_solution in itertools.permutations(range(number_of_choice)):\n",
    "            each_solution = list(each_solution)\n",
    "            solution = []\n",
    "            value = 0\n",
    "            for i in range(len(task_matrix)):\n",
    "                value += task_matrix[i][each_solution[i]]\n",
    "                solution.append(task_matrix[i][each_solution[i]])\n",
    "            values.append(value)\n",
    "            solutions.append(solution)\n",
    "        min_cost = np.min(values)\n",
    "        best_solution = solutions[values.index(min_cost)]\n",
    "        return best_solution\n",
    "\n",
    "    # 匈牙利方法\n",
    "    def Hungary(self, task_matrix):\n",
    "        b = task_matrix.copy()\n",
    "        # 行和列减0\n",
    "        for i in range(len(b)):\n",
    "            row_min = np.min(b[i])\n",
    "            for j in range(len(b[i])):\n",
    "                b[i][j] -= row_min\n",
    "        for i in range(len(b[0])):\n",
    "            col_min = np.min(b[:, i])\n",
    "            for j in range(len(b)):\n",
    "                b[j][i] -= col_min\n",
    "        line_count = 0\n",
    "        # 线数目小于矩阵长度时，进行循环\n",
    "        while (line_count < len(b)):\n",
    "            line_count = 0\n",
    "            row_zero_count = []\n",
    "            col_zero_count = []\n",
    "            for i in range(len(b)):\n",
    "                row_zero_count.append(np.sum(b[i] == 0))\n",
    "            for i in range(len(b[0])):\n",
    "                col_zero_count.append((np.sum(b[:, i] == 0)))\n",
    "            # 划线的顺序（分行或列）\n",
    "            line_order = []\n",
    "            row_or_col = []\n",
    "            for i in range(len(b[0]), 0, -1):\n",
    "                while (i in row_zero_count):\n",
    "                    line_order.append(row_zero_count.index(i))\n",
    "                    row_or_col.append(0)\n",
    "                    row_zero_count[row_zero_count.index(i)] = 0\n",
    "                while (i in col_zero_count):\n",
    "                    line_order.append(col_zero_count.index(i))\n",
    "                    row_or_col.append(1)\n",
    "                    col_zero_count[col_zero_count.index(i)] = 0\n",
    "            # 画线覆盖0，并得到行减最小值，列加最小值后的矩阵\n",
    "            delete_count_of_row = []\n",
    "            delete_count_of_rol = []\n",
    "            row_and_col = [i for i in range(len(b))]\n",
    "            for i in range(len(line_order)):\n",
    "                if row_or_col[i] == 0:\n",
    "                    delete_count_of_row.append(line_order[i])\n",
    "                else:\n",
    "                    delete_count_of_rol.append(line_order[i])\n",
    "                c = np.delete(b, delete_count_of_row, axis=0)\n",
    "                c = np.delete(c, delete_count_of_rol, axis=1)\n",
    "                line_count = len(delete_count_of_row) + len(delete_count_of_rol)\n",
    "                # 线数目等于矩阵长度时，跳出\n",
    "                if line_count == len(b):\n",
    "                    break\n",
    "                # 判断是否画线覆盖所有0，若覆盖，进行加减操作\n",
    "                if 0 not in c:\n",
    "                    row_sub = list(set(row_and_col) - set(delete_count_of_row))\n",
    "                    min_value = np.min(c)\n",
    "                    for i in row_sub:\n",
    "                        b[i] = b[i] - min_value\n",
    "                    for i in delete_count_of_rol:\n",
    "                        b[:, i] = b[:, i] + min_value\n",
    "                    break\n",
    "        row_ind, col_ind = linear_sum_assignment(b)\n",
    "        #min_cost = task_matrix[row_ind, col_ind].sum()\n",
    "        best_solution = list(task_matrix[row_ind, col_ind])\n",
    "        return  best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet101\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from extractor.feature_extractor import Extractor\n",
    "extractor = Extractor(\"./extractor/checkpoint/ckpt.t7\", use_cuda=True)\n",
    "class PCA:\n",
    "    def __init__(self,dir_path='./test_colors/train',NUM_EIGEN_FACES = 64):\n",
    "        self.save={'000':{'center':[],'bbox':[],'lib':[],'frame':0,'passage':False,'kalman':[],'cross':False,'overlap':False}}\n",
    "        self.NUM_EIGEN_FACES = NUM_EIGEN_FACES\n",
    "        self.images = self.readImages(dir_path)\n",
    "        self.data = self.createDataMatrix(self.images)\n",
    "        #self.data = torch.from_numpy(self.data).cuda()\n",
    "        #torch.pca_lowrank(A, q=None, center=True, niter=2)\n",
    "        #self.mean, self.eigenVectors = torch.pca_lowrank(self.data, q=None, center=True, niter= self.NUM_EIGEN_FACES)\n",
    "        #self.means, self.eigenVectorses=[],[]\n",
    "        #print('the alldata %d'%len(self.eigenVectors))\n",
    "        #self.init_pca(basepath)\n",
    "        #self.notebook={'000':{'frame':[],'lib':[]}}\n",
    "        self.frame=0\n",
    "        self.color_old=0\n",
    "        self.flag_frame=[]\n",
    "        self.flag_line=[]\n",
    "        self.dth = 0.05#相似度距离0.5~0.6  / 欧氏距离25\n",
    "        self.Forget=1  #状态切换帧\n",
    "        self.testsave={}\n",
    "        self.models_mean = './models/mean.npy'\n",
    "        self.models_eigenVector = './models/eigenVector.npy'\n",
    "        #self.meta = threading.Lock()\n",
    "        if os.path.exists(self.models_mean)==False and os.path.exists(self.models_eigenVector)==False:\n",
    "            self.mean, self.eigenVectors = cv2.PCACompute(self.data, mean=None, maxComponents=self.NUM_EIGEN_FACES)\n",
    "            np.save(self.models_mean,self.mean)\n",
    "            np.save(self.models_eigenVector,self.eigenVectors)\n",
    "        else:\n",
    "            self.mean=np.load(self.models_mean)\n",
    "            self.eigenVectors=np.load(self.models_eigenVector)\n",
    "        #卡尔曼滤波\n",
    "        self.kalman=[]\n",
    "        self.cross_id=[]\n",
    "        #匈牙利算法\n",
    "        self.task = TaskAssignment()\n",
    "    def createDataMatrix(self,images):\n",
    "        numImages = len(images)\n",
    "        sz = images[0].shape\n",
    "        data = np.zeros((numImages, sz[0] * sz[1] * sz[2]), dtype=np.float32)\n",
    "        for i in range(0, numImages):\n",
    "            image = images[i].flatten()\n",
    "            data[i,:] = image\n",
    "        #print(\"createData ok\")\n",
    "        return data\n",
    "\n",
    "    def readImages(self,path):\n",
    "        print(\"Reading images from \" + path, end=\"...\")\n",
    "        # Create array of array of images.\n",
    "        images = []\n",
    "        # List all files in the directory and read points from text files one by one\n",
    "        for name in glob.glob(path+'/*'):\n",
    "            for imagePath in glob.glob(name+'/*.jpg'):\n",
    "                    # Add to array of images\n",
    "                    im = cv2.imread(imagePath)\n",
    "                    im = cv2.resize(im,(64,128))\n",
    "                    if im is None :\n",
    "                        print(\"image:{} not read properly\".format(imagePath))\n",
    "                    else :\n",
    "                        # Convert image to floating point\n",
    "                        im = np.float32(im)/255.0\n",
    "                        # Add image to list\n",
    "                        images.append(im)\n",
    "                        # Flip image \n",
    "                        imFlip = cv2.flip(im, 1);\n",
    "                        # Append flipped image\n",
    "                        #images.append(imFlip)\n",
    "        numImages = int(len(images))\n",
    "        # Exit if no image found\n",
    "        if numImages == 0 :\n",
    "            print(\"No images found\")\n",
    "            sys.exit(0)\n",
    "        print(str(numImages) + \" files read.\")\n",
    "        return images\n",
    "#*\n",
    "#*\n",
    "#*      算法集合\n",
    "#*\n",
    "#*\n",
    "    def compute_cos(self,x,y):\n",
    "        x_,y_=x.flatten(),y.flatten()\n",
    "        dist =1- abs(np.dot(x_,y_)/(np.linalg.norm(x_)*np.linalg.norm(y_)))      \n",
    "        return abs(dist)\n",
    "    \n",
    "    def compute_dis(self,x,y):\n",
    "         return np.linalg.norm( x - y )\n",
    "    \n",
    "    def compute_Maha(self,x,y):\n",
    "        X=np.vstack([x,y])\n",
    "        XT=X.T\n",
    "        S=np.cov(X)   #两个维度之间协方差矩阵\n",
    "        SI = np.linalg.inv(S) #协方差矩阵的逆矩阵\n",
    "        #马氏距离计算两个样本之间的距离，此处共有10个样本，两两组合，共有45个距离。\n",
    "        n=XT.shape[0]\n",
    "        d1=[]\n",
    "        for i in range(0,n):\n",
    "            for j in range(i+1,n):\n",
    "                delta=XT[i]-XT[j]\n",
    "                d=np.sqrt(np.dot(np.dot(delta,SI),delta.T))\n",
    "                d1.append(d)\n",
    "        return d1\n",
    "    \n",
    "    \n",
    "     #计算两点近距离公式 xyxy\n",
    "    def distEclud(self,veA,vecA,veB,vecB):\n",
    "        lossA=veB-veA\n",
    "        lossB=vecB-vecA\n",
    "        return math.sqrt(pow(lossA,2)+pow(lossB,2))\n",
    "#*\n",
    "#*\n",
    "#*      功能函数\n",
    "#*\n",
    "#*\n",
    "    def clear_id(self):\n",
    "        self.save={'000':{'center':[],'bbox':[],'lib':[],'frame':0,'passage':False,'kalman':[],'cross':False,'overlap':False}}  \n",
    "        \n",
    "    def kalman_distance(self,bbox,name='cross'):\n",
    "        (x,y,w,h)=bbox\n",
    "        list_kalman_distance,list_kalman_id=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k!='000'and v['passage']==True:\n",
    "                list_kalman_distance.append(round(self.distEclud(x,y,v['kalman'][0],v['kalman'][1]),3))\n",
    "                list_kalman_id.append(k)\n",
    "        return list_kalman_distance,list_kalman_id\n",
    "\n",
    "    def kalman_bbox_update(self,id_,bbox):\n",
    "        self.save[id_]['bbox']=bbox\n",
    "        kalman_id=int(id_)-1\n",
    "        self.kalman[kalman_id].update(bbox)\n",
    "        x,y=self.kalman[kalman_id].get()\n",
    "        self.save[id_]['kalman']=[x,y]\n",
    "        return (int(x),int(y))\n",
    "            \n",
    "    #轨迹跟踪被覆盖的bbox 后得到被覆盖的bbox的预测          \n",
    "    def kalman_overlap_get(self,id_,bbox):\n",
    "        (x,y,w,h)=bbox\n",
    "        bboxs=[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k!=id_ and k!='000' and v['cross']==True:\n",
    "                bbox_lib = v['bbox']\n",
    "                (xa,ya,wa,ha)=bbox_lib\n",
    "                dis_ = self.distEclud(x,y,xa,ya)\n",
    "                if (dis_/(w+wa))<0.5:\n",
    "                    kalman_id=int(k)-1\n",
    "                    for i in range(3):\n",
    "                        x,y=self.kalman[kalman_id].get()\n",
    "                        self.kalman[kalman_id].update([x,y,0,0])\n",
    "                        x,y=self.kalman[kalman_id].get()\n",
    "                        self.save[k]['kalman']=[x,y]\n",
    "                    \n",
    "                bboxs.append([x,y,wa,ha])   \n",
    "        return bboxs\n",
    "\n",
    "    def kalman_reid(self,bbox):\n",
    "        (x,y,w,h)=bbox\n",
    "        color_=0\n",
    "        list_kalman_distance,list_kalman_id=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k!='000' and v['passage']==True:\n",
    "                if v['overlap']==True:\n",
    "                    bbox_ = v['bbox']\n",
    "                    (xa,ya,wa,ha)=bbox_\n",
    "                    dis_ = self.distEclud(x,y,xa,ya)\n",
    "                    if (dis_/(w+wa))<0.5:\n",
    "                        list_kalman_distance.append(self.distEclud(x,y,v['kalman'][0],v['kalman'][1]))\n",
    "                        list_kalman_id.append(k)\n",
    "                elif v['cross']==True:\n",
    "                    bbox_ = v['bbox']\n",
    "                    (xa,ya,wa,ha)=bbox_\n",
    "                    dis_ = self.distEclud(x,y,xa,ya)\n",
    "                    if (dis_/(w+wa))<0.5:\n",
    "                        list_kalman_distance.append(self.distEclud(x,y,v['kalman'][0],v['kalman'][1]))\n",
    "                        list_kalman_id.append(k)\n",
    "        if len(list_kalman_id)>0:\n",
    "            id_ = list_kalman_id[list_kalman_distance.index(min(list_kalman_distance))]\n",
    "            color_=int(len(self.save[id_]['lib'])/2)\n",
    "            #for cross_id in list_kalman_id:\n",
    "            #    if cross_id!=id_:\n",
    "            #        self.cross_off(cross_id)\n",
    "        else:\n",
    "            id_ = ' ';color_=0\n",
    "        return id_,color_\n",
    "\n",
    "    def manage_lib(self,frame):\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k=='000':#or v['passage']==False:\n",
    "                continue\n",
    "            lib = v['lib']\n",
    "            frame_lib=v['frame']\n",
    "            if frame-frame_lib>self.Forget:\n",
    "                self.save[k]['frame']=frame\n",
    "                #self.save[k]['lib'].pop(0)\n",
    "                #if len(lib)<10:\n",
    "                    #self.dele_lib_id(k)\n",
    "                #if  k not in self.save:\n",
    "                #    continue\n",
    "                if self.save[k]['passage']==True:\n",
    "                    center =self.save[k]['center']\n",
    "                    for lib_ in self.save[k]['lib']:\n",
    "                        center=center*0.99+lib_*0.01\n",
    "                    #self.save[k]['lib'].pop(0)\n",
    "                    self.passage_off(k,center)\n",
    "                    #self.flag_frame=[]\n",
    "                    \n",
    "    def paassag_on(self,feature,bbox,frame,id_):\n",
    "        self.save[id_]['center']=feature\n",
    "        self.save[id_]['bbox']=bbox\n",
    "        self.save[id_]['lib'].append(feature)\n",
    "        self.save[id_]['frame']=frame\n",
    "        self.save[id_]['passage']=True\n",
    "        print('%s passage is True'%id_)\n",
    "        \n",
    "    def passage_off(self,id_,center):\n",
    "        self.save[id_]['center']=center\n",
    "        self.save[id_]['passage']=False\n",
    "        print('%s passage is False'%id_)\n",
    "    \n",
    "    def overlap_on(self,id_):\n",
    "        self.save[id_]['overlap']=True\n",
    "        #print('%s overlap is True'%id_)\n",
    "        \n",
    "    def overlap_off(self,id_):\n",
    "        self.save[id_]['overlap']=False\n",
    "        #print('%s overlap is False'%id_)\n",
    "        \n",
    "    def cross_on(self,id_):\n",
    "        self.save[id_]['cross']=True\n",
    "        #print('%s cross is True'%id_)\n",
    "        \n",
    "    def cross_off(self,id_):\n",
    "        self.save[id_]['cross']=False\n",
    "        #print('%s cross is False'%id_)\n",
    "        \n",
    "    def update_frame(self,id_,frame):\n",
    "        self.save[id_]['frame']=frame\n",
    "        \n",
    "    def dele_lib_id(self,id_):\n",
    "        del self.save[id_]\n",
    "        print('the id %s Remove'%id_)\n",
    "        \n",
    "    def add_lib(self,feature,bbox,frame,passage=False):\n",
    "        save={'center':[],'bbox':[],'lib':[],'frame':0,'passage':False,'kalman':[],'cross':False,'overlap':False}\n",
    "        for n in  self.save.keys():\n",
    "            id_=n\n",
    "        self.kalman.append(KalmanFilter(bbox))\n",
    "        self.kalman[(int(id_))].update(bbox)\n",
    "        x,y=self.kalman[(int(id_))].get()\n",
    "        \n",
    "        save['kalman']=[x,y]\n",
    "        self.id_new=('%03d'%(int(id_)+1))\n",
    "        save['center']=feature\n",
    "        save['bbox']=bbox\n",
    "        save['lib']=[feature]\n",
    "        save['frame']=frame\n",
    "        save['passage']=passage\n",
    "        self.save[self.id_new]=save\n",
    "        print('find id %s'%self.id_new)\n",
    "        return self.id_new\n",
    "    \n",
    "    def add_id(self,feature,bbox,frame):   \n",
    "        #print(len(self.save))\n",
    "        if frame!=0 and len(self.save)!=1:\n",
    "            id_ = self.check_lib_passage(feature)\n",
    "            #self.id_new = self.check_lib(feature)\n",
    "            if id_ == ' ':\n",
    "                self.flag_line=[]\n",
    "                if self.id_new in self.save:\n",
    "                    if frame-self.save[self.id_new]['frame']>1:\n",
    "                        self.flag_frame=[]\n",
    "                else:\n",
    "                    self.flag_frame=[]\n",
    "                if len(self.flag_frame)==0:\n",
    "                    self.id_new = self.add_lib(feature,bbox,frame)\n",
    "                self.flag_frame.append(frame)\n",
    "                self.save[self.id_new]['frame']=frame\n",
    "                #self.update_frame\n",
    "                if len(self.flag_frame)>=5:\n",
    "                    if np.mean(self.flag_frame)==self.flag_frame[2]:\n",
    "                        self.paassag_on(feature,bbox,frame,self.id_new)\n",
    "                        self.flag_frame=[]\n",
    "                    else:\n",
    "                        self.dele_lib_id(self.id_new)\n",
    "                        self.flag_frame=[]\n",
    "            else:\n",
    "                #if frame - self.save[id_]['frame'] >3:\n",
    "                self.flag_frame=[]\n",
    "                self.flag_line.append(frame)\n",
    "                self.save[id_]['frame']=frame\n",
    "                #self.update_frame\n",
    "                if len(self.flag_line)>=3:\n",
    "                    if np.mean(self.flag_line)==self.flag_line[1]:\n",
    "                        self.paassag_on(feature,bbox,frame,id_)\n",
    "                        self.flag_line=[]\n",
    "                    else:\n",
    "                        self.flag_line=[]\n",
    "                return id_\n",
    "        else:\n",
    "            self.id_new = self.add_lib(feature,bbox,frame,passage=True)\n",
    "        return self.id_new\n",
    "#*\n",
    "#*      检测集合\n",
    "#*                        \n",
    "    def check_frame_id(self,id_,feature,frame):\n",
    "        list_dis=[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k==id_:\n",
    "                if frame-(v['frame'])>=10:\n",
    "                        if k==id_:\n",
    "                            for lib_ in v['lib']:\n",
    "                                list_dis.append(self.compute_cos(lib_,feature))\n",
    "                            if min(list_dis)<self.dth:\n",
    "                                return True\n",
    "                            else:\n",
    "                                return False\n",
    "                else:\n",
    "                    return True\n",
    "        return False\n",
    "    #检查除id_me外是否与数据库里的bbox重叠\n",
    "    def check_bboxs(self,bbox_list,bbox):    \n",
    "        (xc, yc, wc, hc) =bbox\n",
    "        list_id,list_x=[],[]\n",
    "        ret=True\n",
    "        if len(bbox_list)!=1:\n",
    "            for i in range(len(bbox_list)):\n",
    "                for j in range(i+1,len(bbox_list)):\n",
    "                    (xa, ya, wa, ha) = bbox_list[i]\n",
    "                    (xb, yb, wb, hb) = bbox_list[j] \n",
    "                    distance = self.distEclud(xa,ya,xb,yb)\n",
    "                    if (distance/(wa+wb))>=0.5:\n",
    "                        continue\n",
    "                    if (distance/(wa+wb))<0.5:\n",
    "                        if xc==xa or xc==xb:#是不是因为重叠导致的\n",
    "                            ret=False\n",
    "        return ret\n",
    "    def check_bboxs_cross(self,bboxs,bbox):    \n",
    "        ret=True\n",
    "        flag=False#无交叉但有重叠的标志\n",
    "        (xa, ya, wa, ha)=bbox\n",
    "        cross_bboxs=copy.copy(bboxs)\n",
    "        cross_bboxs.remove(bbox)\n",
    "        for bbox_ in cross_bboxs:\n",
    "            (xb, yb, wb, hb) = bbox_ \n",
    "            distance = self.distEclud(xa,ya,xb,yb)\n",
    "            if (distance/(wa+wb))>=0.5:\n",
    "                continue\n",
    "            if (distance/(wa+wb))<0.5:\n",
    "                ret=False\n",
    "        if self.check_bboxs_overlap(bbox)==False:\n",
    "            if ret==True:\n",
    "                flag=True\n",
    "                ret=False   \n",
    "        return ret ,flag\n",
    "    def check_bboxs_overlap(self,bbox):\n",
    "        ret=True\n",
    "        flag_num=0\n",
    "        (xc, yc, wc, hc)=bbox\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k!='000'and v['passage']==True:\n",
    "                (xl, yl, wl, hl) = v['bbox']\n",
    "                distance = self.distEclud(xc,yc,xl,yl)\n",
    "                if (distance/(wc+wl))>=0.5:\n",
    "                    continue\n",
    "                if (distance/(wc+wl))<0.5:  \n",
    "                    flag_num+=1\n",
    "        if flag_num>1:\n",
    "            ret=False\n",
    "        return ret\n",
    "    def check_lib_add(self,featureVector,min_distance_id,bbox):\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if  k==min_distance_id:\n",
    "                n=v['center']\n",
    "                lib = v['lib']\n",
    "                #跟新kalman 轨迹预测\n",
    "                kalman_id=int(k)-1\n",
    "                self.kalman[kalman_id].update(bbox)\n",
    "                x,y =self.kalman[kalman_id].get()\n",
    "                self.save[k]['kalman']=[x,y]\n",
    "                self.cross_off(k)\n",
    "                self.overlap_off(k)\n",
    "                for lib_ in lib:\n",
    "                    list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "                if len(self.save[min_distance_id]['lib'])>254:\n",
    "                    num = list_dis.index(min(list_dis))\n",
    "                    self.save[min_distance_id]['lib'].pop(num)\n",
    "                    #self.save[min_distance_id]['lib'].pop(0)\n",
    "                if len(list_dis)>0 and np.mean(list_dis)>self.dth:\n",
    "                    self.save[min_distance_id]['lib'].append(featureVector)\n",
    "                    print('\\r%s lib len :%d'%(min_distance_id,len(lib)),end='')\n",
    "                break\n",
    "        return int(len(lib))\n",
    "    #检查就绪的\n",
    "    def check_lib(self,featureVector):\n",
    "        list_id,list_mean=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if k=='000'or v['passage']==False :\n",
    "                continue\n",
    "            lib = v['lib']\n",
    "            for lib_ in lib:\n",
    "                list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "            list_id.append(k)\n",
    "            list_mean.append(min(list_dis)) \n",
    "        if len(list_mean)>0 and min(list_mean) <self.dth:\n",
    "            return list_id[list_mean.index(min(list_mean))] \n",
    "        else:\n",
    "            #print( min(list_mean))\n",
    "            return ' '   \n",
    "    #检查未就绪\n",
    "    def check_lib_passage(self,featureVector):\n",
    "        list_id,list_mean=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if k!='000' and v['passage']==False:\n",
    "                lib = v['lib']\n",
    "                for lib_ in lib:\n",
    "                    list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "                list_id.append(k)\n",
    "                list_mean.append(min(list_dis)) \n",
    "        print(list_mean)\n",
    "        if len(list_mean)>0 and min(list_mean) <self.dth:\n",
    "            return list_id[list_mean.index(min(list_mean))] \n",
    "        else:\n",
    "            #print( min(list_mean))\n",
    "            return ' '    \n",
    "   \n",
    "    #def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "    def cross_video_pca(self,user_bbox_list,confidences,im):\n",
    "        #\n",
    "        # * self.notebook 记录发现新的图片的W\n",
    "        # * 保存数据的格式 self.save={'id':{'center':w,'LIB':[w1..wn]}}\n",
    "        #\n",
    "        color=[]\n",
    "        identities=[]\n",
    "        dths=[]\n",
    "        kalman_overlap_bbox=[]\n",
    "        cross_id =[]\n",
    "        overlap_id=[]\n",
    "        guss_bbox=[]\n",
    "        #维护LIB\n",
    "        self.manage_lib(self.frame)\n",
    "        if user_bbox_list!=[]:\n",
    "            list_id,list_feature,list_distance,list_center=[],[],[],[]\n",
    "            list_kalman_distance,list_kalman_ids,list_kalman_c,list_kalman_bbox,list_kalman_feature,list_kalman_flag=[],[],[],[],[],[]\n",
    "            bbox_list=copy.copy(user_bbox_list)\n",
    "            for bbox,c in zip(user_bbox_list,confidences):\n",
    "                (x, y, w, h) = bbox\n",
    "                #print(bbox)\n",
    "                (x1, y1, x2, y2)=abs(int(x-w/2)), abs(int(y-h/2)), int(x+w/2), int(y+h/2)\n",
    "                #print((x1, y1, x2, y2))\n",
    "                im_=im[y1:y2,x1:x2]\n",
    "                im_ = cv2.resize(im_,(64,128))\n",
    "                featureVector = self.compute_feature(im_)\n",
    "                #交叉判断\n",
    "                #print(bbox_list)\n",
    "                ret_bbox_cross,flag = self.check_bboxs_cross(user_bbox_list,bbox)\n",
    "                #print(ret_bbox_cross,flag)\n",
    "                #ret_bbox_overlap=self.check_bboxs_overlap(bbox_list,bbox)\n",
    "                #有交叉则使用kalman跟踪\n",
    "                if ret_bbox_cross ==False :#or ret_bbox_overlap==False:\n",
    "                    #只是交叉的时候，使用匈牙利算法\n",
    "                    bbox_list.remove(bbox)\n",
    "                    if flag==False:\n",
    "                        list_kalman_distances,list_kalaman_ids = self.kalman_distance(bbox)\n",
    "                        list_kalman_distance.append(list_kalman_distances)\n",
    "                        list_kalman_ids.append(list_kalaman_ids)\n",
    "                        list_kalman_c.append(c)\n",
    "                        list_kalman_bbox.append(bbox)\n",
    "                        list_kalman_feature.append(featureVector)\n",
    "                        list_kalman_flag.append(flag)\n",
    "                    else:\n",
    "                        #重叠的时候参考交叉的id情况直接赋予id\n",
    "                        id_,color_ = self.kalman_reid(bbox)\n",
    "                        if id_!=' ':\n",
    "                            #self.cross_on(id_)\n",
    "                            self.overlap_on(id_)\n",
    "                            guss_bbox.append(self.kalman_bbox_update(id_,bbox))\n",
    "                            kalman_overlap_bbox = self.kalman_overlap_get(id_,bbox)\n",
    "                            identities.append(id_)\n",
    "                            dths.append(c)\n",
    "                            color.append(color_)\n",
    "                            overlap_id.append(id_)\n",
    "                            \n",
    "                #PCA算法\n",
    "                else:\n",
    "                    distance=0\n",
    "                #所有图片与LIB中passage为TRUE的计算距离\n",
    "                    list_distance_buffer,list_id_buffer,list_feature_buffer,list_center_buffer=[],[],[],[]\n",
    "                    for k,v in list(self.save.items()):\n",
    "                        if k=='000':\n",
    "                            continue\n",
    "                        if v['passage']==True:\n",
    "                            n=v['center']\n",
    "                            #kalman_xy=v['kalman']\n",
    "                            #distance_kalman = self.distEclud(kalman_xy[0],kalman_xy[1],bbox[0],bbox[1])\n",
    "                            #print(distance_kalman)\n",
    "                            distance = self.compute_cos(n,featureVector)\n",
    "                            #distance =+distance_feature*0.95+distance_kalman*0.005\n",
    "                            list_distance_buffer.append(distance)\n",
    "                            list_id_buffer.append(k)\n",
    "                            list_feature_buffer.append(featureVector)\n",
    "                            list_center_buffer.append(n) \n",
    "\n",
    "                    if len(list_distance_buffer)>0 :#and min(list_distance_buffer)<self.dth:\n",
    "                        list_distance.append(list_distance_buffer)\n",
    "                        list_id.append(list_id_buffer)\n",
    "                        list_feature.append(list_feature_buffer)\n",
    "                        list_center.append(list_center_buffer)\n",
    "                    else:\n",
    "                        #ret = self.check_bboxs(bbox_list,bbox) \n",
    "                        #if ret ==True:\n",
    "                        id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                        identities.append(id_)\n",
    "                        dths.append(c)\n",
    "                        color.append(0) \n",
    "            \n",
    "            #匈牙利算法\n",
    "            #Kalman \n",
    "            if list_kalman_distance!=[]:\n",
    "                list_kalman_id_=[]\n",
    "                if len(list_kalman_distance)>len(list_kalman_distance[0]):\n",
    "                        min_distance=[]\n",
    "                        #print(list_distance,bbox_list)\n",
    "                        for kalman_distance in list_kalman_distance:\n",
    "                            min_distance.append(min(kalman_distance))\n",
    "                        for i in range((len(list_kalman_distance)-len(list_kalman_distance[0]))):\n",
    "                            num=min_distance.index(max(min_distance))\n",
    "                            list_kalman_distance.pop(num)\n",
    "                            min_distance.pop(num)\n",
    "                            list_kalman_ids.pop(num)\n",
    "                #print('data:',len(list_kalman_ids),len(list_kalman_c),len(list_kalman_bbox),len(list_kalman_feature))\n",
    "                #print(list_kalman_c)\n",
    "                for id_s in list_kalman_ids:\n",
    "                    for id_ in id_s:\n",
    "                        list_kalman_id_.append(id_)\n",
    "                #print(list_kalman_distance,list_kalman_bbox,list_kalman_id_,list_kalman_c,list_kalman_feature)\n",
    "                np_kalman_distance = np.asarray(list_kalman_distance)\n",
    "                #print (np_kalman_distance.shape)\n",
    "                if np_kalman_distance.shape[0]<2:\n",
    "                    list_Hungary_kalman=[min(np_kalman_distance.flatten().tolist())]\n",
    "                else:\n",
    "                    list_Hungary_kalman = self.task.Hungary(np_kalman_distance)#all_permutation\n",
    "                #print(np_kalman_distance,list_Hungary_kalman)\n",
    "                count=0\n",
    "                for dis in list_Hungary_kalman:\n",
    "                    number = np_kalman_distance.flatten().tolist().index(dis)\n",
    "                    identities.append(list_kalman_id_[number])\n",
    "                    self.save[list_kalman_id_[number]]['bbox'] =list_kalman_bbox[count]\n",
    "                    self.save[list_kalman_id_[number]]['frame'] =self.frame\n",
    "                    dths.append(list_kalman_c[count])\n",
    "                    #color_=self.check_lib_add(list_kalman_feature[count],list_kalman_id_[number],list_kalman_bbox[count])\n",
    "                    color.append(0)\n",
    "                    count+=1\n",
    "                for flag,id_,bbox in zip(list_kalman_flag,identities,list_kalman_bbox):\n",
    "                    self.cross_on(id_)\n",
    "                    self.overlap_off(id_)\n",
    "                    self.kalman_bbox_update(id_,bbox)\n",
    "                cross_id=identities\n",
    "                    \n",
    "            #PCA\n",
    "            list_bbox_loss,list_feature_loss=[],[]\n",
    "            if bbox_list!=[] and list_distance!=[]:\n",
    "                    kalman_center,kalman_feature,kalman_id,kalman_bbox=[],[],[],[]\n",
    "                    kalman_bbox=bbox_list\n",
    "                    #需要id的数量要小于等于就绪id的数量\n",
    "                    #print(len(bbox_list),len(list_distance[0]))\n",
    "                    if len(bbox_list)>len(list_distance[0]):\n",
    "                        min_distance=[]\n",
    "                        #print(list_distance,bbox_list)\n",
    "                        for id_distanc in list_distance:\n",
    "                            min_distance.append(min(id_distanc))\n",
    "                        for i in range((len(bbox_list)-len(list_distance[0]))):\n",
    "                            num=min_distance.index(max(min_distance))\n",
    "                            min_distance.pop(num)\n",
    "                            list_distance.pop(num)\n",
    "                            list_id.pop(num)\n",
    "                            list_center.pop(num)  \n",
    "                            list_feature_loss.append(list_feature.pop(num))\n",
    "                            list_bbox_loss.append(kalman_bbox.pop(num))\n",
    "                            #print(list_bbox_loss,list_feature_loss)\n",
    "                            confidences.pop(num)\n",
    "                    if list_distance==[]:\n",
    "                        return identities,dths,color,kalman_overlap_bbox,cross_id,overlap_id,guss_bbox\n",
    "                    np_distance=np.asarray(list_distance)\n",
    "                    #print(np_distance)\n",
    "                    #print(self.save.keys())\n",
    "                    if np_distance.shape[0]<2:\n",
    "                        list_Hungary=[min(np_distance.flatten().tolist())]\n",
    "                    else:\n",
    "                        list_Hungary = self.task.Hungary(np_distance)#all_permutation\n",
    "                    #list_Hungary = self.task.Hungary(np_distance)#all_permutation\n",
    "                    #list_Hungary = self.computer_Hungary(np_distance)\n",
    "                    #print(np_distance,list_Hungary)\n",
    "                    list_id_,list_center_,list_feature_=[],[],[]\n",
    "                    for id_s,center_s,feature_s in zip(list_id,list_center,list_feature):\n",
    "                        for id_,center_,feature_ in zip(id_s,center_s,feature_s):\n",
    "                            list_id_.append(id_)\n",
    "                            list_center_.append(center_)\n",
    "                            list_feature_.append(feature_)\n",
    "                    for number in list_Hungary:\n",
    "                        #number = number*0.00001               \n",
    "                        min_distance = np_distance.flatten().tolist().index(number)\n",
    "                        kalman_id.append(list_id_[min_distance])\n",
    "                        kalman_center.append(list_center_[min_distance])\n",
    "                        kalman_feature.append(list_feature_[min_distance])\n",
    "\n",
    "                    #检查重新回来的id的frame\n",
    "                    #ret_id_frame = self.check_frame_id(min_distance_id,min_distance_feature,self.frame)\n",
    "                    #print(kalman_bbox,kalman_center,kalman_feature,kalman_id,confidences)\n",
    "                    #ret_bbox_cross = self.check_bboxs_cross(kalman_bbox,kalman_id)\n",
    "                    #if ret_bbox_cross==False :\n",
    "                        #kalman_bbox=self.kalman_reid(kalman_bbox,kalman_id)\n",
    "                    for bbox,conter,feature,id_,c in zip(kalman_bbox,kalman_center,kalman_feature,kalman_id,confidences):\n",
    "                         #检查除id_me外是否与数据库里的bbox重叠\n",
    "                        center_ = (conter*0.5)+(feature*0.5)\n",
    "                        self.save[id_]['center'] =center_\n",
    "                        self.save[id_]['bbox'] =bbox\n",
    "                        self.save[id_]['frame'] =self.frame\n",
    "                        color_=self.check_lib_add(feature,id_,bbox)\n",
    "                        color.append(color_)\n",
    "                        dths.append(c)\n",
    "                        identities.append(id_)\n",
    "                    #没有ID,重新add_id    \n",
    "                    #print(list_bbox_loss,list_feature_loss,confidences)\n",
    "                    for bbox,featureVector,c in zip(list_bbox_loss,list_feature_loss,confidences):\n",
    "                        #print(bbox,featureVector,c)\n",
    "                        id_ = self.add_id(featureVector[0],bbox,self.frame)\n",
    "                        identities.append(id_)\n",
    "                        dths.append(c)\n",
    "                        color.append(0)  \n",
    "        self.frame+=1\n",
    "        #print(identities,dths,color)\n",
    "        return identities,dths,color ,kalman_overlap_bbox,cross_id,overlap_id,guss_bbox\n",
    "    #输入图片计算，输出Feature\n",
    "    def compute_feature(self,im):\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        #print(im.shape)\n",
    "        feature = extractor([im])\n",
    "        #print(feature.shape)\n",
    "        return feature\n",
    "    \n",
    "    '''\n",
    "    def compute_feature(self,im):\n",
    "        im_ = im\n",
    "        size=im_.shape\n",
    "        im_ = np.float32(im_)/255.0\n",
    "        Fim = im_.flatten()\n",
    "        Fmean = self.mean.reshape(Fim.shape)\n",
    "        Fdf = Fim-Fmean\n",
    "        Fdf= Fdf.reshape(24576,1)\n",
    "        W=[]\n",
    "        for i in range(len(self.eigenVectors)):\n",
    "            E = self.eigenVectors[i,:].reshape(1,24576)\n",
    "            W.append(np.dot(E,Fdf).flatten())\n",
    "        W = np.asarray(W)\n",
    "        return W\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(bbox_list,c_list,im,identities,dths,color,kalman,t,cross_id,overlap_id,guss_bbox):\n",
    "    w_im,h_im=im.shape[:2]\n",
    "    #print(len(out_list))\n",
    "    for bbox,c,id_,dth,color_ in zip(bbox_list,c_list,identities,dths,color):\n",
    "        #(x1, y1, x2, y2) = bbox\n",
    "        (x, y, w, h) = bbox\n",
    "        (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "        cv2.rectangle(im, (x1, y1), (x2, y2), (0, color_, 255-color_), 2)\n",
    "        #cv2.putText(im, ('%.2f'%c), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 250,0), 1)\n",
    "        cv2.putText(im, ('%s'%id_), (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, color_, 255-color_), 2)\n",
    "        cv2.putText(im, ('%.2f'%dth), (x2, y1+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, color_, 255-color_), 2)\n",
    "        cv2.circle(im, (int(x),int(y)), 1, (0, 255, 0), 2)\n",
    "    num=0\n",
    "    for xy in guss_bbox:\n",
    "        cv2.circle(im, xy, 1, (0, 0, 255), 2)\n",
    "    for cid_ in cross_id:\n",
    "        cv2.putText(im, ('Crossid : %s'%cid_), (w_im, 100+num), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        num+=50\n",
    "    for oid_ in overlap_id:\n",
    "        cv2.putText(im, ('Overlapid : %s'%oid_), (w_im, 100+num), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "        num+=50\n",
    "\n",
    "    for ka in kalman:  \n",
    "        (x,y,w,h)=ka\n",
    "        (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "        cv2.rectangle(im, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.circle(im, (x,y), 1, (0, 0, 255), 2)\n",
    "    fps = 1/(time.time()-t)\n",
    "    cv2.putText(im, ('fps:%.2f'%fps), (w_im, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    cv2.putText(im, ('Id number: %d'%len(bbox_list)), (w_im, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    cv2.imshow('V5', im)\n",
    "    return im\n",
    "def yolov5_detect(YOLOV5_CFG,pca):\n",
    "    device = torch_utils.select_device(YOLOV5_CFG.device)\n",
    "    model = torch.load(YOLOV5_CFG.weights, map_location=device)['model']\n",
    "    #model = torch.load(YOLOV5_CFG.weights, map_location=device)\n",
    "    model.to(device).eval()\n",
    "    names = model.names if hasattr(model, 'names') else model.modules.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "    \n",
    "    if os.path.isfile(YOLOV5_CFG.source) is True:\n",
    "        cap = cv2.VideoCapture(YOLOV5_CFG.source)\n",
    "        w0,h0,fps,max_index = int(cap.get(3)),int(cap.get(4)),int(cap.get(5)),int(cap.get(7))\n",
    "        [w1,h1] = YOLOV5_CFG.im_size\n",
    "        if YOLOV5_CFG.output is not False:\n",
    "            fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "            out = cv2.VideoWriter(YOLOV5_CFG.output, fourcc, fps, (w0,h0))\n",
    "        for i in range(max_index):\n",
    "            re,im = cap.read()\n",
    "            net_input = np.transpose(cv2.resize(im, (w1,h1))/255,(2,0,1)).reshape((-1,3,h1,w1))\n",
    "            net_input = torch.from_numpy(net_input).to(device).type(torch.float32)\n",
    "            t = time.time()\n",
    "            pred = model(net_input, augment=YOLOV5_CFG.augment)[0]\n",
    "            pred = non_max_suppression(pred, YOLOV5_CFG.conf_thres, YOLOV5_CFG.iou_thres, fast=True, classes=YOLOV5_CFG.classes, agnostic=YOLOV5_CFG.agnostic_nms)\n",
    "            if pred is None or pred[0] is None:\n",
    "                cv2.imshow('V5',im)\n",
    "                if YOLOV5_CFG.output is not False:\n",
    "                    out.write(im)\n",
    "                continue\n",
    "            w_im,h_im=im.shape[:2]\n",
    "            #print(w_im,h_im)\n",
    "            area_im=int(w_im*h_im)\n",
    "            bboxes,confs,cats = pred[0][:,:4].cpu().detach().numpy(),pred[0][:,4].cpu().detach().numpy(),pred[0][:,5].cpu().detach().numpy()\n",
    "            bboxes[:,[0,2]],bboxes[:,[1,3]]=bboxes[:,[0,2]]*(w0/w1),bboxes[:,[1,3]]*(h0/h1)\n",
    "            list_bbox,list_conf=[],[]\n",
    "            for bbox,conf,cat in zip(bboxes.astype(np.int),confs,cats.astype(np.int)):\n",
    "                if (names[cat]=='person'):\n",
    "                    #p_min,p_max = (bbox[0],bbox[1]),(bbox[2],bbox[3])\n",
    "                    #im = cv2.rectangle(im, p_min, p_max, (255,0,123), 1, cv2.LINE_AA)\n",
    "                    #im = cv2.putText(im, '%s %.2f'%(names[cat],conf), p_min, cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    (x1, y1, x2, y2)=bbox\n",
    "                    bbox_=(int(abs((x1+x2)*0.5)),int(abs((y1+y2)*0.5)),int(abs(x1-x2)),int(abs(y1-y2)))\n",
    "                    (x,y,w,h)=bbox_\n",
    "                    area=int(w*h)\n",
    "                    if (area/area_im) <0.005:\n",
    "                        continue\n",
    "                    list_bbox.append(bbox_)\n",
    "                    list_conf.append(conf)\n",
    "            #CrossVideo Reid\n",
    "            identities,dths,color ,kalman,cross_id,overlap_id,guss_bbox = pca.cross_video_pca(list_bbox,list_conf,im)\n",
    "            display(list_bbox,list_conf,im,identities,dths,color,kalman,t,cross_id,overlap_id,guss_bbox)\n",
    "            t=time.time()\n",
    "            if YOLOV5_CFG.output is not False:\n",
    "                out.write(im)\n",
    "            if cv2.waitKey(1)&0xff==ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        if YOLOV5_CFG.output is not False:\n",
    "            out.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from ./pcadata/train2020...1982 files read.\n",
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX 1080 Ti', total_memory=11264MB)\n",
      "\n",
      "find id 001\n",
      "001 passage is False\n",
      "[0.03786855936050415]\n",
      "[0.03865402936935425]\n",
      "[0.035033583641052246]\n",
      "[0.032151758670806885]\n",
      "[0.033841073513031006]\n",
      "[0.031118929386138916]\n",
      "001 passage is True\n",
      "[]\n",
      "find id 002\n",
      "[0.03248244524002075]\n",
      "001 passage is False\n",
      "[0.027536869049072266, 0.04382121562957764]\n",
      "[0.023078322410583496, 0.043981730937957764]\n",
      "[0.0211641788482666, 0.042613685131073]\n",
      "[0.023404240608215332, 0.04310798645019531]\n",
      "[0.024598896503448486, 0.04289764165878296]\n",
      "001 passage is True\n",
      "001 passage is False\n",
      "[0.03463470935821533, 0.04754769802093506]\n",
      "[0.03526341915130615, 0.043645620346069336]\n",
      "[0.03221839666366577, 0.0449865460395813]\n",
      "[0.029484868049621582, 0.046312689781188965]\n",
      "[0.02910667657852173, 0.04536384344100952]\n",
      "[0.030738532543182373, 0.05011337995529175]\n",
      "001 passage is True\n",
      "[0.04218423366546631]\n",
      "[0.0402563214302063]\n",
      "[0.04704469442367554]\n",
      "[0.04718440771102905]\n",
      "[0.04533427953720093]\n",
      "[0.047116756439208984]\n",
      "002 passage is True\n",
      "[]\n",
      "find id 003\n",
      "[0.048413217067718506]\n",
      "[0.04587894678115845]\n",
      "[0.04417121410369873]\n",
      "[0.0453985333442688]\n",
      "[0.0462760329246521]\n",
      "[0.04573601484298706]\n",
      "003 passage is True\n",
      "002 passage is False\n",
      "001 passage is False\n",
      "003 passage is False\n",
      "[0.03368520736694336, 0.03776437044143677, 0.04944777488708496]\n",
      "[0.03342843055725098, 0.038778603076934814, 0.0519832968711853]\n",
      "[0.034921348094940186, 0.04023611545562744, 0.05272907018661499]\n",
      "001 passage is True\n",
      "[0.04008227586746216, 0.021876037120819092]\n",
      "[0.038101017475128174, 0.020703256130218506]\n",
      "[0.036981940269470215, 0.019261479377746582]\n",
      "003 passage is True\n",
      "[0.03743225336074829]\n",
      "[0.036773502826690674]\n",
      "[0.03535240888595581]\n",
      "002 passage is True\n",
      "[]\n",
      "find id 004\n",
      "[0.008252441883087158]\n",
      "002 passage is False\n",
      "003 passage is False\n",
      "[0.02162754535675049, 0.038748323917388916, 0.04647570848464966]\n",
      "[0.02101266384124756, 0.04055774211883545, 0.048709750175476074]\n",
      "[0.02198690176010132, 0.041492581367492676, 0.04979431629180908]\n",
      "[0.021134674549102783, 0.04016470909118652, 0.04902571439743042]\n",
      "[0.02019709348678589, 0.04062306880950928, 0.04717075824737549]\n",
      "002 passage is True\n",
      "[0.012749850749969482, 0.04951274394989014]\n",
      "[0.012769758701324463, 0.04596775770187378]\n",
      "[0.013603031635284424, 0.047129154205322266]\n",
      "[0.01461118459701538, 0.048996567726135254]\n",
      "[0.015765607357025146, 0.04720783233642578]\n",
      "[0.01662355661392212, 0.049622297286987305]\n",
      "003 passage is True\n",
      "002 passage is False\n",
      "003 passage is False\n",
      "[0.018260955810546875, 0.04841899871826172, 0.0485040545463562]\n",
      "[0.021192073822021484, 0.04630047082901001, 0.04773604869842529]\n",
      "[0.020331919193267822, 0.04455530643463135, 0.04564213752746582]\n",
      "002 passage is True\n",
      "[0.04368412494659424, 0.029785633087158203]\n",
      "[0.04456049203872681, 0.02875518798828125]\n",
      "[0.04197382926940918, 0.030140399932861328]\n",
      "004 passage is True\n",
      "002 passage is False\n",
      "004 lib len :3[0.041603803634643555, 0.01578962802886963]\n",
      "[0.04106992483139038, 0.014065325260162354]\n",
      "[0.04089003801345825, 0.014564335346221924]\n",
      "003 passage is True\n",
      "001 passage is False\n",
      "004 passage is False\n",
      "[0.027969419956207275, 0.031695544719696045, 0.034320294857025146]\n",
      "[0.02861189842224121, 0.03190559148788452, 0.033984482288360596]\n",
      "[0.03675180673599243, 0.02359151840209961, 0.029125690460205078]\n",
      "002 passage is True\n",
      "[0.032047927379608154, 0.02627640962600708]\n",
      "[0.03138333559036255, 0.024824023246765137]\n",
      "[0.03286385536193848, 0.026441991329193115]\n",
      "004 passage is True\n",
      "003 passage is False\n",
      "004 passage is False\n",
      "[0.03370332717895508, 0.03067493438720703, 0.03029078245162964]\n",
      "[0.033328115940093994, 0.028549909591674805, 0.028463780879974365]\n",
      "[0.033261001110076904, 0.02652442455291748, 0.027687668800354004]\n",
      "003 passage is True\n",
      "[0.030251502990722656, 0.016759216785430908]\n",
      "[0.028250455856323242, 0.015119671821594238]\n",
      "[0.028288662433624268, 0.014302551746368408]\n",
      "004 passage is True\n",
      "003 passage is False\n",
      "[0.03268313407897949, 0.01738154888153076]\n",
      "[0.03416180610656738, 0.016487479209899902]\n",
      "[0.0326540470123291, 0.014683008193969727]\n",
      "003 passage is True\n",
      "003 passage is False\n",
      "002 passage is False\n",
      "004 passage is False\n",
      "[0.023322343826293945, 0.0190277099609375, 0.028240442276000977, 0.018662214279174805]\n",
      "[0.028999507427215576, 0.019360840320587158, 0.029834389686584473, 0.01848304271697998]\n",
      "[0.030001699924468994, 0.018388569355010986, 0.026076555252075195, 0.018581926822662354]\n",
      "002 passage is True\n",
      "[0.033854782581329346, 0.017825961112976074, 0.044368088245391846]\n",
      "[0.035729050636291504, 0.017727017402648926, 0.044494807720184326]\n",
      "[0.03481793403625488, 0.018036067485809326, 0.04358184337615967]\n",
      "003 passage is True\n",
      "[0.029959440231323242, 0.015050411224365234]\n",
      "[0.03103470802307129, 0.014934301376342773]\n",
      "[0.03159666061401367, 0.015585899353027344]\n",
      "004 passage is True\n",
      "002 passage is False\n",
      "[0.03256082534790039, 0.02290821075439453]\n",
      "[0.031119227409362793, 0.021369218826293945]\n",
      "[0.03116285800933838, 0.02121645212173462]\n",
      "[0.03311985731124878, 0.021358191967010498]\n",
      "[0.03205901384353638, 0.02127087116241455]\n",
      "[0.031237363815307617, 0.02144777774810791]\n",
      "002 passage is True\n",
      "003 passage is False\n",
      "004 passage is False\n",
      "[0.03263944387435913, 0.023435771465301514, 0.03015238046646118]\n",
      "[0.03246033191680908, 0.020163118839263916, 0.029237091541290283]\n",
      "[0.033937811851501465, 0.017470359802246094, 0.029692232608795166]\n",
      "003 passage is True\n",
      "[0.01144707202911377, 0.031225144863128662]\n",
      "[0.012382745742797852, 0.03054797649383545]\n",
      "[0.013896584510803223, 0.029880881309509277]\n",
      "001 passage is True\n",
      "001 passage is False\n",
      "[0.014082133769989014, 0.0335162878036499]\n",
      "[0.013903796672821045, 0.034232497215270996]\n",
      "[0.014682471752166748, 0.03220510482788086]\n",
      "001 passage is True\n",
      "002 passage is False\n",
      "003 passage is False\n",
      "[0.014593183994293213, 0.02573704719543457, 0.014101862907409668]\n",
      "[0.0169144868850708, 0.024600446224212646, 0.01690906286239624]\n",
      "[0.01808905601501465, 0.023375749588012695, 0.01689934730529785]\n",
      "004 passage is True\n",
      "[0.04101228713989258, 0.012641191482543945]\n",
      "[0.0424838662147522, 0.013529062271118164]\n",
      "[0.043387413024902344, 0.013196885585784912]\n",
      "003 passage is True\n",
      "001 passage is False\n",
      "[0.033265531063079834, 0.016374170780181885]\n",
      "[0.03363519906997681, 0.016403913497924805]\n",
      "003 passage is False\n",
      "004 passage is False\n",
      "[0.028068363666534424, 0.018106281757354736, 0.029846668243408203, 0.013738632202148438]\n",
      "[0.029034435749053955, 0.01953864097595215, 0.03311222791671753, 0.014552950859069824]\n",
      "[0.027531147003173828, 0.018877625465393066, 0.03247040510177612, 0.01405191421508789]\n",
      "[0.028609395027160645, 0.01808798313140869, 0.03190422058105469, 0.014202356338500977]\n",
      "004 passage is True\n",
      "[0.013714373111724854, 0.029063284397125244, 0.0316624641418457]\n",
      "[0.01332765817642212, 0.028476178646087646, 0.031186401844024658]\n",
      "[0.012872576713562012, 0.027508854866027832, 0.031116843223571777]\n",
      "001 passage is True\n",
      "[0.03906738758087158, 0.01429075002670288]\n",
      "[0.040062129497528076, 0.01407843828201294]\n",
      "[0.040218889713287354, 0.014816582202911377]\n",
      "003 passage is True\n",
      "001 passage is False\n",
      "[0.03018409013748169, 0.01933109760284424]\n",
      "[0.031147420406341553, 0.01618140935897827]\n",
      "[0.0308302640914917, 0.015433549880981445]\n",
      "002 passage is True\n",
      "003 passage is False\n",
      "002 passage is False\n",
      "004 passage is False\n"
     ]
    }
   ],
   "source": [
    "YOLOV5_CFG = CN()\n",
    "YOLOV5_CFG.agnostic_nms = False\n",
    "YOLOV5_CFG.augment      = False\n",
    "YOLOV5_CFG.classes      = False\n",
    "YOLOV5_CFG.device       = '0'\n",
    "\n",
    "YOLOV5_CFG.weights = 'weights/yolov5l.pt'\n",
    "YOLOV5_CFG.source = './testvideo/threecrossrotate.mp4'\n",
    "name = time.strftime('%Y.%m.%d',time.localtime(time.time()))\n",
    "YOLOV5_CFG.output = './savevideo/'+name+'.mp4'\n",
    "\n",
    "\n",
    "YOLOV5_CFG.save_npz     = False\n",
    "YOLOV5_CFG.conf_thres   = 0.3\n",
    "YOLOV5_CFG.iou_thres    = 0.3\n",
    "YOLOV5_CFG.im_size      = [640,512]\n",
    "YOLOV5_CFG.freeze()\n",
    "\n",
    "pca=PCA('./pcadata/train2020',256)\n",
    "yolov5_detect(YOLOV5_CFG,pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
