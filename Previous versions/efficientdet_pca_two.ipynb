{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import copy\n",
    "import queue\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.backends import cudnn\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess,sirxiapreprocess\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self):\n",
    "        self.x,self.y=0,0\n",
    "        self.last_measurement = self.current_measurement = np.array((2,1),np.float32)\n",
    "        self.last_predicition = self.current_prediction = np.zeros((2,1),np.float32)#np.asarray(bbox).totype(,np.float32)#np.zeros((2,1),np.float32)\n",
    "        self.kalman = cv2.KalmanFilter(4,2)\n",
    "        #设置测量矩阵\n",
    "        self.kalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)\n",
    "        #设置转移矩阵\n",
    "        self.kalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)\n",
    "        #设置过程噪声协方差矩阵\n",
    "        self.kalman.processNoiseCov = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32)*0.03 \n",
    "    def mousemove(self,x,y):\n",
    "        #初始化\n",
    "        self.last_measurement = self.current_measurement\n",
    "        self.last_prediction = self.current_prediction\n",
    "        #传递当前测量坐标值\n",
    "        self.current_measurement = np.array([[np.float32(x)],[np.float32(y)]])\n",
    "        #用来修正卡尔曼滤波的预测结果\n",
    "        self.kalman.correct(self.current_measurement)\n",
    "        # 调用kalman这个类的predict方法得到状态的预测值矩阵，用来估算目标位置\n",
    "        current_prediction = self.kalman.predict()\n",
    "        #上一次测量值\n",
    "        lmx,lmy = self.last_measurement[0],self.last_measurement[1]\n",
    "        #当前测量值\n",
    "        cmx,cmy = self.current_measurement[0],self.current_measurement[1]\n",
    "        #上一次预测值\n",
    "        #lpx,lpy = last_prediction[0],last_prediction[1]\n",
    "        #当前预测值\n",
    "        cpx,cpy = current_prediction[0],current_prediction[1]\n",
    "        return cpx,cpy\n",
    "    def update(self,bbox):\n",
    "        (x,y,w,h)=bbox\n",
    "        self.x,self.y = self.mousemove(x,y)\n",
    "    def get(self):\n",
    "        return self.x,self.y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class efficientdet:\n",
    "    def __init__(self,compound_coef,force_input_size = 1920,huamanNum=1,dir_path='./walkingworkspace/train_all',NUM_EIGEN_FACES= 128,test=False):\n",
    "        self.humanNum=huamanNum\n",
    "        cudnn.fastest = True\n",
    "        cudnn.benchmark = True\n",
    "        self.bbox_save=[]\n",
    "        self.id_save=[]\n",
    "        self.test=test\n",
    "        self.bbox_threshold=0.01#%bbox的阈值!<\n",
    "        self.probability_threshold=0.3#%人体识别概率的阈值!<\n",
    "        self.use_cuda = True \n",
    "        self.use_float16 = False\n",
    "        self.threshold = 0.2\n",
    "        self.iou_threshold = 0.2\n",
    "        self.obj_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "            'fire hydrant', '', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "            'cow', 'elephant', 'bear', 'zebra', 'giraffe', '', 'backpack', 'umbrella', '', '', 'handbag', 'tie',\n",
    "            'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "            'skateboard', 'surfboard', 'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "            'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
    "            'cake', 'chair', 'couch', 'potted plant', 'bed', '', 'dining table', '', '', 'toilet', '', 'tv',\n",
    "            'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "            'refrigerator', '', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "            'toothbrush']\n",
    "        #self.device = torch.device('cuda')\n",
    "        self.model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(self.obj_list))\n",
    "        self.model.load_state_dict(torch.load(f'weights/efficientdet-d{compound_coef}.pth'))\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.eval()\n",
    "        #self.model=nn.DataParallel(self.model)\n",
    "        self.model.cuda()\n",
    "        input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "        self.input_size =  force_input_size\n",
    "        self.t=time.time()\n",
    "        self.pca=PCA(dir_path,NUM_EIGEN_FACES)\n",
    "        if self.test==True:\n",
    "            self.pca.test('./walkingworkspace/test2020')\n",
    "            self.label_test=[]\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        name = time.strftime('%Y.%m.%d',time.localtime(time.time()))\n",
    "        self.out = cv2.VideoWriter('./savevideo/'+name+'.avi',fourcc, 30.0, (640,480))\n",
    "        self.save={}\n",
    "        self.frame=0\n",
    "    def init_video(self):\n",
    "        self.out.release()\n",
    "        self.pca.clear_id()\n",
    "        self.pca.frame=0\n",
    "        name = time.strftime('%Y.%m.%d',time.localtime(time.time()))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.out = cv2.VideoWriter('./savevideo/'+name+'.avi',fourcc, 30.0, (640,480))\n",
    "    def threadStart(self):\n",
    "        threadone=threading.Thread(target=self.mythread,args=())\n",
    "        threadone.start()\n",
    "      \n",
    "    def mythread(self):\n",
    "        global data_queue,out_queue\n",
    "        print('start thread ->>> efficientdet ')\n",
    "        while True:\n",
    "            self.t=time.time()\n",
    "            while(data_queue.qsize()<2):\n",
    "                time.sleep(0.01)\n",
    "                if time.time()-self.t>10:\n",
    "                    print('stop thread ->>> efficientdet ')\n",
    "                    break\n",
    "            out_queue.put(self.detector(data_queue.get()))\n",
    "                            ##################\n",
    "                            ####detector######\n",
    "                            ##################\n",
    "    def  detector(self,im):\n",
    "        ori_imgs, framed_imgs, framed_metas = sirxiapreprocess(im, max_size=self.input_size)\n",
    "        x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "        x = x.to(torch.float32 if not self.use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "        with torch.no_grad():\n",
    "            features, regression, classification, anchors = self.model(x)\n",
    "            regressBoxes = BBoxTransform()\n",
    "            clipBoxes = ClipBoxes()\n",
    "            out = postprocess(x,\n",
    "                              anchors, regression, classification,\n",
    "                              regressBoxes, clipBoxes,\n",
    "                              self.threshold, self.iou_threshold)\n",
    "            out = invert_affine(framed_metas, out)\n",
    "            bbox_list,c_list=self.update(out, ori_imgs)\n",
    "            #print(bbox_list,c_list)\n",
    "            #identities,bbox_xyxy = DeepSort.deep_sort(np.asarray(bbox_list),np.asarray(c_list),im)\n",
    "            identities,dths,color = self.pca.efficientdet_compute_pca(bbox_list,c_list,im)        \n",
    "            im =self.display(bbox_list,c_list ,im,identities,dths,color) \n",
    "            #for bbox,id_ in zip(bbox_list,identities):\n",
    "                #self.bbox_save.append(bbox)\n",
    "                #self.id_save.append(id_)\n",
    "            if self.test:\n",
    "                self.save[self.frame]=[identities,bbox_list]\n",
    "            self.out.write(im)\n",
    "            self.t=time.time()\n",
    "            cv2.waitKey(1)\n",
    "            self.frame+=1\n",
    "            #return identities,bbox_xyxy,c_list\n",
    "            #return bbox_list,c_list ,identities\n",
    "    #过滤\n",
    "    def update(self,preds, imgs):\n",
    "        save_list=[]\n",
    "        area_list=[]\n",
    "        score_list=[]\n",
    "        for i in range(len(imgs)):\n",
    "            if len(preds[i]['rois']) == 0:\n",
    "                continue\n",
    "            for j in range(len(preds[i]['rois'])):\n",
    "                if preds[i]['class_ids'][j]==0:#person\n",
    "                    score = float(preds[i]['scores'][j])#百分比\n",
    "                    H,W=imgs[i].shape[:2]\n",
    "                    (x1, y1, x2, y2) = preds[i]['rois'][j].astype(np.int)\n",
    "                    area = (x2-x1)*(y2-y1)\n",
    "                    if  (area/H*W)<self.bbox_threshold or score<self.probability_threshold:\n",
    "                        continue\n",
    "                    x,y,w,h=(x1+x2)/2,(y1+y2)/2,abs(x1-x2),abs(y1-y2)\n",
    "                    area_list.append(area)\n",
    "                    save_list.append([x,y,w,h]) \n",
    "                    score_list.append(score)\n",
    "        bbox_list,c_list=[],[]\n",
    "        if len(area_list)>self.humanNum:\n",
    "            \n",
    "            for i in range(self.humanNum):\n",
    "                one=save_list[area_list.index(max(area_list))]\n",
    "                two=score_list[area_list.index(max(area_list))]\n",
    "                bbox_list.append(copy.copy(one))\n",
    "                c_list.append(copy.copy(two))\n",
    "                save_list.remove(one)\n",
    "                score_list.remove(two)\n",
    "                area_list.remove(max(area_list))\n",
    "                 \n",
    "        else:\n",
    "            for i in range(len(area_list)):\n",
    "                one=save_list[area_list.index(max(area_list))]\n",
    "                two=score_list[area_list.index(max(area_list))]\n",
    "                bbox_list.append(copy.copy(one))\n",
    "                c_list.append(copy.copy(two))\n",
    "                save_list.remove(one)\n",
    "                score_list.remove(two)\n",
    "                area_list.remove(max(area_list))\n",
    "        return bbox_list,c_list\n",
    "    \n",
    "    def display(self,bbox_list,c_list,im,identities,dths,color):\n",
    "        #print(len(out_list))\n",
    "        for bbox,c,id_,dth,color_ in zip(bbox_list,c_list,identities,dths,color):\n",
    "            #(x1, y1, x2, y2) = bbox\n",
    "            (x, y, w, h) = bbox\n",
    "            (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "            cv2.rectangle(im, (x1, y1), (x2, y2), (0, color_, 255-color_), 2)\n",
    "            #cv2.putText(im, ('%.2f'%c), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 250,0), 1)\n",
    "            cv2.putText(im, ('%.2f'%dth), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, color_, 255-color_), 1)\n",
    "            cv2.putText(im, ('%s'%id_), (x1, y1+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, color_, 255-color_), 2)\n",
    "        fps = 1/(time.time()-self.t)\n",
    "        cv2.putText(im, ('%.2f'%fps), (590, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.imshow('efficientdet', im)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet101\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "class PCA:\n",
    "    def __init__(self,dir_path='./test_colors/train',NUM_EIGEN_FACES = 64):\n",
    "        self.save={'000':{'center':[],'bbox':[],'lib':[],'frame':0,'passage':False}}\n",
    "        self.NUM_EIGEN_FACES = NUM_EIGEN_FACES\n",
    "        self.images = self.readImages(dir_path)\n",
    "        self.data = self.createDataMatrix(self.images)\n",
    "        #self.data = torch.from_numpy(self.data).cuda()\n",
    "        #torch.pca_lowrank(A, q=None, center=True, niter=2)\n",
    "        #self.mean, self.eigenVectors = torch.pca_lowrank(self.data, q=None, center=True, niter= self.NUM_EIGEN_FACES)\n",
    "        #self.means, self.eigenVectorses=[],[]\n",
    "        #print('the alldata %d'%len(self.eigenVectors))\n",
    "        #self.init_pca(basepath)\n",
    "        #self.notebook={'000':{'frame':[],'lib':[]}}\n",
    "        self.frame=0\n",
    "        self.flag_frame=[]\n",
    "        self.flag_line=[]\n",
    "        self.dth = 0.5#相似度距离0.6  / 欧氏距离25\n",
    "        self.Forget=10  #状态切换帧\n",
    "        self.testsave={}\n",
    "        self.models_mean = './models/mean.npy'\n",
    "        self.models_eigenVector = './models/eigenVector.npy'\n",
    "        #self.meta = threading.Lock()\n",
    "        if os.path.exists(self.models_mean)==False and os.path.exists(self.models_eigenVector)==False:\n",
    "            self.mean, self.eigenVectors = cv2.PCACompute(self.data, mean=None, maxComponents=self.NUM_EIGEN_FACES)\n",
    "            np.save(self.models_mean,self.mean)\n",
    "            np.save(self.models_eigenVector,self.eigenVectors)\n",
    "        else:\n",
    "            self.mean=np.load(self.models_mean)\n",
    "            self.eigenVectors=np.load(self.models_eigenVector)\n",
    "        #卡尔曼滤波\n",
    "        self.kalman=[]\n",
    "        self.old_id=[]\n",
    "    def createDataMatrix(self,images):\n",
    "        numImages = len(images)\n",
    "        sz = images[0].shape\n",
    "        data = np.zeros((numImages, sz[0] * sz[1] * sz[2]), dtype=np.float32)\n",
    "        for i in range(0, numImages):\n",
    "            image = images[i].flatten()\n",
    "            data[i,:] = image\n",
    "        #print(\"createData ok\")\n",
    "        return data\n",
    "\n",
    "    def readImages(self,path):\n",
    "        print(\"Reading images from \" + path, end=\"...\")\n",
    "        # Create array of array of images.\n",
    "        images = []\n",
    "        # List all files in the directory and read points from text files one by one\n",
    "        for name in glob.glob(path+'/*'):\n",
    "            for imagePath in glob.glob(name+'/*.jpg'):\n",
    "                    # Add to array of images\n",
    "                    im = cv2.imread(imagePath)\n",
    "                    im = cv2.resize(im,(64,128))\n",
    "                    if im is None :\n",
    "                        print(\"image:{} not read properly\".format(imagePath))\n",
    "                    else :\n",
    "                        # Convert image to floating point\n",
    "                        im = np.float32(im)/255.0\n",
    "                        # Add image to list\n",
    "                        images.append(im)\n",
    "                        # Flip image \n",
    "                        imFlip = cv2.flip(im, 1);\n",
    "                        # Append flipped image\n",
    "                        #images.append(imFlip)\n",
    "        numImages = int(len(images))\n",
    "        # Exit if no image found\n",
    "        if numImages == 0 :\n",
    "            print(\"No images found\")\n",
    "            sys.exit(0)\n",
    "        print(str(numImages) + \" files read.\")\n",
    "        return images\n",
    "#*\n",
    "#*\n",
    "#*      算法集合\n",
    "#*\n",
    "#*\n",
    "    def compute_cos(self,x,y):\n",
    "        x_,y_=x.flatten(),y.flatten()\n",
    "        dist =1- abs(np.dot(x_,y_)/(np.linalg.norm(x_)*np.linalg.norm(y_)))      \n",
    "        return abs(dist)\n",
    "    \n",
    "    def compute_dis(self,x,y):\n",
    "         return np.linalg.norm( x - y )\n",
    "    \n",
    "    def compute_Maha(self,x,y):\n",
    "        X=np.vstack([x,y])\n",
    "        XT=X.T\n",
    "        S=np.cov(X)   #两个维度之间协方差矩阵\n",
    "        SI = np.linalg.inv(S) #协方差矩阵的逆矩阵\n",
    "        #马氏距离计算两个样本之间的距离，此处共有10个样本，两两组合，共有45个距离。\n",
    "        n=XT.shape[0]\n",
    "        d1=[]\n",
    "        for i in range(0,n):\n",
    "            for j in range(i+1,n):\n",
    "                delta=XT[i]-XT[j]\n",
    "                d=np.sqrt(np.dot(np.dot(delta,SI),delta.T))\n",
    "                d1.append(d)\n",
    "        return d1\n",
    "    \n",
    "    def computer_Hungary(self,task_matrix):\n",
    "        b = task_matrix.copy()\n",
    "        # 行和列减0\n",
    "        for i in range(len(b)):\n",
    "            row_min = np.min(b[i])\n",
    "            for j in range(len(b[i])):\n",
    "                b[i][j] -= row_min\n",
    "        for i in range(len(b[0])):\n",
    "            col_min = np.min(b[:, i])\n",
    "            for j in range(len(b)):\n",
    "                b[j][i] -= col_min\n",
    "        line_count = 0\n",
    "        # 线数目小于矩阵长度时，进行循环\n",
    "        while (line_count < len(b)):\n",
    "            line_count = 0\n",
    "            row_zero_count = []\n",
    "            col_zero_count = []\n",
    "            for i in range(len(b)):\n",
    "                row_zero_count.append(np.sum(b[i] == 0))\n",
    "            for i in range(len(b[0])):\n",
    "                col_zero_count.append((np.sum(b[:, i] == 0)))\n",
    "            # 划线的顺序（分行或列）\n",
    "            line_order = []\n",
    "            row_or_col = []\n",
    "            for i in range(len(b[0]), 0, -1):\n",
    "                while (i in row_zero_count):\n",
    "                    line_order.append(row_zero_count.index(i))\n",
    "                    row_or_col.append(0)\n",
    "                    row_zero_count[row_zero_count.index(i)] = 0\n",
    "                while (i in col_zero_count):\n",
    "                    line_order.append(col_zero_count.index(i))\n",
    "                    row_or_col.append(1)\n",
    "                    col_zero_count[col_zero_count.index(i)] = 0\n",
    "            # 画线覆盖0，并得到行减最小值，列加最小值后的矩阵\n",
    "            delete_count_of_row = []\n",
    "            delete_count_of_rol = []\n",
    "            row_and_col = [i for i in range(len(b))]\n",
    "            for i in range(len(line_order)):\n",
    "                if row_or_col[i] == 0:\n",
    "                    delete_count_of_row.append(line_order[i])\n",
    "                else:\n",
    "                    delete_count_of_rol.append(line_order[i])\n",
    "                c = np.delete(b, delete_count_of_row, axis=0)\n",
    "                c = np.delete(c, delete_count_of_rol, axis=1)\n",
    "                line_count = len(delete_count_of_row) + len(delete_count_of_rol)\n",
    "                # 线数目等于矩阵长度时，跳出\n",
    "                if line_count == len(b):\n",
    "                    break\n",
    "                # 判断是否画线覆盖所有0，若覆盖，进行加减操作\n",
    "                if 0 not in c:\n",
    "                    row_sub = list(set(row_and_col) - set(delete_count_of_row))\n",
    "                    min_value = np.min(c)\n",
    "                    for i in row_sub:\n",
    "                        b[i] = b[i] - min_value\n",
    "                    for i in delete_count_of_rol:\n",
    "                        b[:, i] = b[:, i] + min_value\n",
    "                    break\n",
    "        row_ind, col_ind = linear_sum_assignment(b)\n",
    "        min_cost = task_matrix[row_ind, col_ind].sum()\n",
    "        best_solution = list(task_matrix[row_ind, col_ind])\n",
    "        return  best_solution\n",
    "     #计算两点近距离公式 \n",
    "    def distEclud(self,veA,vecA,veB,vecB):\n",
    "        lossA=veB-veA\n",
    "        lossB=vecB-vecA\n",
    "        return math.sqrt(pow(lossA,2)+pow(lossB,2))\n",
    "#*\n",
    "#*\n",
    "#*      功能函数\n",
    "#*\n",
    "#*\n",
    "    def clear_id(self):\n",
    "        self.save={'000':{'center':[],'bbox':[],'lib':[],'frame':0,'passage':False}}\n",
    "        \n",
    "    '''def kalman_dis(self,bboxs):\n",
    "        (x,y,w,h)=bbox\n",
    "        ids_,min_distance,list_kalman_id,list_kalman_bbox,list_kalman_name=[],[],[],[],[]\n",
    "        for bbox in bboxs:\n",
    "            for name in self.old_id:\n",
    "                kalman_name=int(name)-1\n",
    "                x1,y1=self.kalman[kalman_name].get()\n",
    "                min_distance.append(self.distEclud(x1,y1,x,y))\n",
    "                list_kalman_id.append(name)\n",
    "                list_kalman_bbox.append(bbox)\n",
    "                list_kalman_name.append(name) \n",
    "            num=min_distance.index(min(min_distance))\n",
    "            ids_.append(list_kalman_id[num])\n",
    "            kalman_name =int(list_kalman_name[num])-1\n",
    "            self.kalman[kalman_name].update(list_kalman_bbox[num]\n",
    "        return ids_'''\n",
    "    \n",
    "    def manage_lib(self,frame):\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k=='000':#or v['passage']==False:\n",
    "                continue\n",
    "            lib = v['lib']\n",
    "            frame_lib=v['frame']\n",
    "            if frame-frame_lib>self.Forget:\n",
    "                self.save[k]['frame']=frame\n",
    "                #self.save[k]['lib'].pop(0)\n",
    "                if len(lib)<10:\n",
    "                    self.dele_lib_id(k)\n",
    "                if  k not in self.save:\n",
    "                    continue\n",
    "                if self.save[k]['passage']==True:\n",
    "                    center =self.save[k]['center']\n",
    "                    for lib_ in self.save[k]['lib']:\n",
    "                        center=center*0.99+lib_*0.01\n",
    "                    #self.save[k]['lib'].pop(0)\n",
    "                    self.passage_off(k,center)\n",
    "                    #self.flag_frame=[]\n",
    "                    \n",
    "    def paassag_on(self,feature,bbox,frame,id_):\n",
    "        self.save[id_]['center']=feature\n",
    "        self.save[id_]['bbox']=bbox\n",
    "        self.save[id_]['lib'].append(feature)\n",
    "        self.save[id_]['frame']=frame\n",
    "        self.save[id_]['passage']=True\n",
    "        print('%s passage is True'%id_)\n",
    "        \n",
    "    def passage_off(self,id_,center):\n",
    "        self.save[id_]['center']=center\n",
    "        self.save[id_]['passage']=False\n",
    "        print('%s passage is False'%id_)\n",
    "        \n",
    "    def update_frame(self,id_,frame):\n",
    "        self.save[id_]['frame']=frame\n",
    "        \n",
    "    def dele_lib_id(self,id_):\n",
    "        del self.save[id_]\n",
    "        print('the id %s Remove'%id_)\n",
    "        \n",
    "    def add_lib(self,feature,bbox,frame,passage=False):\n",
    "        save={'center':[],'bbox':[],'lib':[],'frame':0,'passage':False}\n",
    "        for n in  self.save.keys():\n",
    "            id_=n\n",
    "        self.id_new=('%03d'%(int(id_)+1))\n",
    "        save['center']=feature\n",
    "        save['bbox']=bbox\n",
    "        save['lib']=[feature]\n",
    "        save['frame']=frame\n",
    "        save['passage']=passage\n",
    "        self.save[self.id_new]=save\n",
    "        print('find id %s'%self.id_new)\n",
    "        self.kalman.append(KalmanFilter())\n",
    "        return self.id_new\n",
    "    \n",
    "    def add_id(self,feature,bbox,frame):   \n",
    "        #print(len(self.save))\n",
    "        if frame!=0 and len(self.save)!=1:\n",
    "            id_ = self.check_lib_passage(feature)\n",
    "            #self.id_new = self.check_lib(feature)\n",
    "            if id_ == ' ':\n",
    "                self.flag_line=[]\n",
    "                if self.id_new in self.save:\n",
    "                    if frame-self.save[self.id_new]['frame']>1:\n",
    "                        self.flag_frame=[]\n",
    "                else:\n",
    "                    self.flag_frame=[]\n",
    "                if len(self.flag_frame)==0:\n",
    "                    self.id_new = self.add_lib(feature,bbox,frame)\n",
    "                self.flag_frame.append(frame)\n",
    "                self.save[self.id_new]['frame']=frame\n",
    "                #self.update_frame\n",
    "                if len(self.flag_frame)>=5:\n",
    "                    if np.mean(self.flag_frame)==self.flag_frame[2]:\n",
    "                        self.paassag_on(feature,bbox,frame,self.id_new)\n",
    "                        self.flag_frame=[]\n",
    "                    else:\n",
    "                        self.dele_lib_id(self.id_new)\n",
    "                        self.flag_frame=[]\n",
    "            else:\n",
    "                #if frame - self.save[id_]['frame'] >3:\n",
    "                self.flag_frame=[]\n",
    "                self.flag_line.append(frame)\n",
    "                self.save[id_]['frame']=frame\n",
    "                #self.update_frame\n",
    "                if len(self.flag_line)>=3:\n",
    "                    if np.mean(self.flag_line)==self.flag_line[1]:\n",
    "                        self.paassag_on(feature,bbox,frame,id_)\n",
    "                        self.flag_line=[]\n",
    "                    else:\n",
    "                        self.flag_line=[]\n",
    "                return id_\n",
    "        else:\n",
    "            self.id_new = self.add_lib(feature,bbox,frame,passage=True)\n",
    "        return self.id_new\n",
    "#*\n",
    "#*      检测集合\n",
    "#*                        \n",
    "    def check_frame_id(self,id_,feature,frame):\n",
    "        list_dis=[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k==id_:\n",
    "                if frame-(v['frame'])>=10:\n",
    "                        if k==id_:\n",
    "                            for lib_ in v['lib']:\n",
    "                                list_dis.append(self.compute_cos(lib_,feature))\n",
    "                            if min(list_dis)<self.dth:\n",
    "                                return True\n",
    "                            else:\n",
    "                                return False\n",
    "                else:\n",
    "                    return True\n",
    "        return False\n",
    "    #检查除id_me外是否与数据库里的bbox重叠\n",
    "    def check_bboxs(self,bbox_list,bbox):    \n",
    "        (xc, yc, wc, hc) =bbox\n",
    "        list_id,list_x=[],[]\n",
    "        ret=True\n",
    "        if len(bbox_list)!=1:\n",
    "        #if (5<(xc-(wc*0.5)) and(xc+(wc*0.5))<(im_w-10)) or (5<(yc-(hc*0.5)) and (yc+(hc*0.5))<(im_h-10)):\n",
    "            for i in range(len(bbox_list)):\n",
    "                for j in range(i+1,len(bbox_list)):\n",
    "                    (xa, ya, wa, ha) = bbox_list[i]\n",
    "                    (xb, yb, wb, hb) = bbox_list[j] \n",
    "                    distance = self.distEclud(xa,ya,xb,yb)\n",
    "                    if (distance/(wa+wb))>=0.5:\n",
    "                        continue\n",
    "                    if (distance/(wa+wb))<0.5:\n",
    "                        if xc==xa or xc==xb:#是不是因为重叠导致的\n",
    "                            ret=False\n",
    "        return ret\n",
    "    def check_lib_add(self,featureVector,min_distance_id,bbox):\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if  k==min_distance_id:\n",
    "                n=v['center']\n",
    "                lib = v['lib']\n",
    "                for lib_ in lib:\n",
    "                    list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "                if len(self.save[min_distance_id]['lib'])>255:\n",
    "                    num = list_dis.index(min(list_dis))\n",
    "                    self.save[min_distance_id]['lib'].pop(num)\n",
    "                    #self.save[min_distance_id]['lib'].pop(0)\n",
    "                if len(list_dis)>0 and np.mean(list_dis)>self.dth:\n",
    "                    self.save[min_distance_id]['lib'].append(featureVector)\n",
    "                    print('\\r%s lib len :%d'%(min_distance_id,len(lib)),end='')\n",
    "                    #跟新kalman bbox\n",
    "                    num=int(k)-1\n",
    "                    self.kalman[num].update(bbox)\n",
    "                break\n",
    "        return len(lib)\n",
    "    #检查就绪的\n",
    "    def check_lib(self,featureVector):\n",
    "        list_id,list_mean=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if k=='000'or v['passage']==False :\n",
    "                continue\n",
    "            lib = v['lib']\n",
    "            for lib_ in lib:\n",
    "                list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "            list_id.append(k)\n",
    "            list_mean.append(min(list_dis)) \n",
    "        if len(list_mean)>0 and min(list_mean) <self.dth:\n",
    "            return list_id[list_mean.index(min(list_mean))] \n",
    "        else:\n",
    "            #print( min(list_mean))\n",
    "            return ' '   \n",
    "    #检查未就绪\n",
    "    def check_lib_passage(self,featureVector):\n",
    "        list_id,list_mean=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if k!='000' and v['passage']==False and len(v['lib'])>10:\n",
    "                lib = v['lib']\n",
    "                for lib_ in lib:\n",
    "                    list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "                list_id.append(k)\n",
    "                list_mean.append(min(list_dis)) \n",
    "        if len(list_mean)>0 and min(list_mean) <self.dth:\n",
    "            return list_id[list_mean.index(min(list_mean))] \n",
    "        else:\n",
    "            #print( min(list_mean))\n",
    "            return ' '    \n",
    "   \n",
    "    #def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "    def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "        #\n",
    "        # * self.notebook 记录发现新的图片的W\n",
    "        # * 保存数据的格式 self.save={'id':{'center':w,'LIB':[w1..wn]}}\n",
    "        #\n",
    "        color=[]\n",
    "        identities=[]\n",
    "        dths=[]\n",
    "        #维护LIB\n",
    "        self.manage_lib(self.frame)\n",
    "        if bbox_list!=[]:\n",
    "            list_id,list_feature,list_distance,list_center=[],[],[],[]\n",
    "            for bbox,c in zip(bbox_list,confidences):\n",
    "                (x, y, w, h) = bbox\n",
    "                (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "                (x,y,w,h)=(x1+x2)*0.5,(y1+y2)*0.5,abs(x1-x2),abs(y1-y2)\n",
    "                im_=im[y1:y2,x1:x2]\n",
    "                im_ = cv2.resize(im_,(64,128))\n",
    "                featureVector = self.compute_feature(im_)\n",
    "                distance=0\n",
    "            #所有图片与LIB中passage为TRUE的计算距离\n",
    "                list_distance_buffer,list_id_buffer,list_feature_buffer,list_center_buffer=[],[],[],[]\n",
    "                for k,v in list(self.save.items()):\n",
    "                    if k=='000':\n",
    "                        continue\n",
    "                    n=v['center']\n",
    "                    if v['passage']==True:\n",
    "                        distance = self.compute_cos(n,featureVector)\n",
    "                        list_distance_buffer.append(distance)\n",
    "                        list_id_buffer.append(k)\n",
    "                        list_feature_buffer.append(featureVector)\n",
    "                        list_center_buffer.append(n) \n",
    "                if len(list_distance_buffer)>0:\n",
    "                    list_distance.append(list_distance_buffer)\n",
    "                    list_id.append(list_id_buffer)\n",
    "                    list_feature.append(list_feature_buffer)\n",
    "                    list_center.append(list_center_buffer)\n",
    "                else:\n",
    "                    id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                    identities.append(id_)\n",
    "                    dths.append(c)\n",
    "                    color.append(0) \n",
    "            #进行匈牙利算法\n",
    "            list_bbox_loss,list_feature_loss=[],[]\n",
    "            if len(list_distance)>0 and len(bbox_list)>0:\n",
    "                    kalman_center,kalman_feature,kalman_id,kalman_bbox=[],[],[],[]\n",
    "                    kalman_bbox=bbox_list\n",
    "                    #需要id的数量要小于等于就绪id的数量\n",
    "                    #print(len(bbox_list),len(list_distance[0]))\n",
    "                    if len(bbox_list)>len(list_distance[0]):\n",
    "                        min_distance=[]\n",
    "                        for id_distanc in list_distance:\n",
    "                            min_distance.append(min(id_distanc))\n",
    "                        #print(min_distance)\n",
    "                        #print((len(list_distance[0])-len(bbox_list)))\n",
    "                        for i in range((len(bbox_list)-len(list_distance[0]))):\n",
    "                            num=min_distance.index(max(min_distance))\n",
    "                            list_distance.pop(num)\n",
    "                            list_id.pop(num)\n",
    "                            list_center.pop(num)  \n",
    "                            list_feature_loss.append(list_feature.pop(num))\n",
    "                            list_bbox_loss.append(kalman_bbox.pop(num))\n",
    "                            #print(list_bbox_loss,list_feature_loss)\n",
    "                            confidences.pop(num)\n",
    "                    np_distance=np.asarray(list_distance)\n",
    "                    #print(np_distance)\n",
    "                    #print(self.save.keys())\n",
    "                    list_Hungary = self.computer_Hungary(np_distance)\n",
    "                    #print(list_Hungary)\n",
    "                    list_id_,list_center_,list_feature_=[],[],[]\n",
    "                    for id_s,center_s,feature_s in zip(list_id,list_center,list_feature):\n",
    "                        for id_,center_,feature_ in zip(id_s,center_s,feature_s):\n",
    "                            list_id_.append(id_)\n",
    "                            list_center_.append(center_)\n",
    "                            list_feature_.append(feature_)\n",
    "                    for number in list_Hungary:\n",
    "                        #number = number*0.00001               \n",
    "                        min_distance = np_distance.flatten().tolist().index(number)\n",
    "                        kalman_id.append(list_id_[min_distance])\n",
    "                        kalman_center.append(list_center_[min_distance])\n",
    "                        kalman_feature.append(list_feature_[min_distance])\n",
    "\n",
    "                    #检查重新回来的id的frame\n",
    "                    #ret_id_frame = self.check_frame_id(min_distance_id,min_distance_feature,self.frame)\n",
    "                    #print(kalman_bbox,kalman_center,kalman_feature,kalman_id,confidences)\n",
    "                    for bbox,conter,feature,id_,c in zip(kalman_bbox,kalman_center,kalman_feature,kalman_id,confidences):\n",
    "                         #检查除id_me外是否与数据库里的bbox重叠\n",
    "                        #print(conter,feature)\n",
    "                        #if distance_<self.dth:\n",
    "                        center_ = (conter*0.5)+(feature*0.5)\n",
    "                        self.save[id_]['center'] =center_\n",
    "                        self.save[id_]['bbox'] =bbox\n",
    "                        self.save[id_]['frame'] =self.frame\n",
    "                        color_ = self.check_lib_add(conter,id_,bbox)\n",
    "                        color.append(color_)\n",
    "                        dths.append(c)\n",
    "                        identities.append(id_)\n",
    "                    #没有ID,重新add_id    \n",
    "                    #print(list_bbox_loss,list_feature_loss,confidences)\n",
    "                    for bbox,featureVector,c in zip(list_bbox_loss,list_feature_loss,confidences):\n",
    "                        #print(bbox,featureVector,c)\n",
    "                        id_ = self.add_id(featureVector[0],bbox,self.frame)\n",
    "                        identities.append(id_)\n",
    "                        dths.append(c)\n",
    "                        color.append(0)  \n",
    "        self.frame+=1\n",
    "        #保存id\n",
    "        self.old_id=identities\n",
    "        return identities,dths,color\n",
    "    #输入图片计算，输出Feature\n",
    "    def compute_feature(self,im):\n",
    "        im_ = im\n",
    "        size=im_.shape\n",
    "        im_ = np.float32(im_)/255.0\n",
    "        Fim = im_.flatten()\n",
    "        Fmean = self.mean.reshape(Fim.shape)\n",
    "        Fdf = Fim-Fmean\n",
    "        Fdf= Fdf.reshape(24576,1)\n",
    "        W=[]\n",
    "        for i in range(len(self.eigenVectors)):\n",
    "            E = self.eigenVectors[i,:].reshape(1,24576)\n",
    "            W.append(np.dot(E,Fdf).flatten())\n",
    "        W = np.asarray(W)\n",
    "        return W\n",
    "    #每一帧图片的ims\n",
    "    def compute_pca(self,ims):\n",
    "        self.classes=['A','B','C','D']\n",
    "        #num=0\n",
    "        #if  self.frame==0:\n",
    "        print('initfeature')\n",
    "        #self.flag==True\n",
    "        featureVector = self.compute_feature(ims[0])\n",
    "        self.testsave[self.classes[0]]=featureVector\n",
    "            #self.frame+=1  \n",
    "        for k,v in self.testsave.items():\n",
    "            list_,list_W,list_w0=[],[],[]\n",
    "            list_mashi1,list_mashi2=[],[]\n",
    "            n = np.asarray(v)\n",
    "            for im in ims:\n",
    "                #im=self.fill_im(im)\n",
    "                #im=cv2.resize(im,(64,128))\n",
    "                featureVector = self.compute_feature(im)\n",
    "                list_W.append(featureVector)\n",
    "                n_ = n.reshape((128,2))\n",
    "                feature_ = featureVector.reshape((128,2))\n",
    "                list_.append(self.compute_Maha(n_,feature_))\n",
    "                #self.frame+=1\n",
    "                n =np.asarray(featureVector)*0.5+n*0.5#根据三比七的比重进行调节\n",
    "                #self.testsave[self.classes[0]]=n\n",
    "                list_w0.append(n)\n",
    "        #print('\\r %d'%self.frame,end ='')\n",
    "        for W in list_W:\n",
    "            self.createNewFace(W,self.frame)\n",
    "            self.frame+=1\n",
    "        return list_ , list_W ,list_w0\n",
    "    def createNewFace(self,W,num):\n",
    "        # Start with the mean image\n",
    "        output = self.mean.reshape(64,128,3)\n",
    "        w=W.tolist()\n",
    "        # Add the eigen faces with the weights\n",
    "        for i in range(0, self.NUM_EIGEN_FACES):\n",
    "            '''\n",
    "            OpenCV does not allow slider values to be negative. \n",
    "            So we use weight = sliderValue - MAX_SLIDER_VALUE / 2\n",
    "            ''' \n",
    "            #sliderValues[i] = cv2.getTrackbarPos(\"Weight\" + str(i), \"Trackbars\");\n",
    "            weight = w[i]\n",
    "            e = self.eigenVectors[i].reshape(64,128,3)\n",
    "            output = np.add(output, e * weight)\n",
    "\n",
    "        # Display Result at 2x size\n",
    "        #output = cv2.resize(output, (0,0), fx=2, fy=2)\n",
    "        output=output*255.0\n",
    "        cv2.imshow(\"Result\", output)\n",
    "        name=('%06d.jpg'%num)\n",
    "        cv2.imwrite('./walkingworkspace/output/'+name,output)\n",
    "        cv2.waitKey(1)\n",
    "    def pca_class_dataset(self,im,name,output_path):\n",
    "        identities = os.path.basename(name)\n",
    "        self.frame+=1\n",
    "        #testimage = self.im_creat(testimage)\n",
    "        im_ = im\n",
    "        #sz = self.images[0].shape\n",
    "        size=im_.shape\n",
    "        im_ = np.float32(im_)/255.0\n",
    "        Fim = im_.flatten()\n",
    "        Fmean = self.mean.reshape(Fim.shape)\n",
    "        Fdf = Fim-Fmean\n",
    "        Fdf= Fdf.reshape(24576,1)\n",
    "        W=[]\n",
    "        for i in range(len(self.eigenVectors)):\n",
    "            E = self.eigenVectors[i,:].reshape(1,24576)\n",
    "            #print(self.eigenVectors[i,:].reshape(1,24576).T.shape)\n",
    "            W.append(np.dot(E,Fdf).flatten())\n",
    "        W = np.asarray(W)\n",
    "        #print(W)\n",
    "        #cv2.imshow('build',build[0:])\n",
    "        name = ('/%s'%identities)\n",
    "        name = name.replace('jpg','npy')\n",
    "        np.save(output_path+name,W)\n",
    "        #cv2.imwrite(name+'.jpg',im)\n",
    "        cv2.waitKey(1)\n",
    "    def test_add_lib(self,im_,id_):\n",
    "        list_distance,list_feature=[],[]\n",
    "        featureVector = self.compute_feature(im_)\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k=='000'and  k!=id_:\n",
    "                continue\n",
    "            if v['passage']==True:\n",
    "                n=v['center']\n",
    "                distance = self.compute_cos(n,featureVector)\n",
    "                if distance <self.dth:\n",
    "                    list_distance.append(distance)\n",
    "                    list_feature.append(featureVector)\n",
    "        if len(list_distance)!=0:\n",
    "                min_distance_feature = list_feature[list_distance.index(min(list_distance))]\n",
    "                center = (min_distance_feature*0.5)+(featureVector*0.5)\n",
    "                self.save[id_]['center'] =center\n",
    "                self.check_lib_add(min_distance_feature,id_,bbox)\n",
    "                                        \n",
    "    def test(self,path):\n",
    "        list_val1,list_val2,list_test1,list_test2,list_test1_loss,list_test2_loss=[],[],[],[],[],[]\n",
    "        for name in glob.glob(path+'/*'):\n",
    "            if name.find('xia001')!=-1:\n",
    "                for im_name1 in glob.glob(name+'/*.jpg'):\n",
    "                    list_val1.append(cv2.imread(im_name1))\n",
    "            if name.find('li002')!=-1:\n",
    "                for im_name2 in glob.glob(name+'/*.jpg'):\n",
    "                    list_val2.append(cv2.imread(im_name2))\n",
    "                    \n",
    "        featureVector = self.compute_feature(list_val1[0])\n",
    "        self.add_lib(featureVector,[],1,passage=True)\n",
    "        featureVector = self.compute_feature(list_val2[0])\n",
    "        self.add_lib(featureVector,[],1,passage=True)\n",
    "        for im_ in list_val1:\n",
    "            cv2.imshow('in',im_)\n",
    "            self.test_add_lib(im_,'001')\n",
    "            self.kalman.append(KalmanFilter())\n",
    "            cv2.waitKey(1)\n",
    "        for im_ in list_val2:\n",
    "            cv2.imshow('in',im_)\n",
    "            self.test_add_lib(im_,'002') \n",
    "            self.kalman.append(KalmanFilter())\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "        center =self.save['001']['lib'][0]\n",
    "        for lib_ in self.save['001']['lib']:\n",
    "            center=center*0.5+lib_*0.5\n",
    "        #self.save[k]['lib'].pop(0)\n",
    "        self.passage_off('001',center)\n",
    "        \n",
    "        center =self.save['002']['lib'][0]\n",
    "        for lib_ in self.save['002']['lib']:\n",
    "            center=center*0.5+lib_*0.5\n",
    "        #self.save[k]['lib'].pop(0)\n",
    "        self.passage_off('002',center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efficientdet + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from ./walkingworkspace/train2020...1982 files read.\n"
     ]
    }
   ],
   "source": [
    "HumanMaxNumber=4\n",
    "size=(640,480)\n",
    "E = efficientdet(0 ,640,HumanMaxNumber,dir_path='./walkingworkspace/train2020',NUM_EIGEN_FACES = 256,test=False)\n",
    "#E = efficientdet(0 ,512,HumanMaxNumber,dir_path='./datasets/multi-query',NUM_EIGEN_FACES = 256)\n",
    "#从新构建models\n",
    "#E.init_PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2608.0\n",
      "find id 001\n",
      "001 lib len :178find id 002\n",
      "001 lib len :184find id 003\n",
      "001 lib len :188003 passage is True\n",
      "the id 002 Remove\n",
      "001 lib len :256find id 004\n",
      "001 lib len :256the id 004 Remove\n",
      "001 lib len :256001 passage is False\n",
      "001 passage is True\n",
      "001 lib len :257001 passage is False\n",
      "003 lib len :44001 passage is True\n",
      "003 lib len :478001 passage is False\n",
      "001 passage is True\n",
      "001 lib len :259find id 004\n",
      "001 lib len :259the id 004 Remove\n",
      "001 lib len :259001 passage is False\n",
      "003 lib len :105001 passage is True\n",
      "001 lib len :256find id 004\n",
      "001 lib len :256the id 004 Remove\n",
      "001 lib len :256find id 004\n",
      "001 lib len :256the id 004 Remove\n",
      "003 lib len :256001 passage is False\n",
      "003 lib len :256find id 004\n",
      "003 lib len :256find id 005\n",
      "003 lib len :256001 passage is True\n",
      "001 lib len :257the id 004 Remove\n",
      "003 lib len :256the id 005 Remove\n",
      "003 lib len :256001 passage is False\n",
      "003 lib len :256003 passage is False\n"
     ]
    }
   ],
   "source": [
    "E.init_video()\n",
    "#videopath='./testvideo/liandxia.mp4'\n",
    "#videopath='./testvideo/two_rotation.mp4'\n",
    "videopath='./testvideo/test004.mp4'\n",
    "#videopath='./walkingvideo/two_rotationwalking.mp4'\n",
    "#videopath=0\n",
    "video = cv2.VideoCapture(videopath)\n",
    "video_fps = video.get(7)\n",
    "print(video_fps)\n",
    "num=0\n",
    "for i in range(int(video_fps-1)):\n",
    "#t=time.time()\n",
    "\n",
    "#while True:\n",
    "#    if (time.time()-t)>=5:\n",
    "#        if (time.time()-t)>=300:\n",
    "#            break \n",
    "        ret,im = video.read()\n",
    "        #im_=cv2.flip(im,0)\n",
    "        if ret:\n",
    "            if num%1==0:\n",
    "                E.detector(cv2.resize(im,size))\n",
    "        num+=1\n",
    "cv2.destroyAllWindows() \n",
    "E.out.release()\n",
    "video.release()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCATEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from ./walkingworkspace/train2020...1982 files read.\n",
      "find id 001\n",
      "find id 002\n",
      "002 lib len :256001 passage is False\n",
      "002 passage is False\n",
      "335.0\n",
      "find id 003\n",
      "find id 004\n",
      "003 lib len :14find id 005\n",
      "003 passage is False\n",
      "004 lib len :5the id 005 Remove\n",
      "004 lib len :10002 passage is True\n",
      "004 lib len :517find id 005\n",
      "find id 006\n",
      "002 passage is False\n",
      "004 passage is False\n",
      "002 passage is True\n",
      "002 lib len :258the id 005 Remove\n",
      "002 lib len :258the id 006 Remove\n",
      "find id 005\n",
      "002 passage is False\n",
      "find id 006\n",
      "find id 007\n",
      "the id 005 Remove\n",
      "find id 008\n",
      "the id 006 Remove\n",
      "the id 007 Remove\n",
      "the id 008 Remove\n",
      "001 passage is True\n",
      "001 lib len :257002 passage is True\n",
      "002 lib len :259001 passage is False\n",
      "002 passage is False\n",
      "001 passage is True\n",
      "001 lib len :258002 passage is True\n",
      "002 lib len :260001 passage is False\n",
      "002 lib len :260004 passage is True\n",
      "002 lib len :260"
     ]
    }
   ],
   "source": [
    "HumanMaxNumber=4\n",
    "size=(640,480)\n",
    "E = efficientdet(0 ,640,HumanMaxNumber,dir_path='./walkingworkspace/train2020',NUM_EIGEN_FACES = 256,test=True)\n",
    "#E.init_video()\n",
    "videopath='./testvideo/test_kelman.mp4'\n",
    "#videopath=0\n",
    "video = cv2.VideoCapture(videopath)\n",
    "video_fps = video.get(7)\n",
    "print(video_fps)\n",
    "num=0\n",
    "for i in range(int(video_fps-1)):\n",
    "#t=time.time()\n",
    "#while True:\n",
    "#    if (time.time()-t)>=5:\n",
    "#        if (time.time()-t)>=300:\n",
    "#            break \n",
    "        ret,im = video.read()\n",
    "        #im_=cv2.flip(im,0)\n",
    "        if ret:\n",
    "            if num%1==0:\n",
    "                E.detector(cv2.resize(im,size))\n",
    "        num+=1\n",
    "cv2.destroyAllWindows() \n",
    "E.out.release()\n",
    "video.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [['002', '001'], [[375.0, 323.0, 66, 248], [262.5, 317.0, 59, 254]]], 1: [['002', '001'], [[375.5, 323.0, 65, 250], [263.0, 318.0, 56, 258]]], 2: [['002', '001'], [[376.5, 323.5, 65, 251], [262.0, 318.0, 58, 258]]], 3: [['002', '001'], [[377.0, 323.5, 64, 251], [261.5, 317.0, 57, 258]]], 4: [['002', '001'], [[377.0, 324.0, 62, 252], [260.5, 316.0, 59, 254]]], 5: [['002', '001'], [[377.0, 324.5, 62, 255], [260.0, 316.0, 60, 254]]], 6: [['002', '001'], [[377.5, 326.0, 61, 258], [260.0, 316.0, 60, 254]]], 7: [['002', '001'], [[378.0, 328.0, 62, 262], [260.0, 315.5, 60, 253]]], 8: [['002', '001'], [[378.0, 328.5, 62, 263], [260.0, 316.0, 60, 252]]], 9: [['002', '001'], [[378.0, 328.5, 62, 263], [259.5, 316.5, 59, 253]]], 10: [['002', '001'], [[378.0, 327.5, 62, 263], [259.5, 317.0, 59, 254]]], 11: [['002', '001'], [[377.5, 327.0, 63, 260], [259.0, 317.5, 58, 253]]], 12: [['002', '001'], [[377.5, 326.5, 65, 259], [259.0, 318.0, 58, 254]]], 13: [['002', '001'], [[377.0, 325.5, 64, 259], [259.0, 318.0, 58, 256]]], 14: [['002', '001'], [[377.0, 325.5, 62, 259], [259.0, 318.0, 58, 258]]], 15: [['002', '001'], [[377.0, 325.5, 62, 259], [259.0, 317.5, 58, 259]]], 16: [['002', '001'], [[377.0, 325.0, 62, 258], [259.0, 317.5, 58, 259]]], 17: [['002', '001'], [[377.0, 324.5, 64, 257], [259.5, 317.0, 57, 260]]], 18: [['002', '001'], [[377.5, 324.5, 65, 257], [259.5, 317.0, 57, 260]]], 19: [['002', '001'], [[377.0, 324.5, 68, 257], [260.5, 316.5, 57, 261]]], 20: [['002', '001'], [[376.0, 325.0, 72, 258], [260.5, 316.5, 57, 261]]], 21: [['002', '001'], [[375.5, 325.0, 75, 256], [261.0, 316.5, 56, 263]]], 22: [['002', '001'], [[375.0, 325.0, 76, 256], [261.0, 317.0, 56, 262]]], 23: [['002', '001'], [[374.0, 325.5, 76, 255], [261.5, 317.5, 55, 263]]], 24: [['002', '001'], [[375.0, 325.0, 72, 254], [261.5, 317.5, 55, 263]]], 25: [['002', '001'], [[375.0, 325.0, 64, 254], [261.0, 318.0, 56, 262]]], 26: [['002', '001'], [[375.5, 327.0, 57, 256], [261.0, 319.0, 56, 258]]], 27: [['001', '002'], [[260.0, 319.5, 58, 257], [377.0, 326.0, 54, 250]]], 28: [['001', '002'], [[259.0, 319.5, 60, 255], [378.0, 326.5, 54, 253]]], 29: [['001', '002'], [[258.5, 320.5, 61, 255], [376.5, 325.5, 55, 251]]], 30: [['001', '002'], [[258.5, 321.5, 61, 257], [374.0, 326.5, 58, 253]]], 31: [['001', '002'], [[260.5, 319.5, 59, 261], [372.0, 325.5, 60, 243]]], 32: [['001', '002'], [[260.5, 320.0, 59, 260], [370.5, 326.5, 63, 241]]], 33: [['002', '001'], [[369.5, 326.0, 65, 242], [260.5, 320.5, 59, 261]]], 34: [['002', '001'], [[367.5, 327.0, 67, 244], [260.5, 320.5, 59, 261]]], 35: [['002', '001'], [[365.5, 327.5, 69, 245], [260.5, 320.5, 59, 263]]], 36: [['002', '001'], [[365.0, 327.5, 68, 245], [260.5, 321.0, 59, 264]]], 37: [['002', '001'], [[364.0, 327.5, 66, 249], [259.0, 320.5, 62, 263]]], 38: [['001', '002'], [[260.0, 320.0, 62, 264], [364.0, 326.5, 62, 253]]], 39: [['001', '002'], [[261.5, 319.5, 63, 263], [366.0, 324.0, 62, 246]]], 40: [['001', '002'], [[263.0, 319.5, 64, 263], [366.5, 320.5, 61, 239]]], 41: [['001', '002'], [[263.0, 320.0, 68, 262], [366.0, 321.0, 56, 236]]], 42: [['001'], [[263.5, 321.5, 71, 261]]], 43: [['001', '002'], [[265.0, 322.5, 74, 261], [361.0, 323.0, 52, 230]]], 44: [['001', '002'], [[266.5, 323.0, 81, 260], [360.0, 319.5, 50, 233]]], 45: [['001', '002'], [[267.0, 324.0, 82, 264], [359.5, 319.5, 53, 217]]], 46: [['001', '002'], [[269.0, 327.0, 84, 268], [357.0, 321.0, 58, 224]]], 47: [['001', '002'], [[270.5, 329.0, 87, 270], [356.0, 318.5, 64, 225]]], 48: [['001', '002'], [[272.0, 330.5, 86, 269], [351.5, 319.0, 73, 226]]], 49: [[' ', ' '], [[273.0, 330.0, 84, 268], [350.0, 320.0, 78, 230]]], 50: [[' ', ' '], [[275.0, 330.0, 86, 268], [350.5, 321.0, 79, 230]]], 51: [[' ', ' '], [[277.0, 329.5, 86, 265], [350.5, 321.5, 79, 231]]], 52: [[' ', ' '], [[280.5, 337.0, 81, 254], [347.0, 318.0, 72, 214]]], 53: [[' ', ' '], [[300.5, 323.5, 75, 265], [344.5, 318.5, 65, 211]]], 54: [['001'], [[326.5, 323.5, 89, 263]]], 55: [['003'], [[321.5, 327.5, 89, 285]]], 56: [['001'], [[320.0, 329.0, 80, 292]]], 57: [['001'], [[313.0, 327.5, 72, 287]]], 58: [['001'], [[315.5, 327.5, 75, 283]]], 59: [[' '], [[321.0, 331.0, 86, 286]]], 60: [[' '], [[326.0, 329.0, 96, 284]]], 61: [[' '], [[331.5, 333.0, 109, 278]]], 62: [[' '], [[334.5, 333.5, 117, 281]]], 63: [[' '], [[334.5, 333.0, 115, 284]]], 64: [['001'], [[334.5, 332.5, 113, 281]]], 65: [['001'], [[334.5, 331.5, 105, 283]]], 66: [['001'], [[338.5, 332.5, 99, 287]]], 67: [[' ', ' '], [[344.0, 332.0, 96, 284], [298.0, 308.5, 58, 211]]], 68: [[' ', ' '], [[353.0, 330.0, 90, 290], [298.5, 311.5, 57, 213]]], 69: [[' ', ' '], [[359.5, 329.5, 79, 291], [296.5, 312.0, 51, 208]]], 70: [[' ', ' '], [[366.5, 330.5, 75, 291], [292.0, 310.0, 52, 224]]], 71: [[' ', ' '], [[375.5, 336.5, 63, 303], [284.5, 305.0, 59, 216]]], 72: [['001', '002'], [[379.0, 332.0, 70, 296], [282.0, 305.5, 68, 215]]], 73: [['001', '002'], [[380.0, 332.5, 74, 293], [282.0, 305.5, 72, 213]]], 74: [['001', '002'], [[379.5, 332.5, 77, 291], [281.0, 306.0, 78, 214]]], 75: [['001', '002'], [[379.5, 333.0, 83, 290], [279.5, 307.0, 83, 216]]], 76: [['001', '002'], [[380.0, 333.0, 88, 288], [278.5, 308.5, 85, 221]]], 77: [['001', '002'], [[383.0, 329.5, 88, 285], [278.0, 311.5, 86, 221]]], 78: [['001', '002'], [[384.0, 330.0, 88, 284], [276.0, 314.0, 82, 222]]], 79: [['001', '003'], [[386.5, 329.5, 85, 283], [274.0, 315.0, 80, 222]]], 80: [['001', '004'], [[385.0, 332.5, 82, 283], [271.5, 316.5, 77, 223]]], 81: [['001', '002'], [[387.0, 331.0, 76, 282], [267.5, 315.0, 71, 222]]], 82: [['001', '002'], [[390.0, 332.0, 74, 282], [264.0, 315.5, 66, 227]]], 83: [['001', '002'], [[392.5, 333.0, 69, 278], [261.0, 314.0, 64, 230]]], 84: [['001', '002'], [[393.5, 330.0, 67, 272], [259.0, 313.5, 64, 233]]], 85: [['001', '002'], [[395.0, 333.5, 66, 277], [257.5, 312.5, 63, 235]]], 86: [['001', '002'], [[396.5, 332.5, 65, 277], [257.0, 311.5, 62, 233]]], 87: [['001', '002'], [[398.0, 331.5, 64, 275], [256.5, 309.5, 67, 233]]], 88: [['001', '002'], [[398.0, 330.5, 66, 273], [255.5, 309.5, 71, 229]]], 89: [['001', '002'], [[398.0, 330.0, 66, 272], [254.0, 310.0, 74, 230]]], 90: [['002', '001'], [[253.5, 311.0, 77, 234], [398.5, 330.0, 65, 270]]], 91: [['002', '001'], [[252.0, 313.0, 76, 238], [398.5, 330.0, 65, 270]]], 92: [['002', '001'], [[252.0, 314.5, 76, 239], [396.5, 330.5, 65, 269]]], 93: [['001', '002'], [[394.5, 330.0, 67, 266], [250.0, 315.0, 74, 240]]], 94: [['001', '002'], [[393.0, 330.5, 68, 263], [249.5, 315.5, 73, 241]]], 95: [['001', '002'], [[392.0, 331.0, 68, 262], [247.0, 318.5, 70, 245]]], 96: [['001', '002'], [[391.0, 331.0, 68, 264], [246.0, 318.5, 70, 245]]], 97: [['001', '002'], [[390.5, 331.0, 67, 262], [246.5, 317.5, 69, 245]]], 98: [['002', '001'], [[247.0, 317.0, 68, 246], [391.0, 330.5, 64, 259]]], 99: [['002', '001'], [[247.5, 317.0, 65, 250], [392.0, 329.5, 60, 261]]], 100: [['002', '001'], [[245.5, 318.0, 63, 252], [393.5, 330.0, 57, 258]]], 101: [['002', '001'], [[244.5, 317.5, 61, 253], [397.0, 329.0, 54, 256]]], 102: [['002', '001'], [[245.0, 316.5, 62, 251], [398.5, 327.5, 53, 251]]], 103: [['002', '001'], [[245.0, 316.0, 64, 250], [396.5, 324.5, 53, 247]]], 104: [['002', '001'], [[245.0, 315.5, 64, 251], [393.0, 322.5, 52, 241]]], 105: [['002', '001'], [[246.0, 316.5, 66, 251], [392.5, 325.0, 51, 242]]], 106: [['002', '001'], [[246.5, 317.5, 67, 253], [392.5, 331.5, 51, 205]]], 107: [['002', '001'], [[246.5, 316.5, 69, 253], [392.5, 327.0, 53, 208]]], 108: [['002', '001'], [[248.5, 320.5, 71, 255], [391.0, 319.5, 54, 233]]], 109: [['002', '001'], [[250.0, 321.0, 72, 254], [390.0, 318.5, 56, 233]]], 110: [['002', '001'], [[250.5, 322.0, 73, 254], [388.5, 318.5, 59, 233]]], 111: [['002', '001'], [[250.5, 321.5, 73, 255], [386.5, 318.0, 63, 232]]], 112: [['002', '001'], [[250.0, 321.5, 72, 259], [381.5, 317.5, 61, 227]]], 113: [['002', '001'], [[252.5, 321.5, 71, 261], [379.5, 316.5, 61, 227]]], 114: [['002', '001'], [[258.5, 319.0, 71, 260], [379.5, 315.0, 59, 226]]], 115: [['002', '001'], [[266.5, 321.0, 63, 262], [379.0, 318.0, 58, 220]]], 116: [['002', '001'], [[272.0, 321.0, 64, 262], [378.0, 318.0, 58, 228]]], 117: [['003', '001'], [[275.5, 320.5, 73, 259], [375.5, 317.0, 59, 228]]], 118: [['004', '001'], [[277.0, 321.0, 78, 260], [372.5, 318.0, 59, 226]]], 119: [['005', '001'], [[279.0, 318.5, 84, 259], [370.5, 318.0, 57, 226]]], 120: [['006', '001'], [[282.5, 319.5, 87, 259], [368.0, 316.5, 58, 227]]], 121: [['007', '001'], [[285.5, 321.0, 89, 264], [362.5, 314.0, 53, 218]]], 122: [['008', '001'], [[287.5, 324.5, 87, 265], [358.5, 312.0, 53, 212]]], 123: [['001'], [[288.0, 326.0, 92, 272]]], 124: [['001'], [[292.5, 328.5, 97, 275]]], 125: [[' '], [[297.0, 328.0, 102, 276]]], 126: [[' ', ' '], [[298.0, 333.0, 88, 276], [343.0, 313.5, 52, 235]]], 127: [[' '], [[299.0, 332.0, 88, 274]]], 128: [[' '], [[306.5, 331.5, 83, 273]]], 129: [[' '], [[314.0, 330.5, 86, 277]]], 130: [['003'], [[320.5, 325.0, 89, 276]]], 131: [['002'], [[324.0, 325.0, 86, 280]]], 132: [['001'], [[325.0, 326.0, 84, 278]]], 133: [['002'], [[328.0, 326.0, 86, 280]]], 134: [[' '], [[334.0, 329.5, 88, 285]]], 135: [[' '], [[335.5, 330.5, 91, 283]]], 136: [[' '], [[337.0, 330.5, 96, 283]]], 137: [[' '], [[339.0, 331.5, 102, 285]]], 138: [[' '], [[341.0, 332.5, 104, 285]]], 139: [['001'], [[340.5, 330.5, 103, 277]]], 140: [['001'], [[343.0, 330.5, 100, 275]]], 141: [['003'], [[342.5, 328.5, 97, 281]]], 142: [[' ', ' '], [[344.0, 327.0, 94, 280], [295.5, 308.0, 57, 224]]], 143: [[' ', ' '], [[344.5, 328.0, 83, 276], [292.5, 310.0, 63, 228]]], 144: [['002', '001'], [[357.5, 332.0, 65, 284], [290.5, 314.5, 69, 231]]], 145: [['001', '002'], [[286.5, 315.0, 73, 230], [362.0, 332.5, 58, 285]]], 146: [['001', '002'], [[287.5, 313.0, 81, 228], [364.0, 331.5, 58, 285]]], 147: [['001', '002'], [[285.5, 312.0, 81, 224], [365.5, 330.5, 57, 281]]], 148: [['001', '002'], [[283.5, 311.5, 83, 225], [367.0, 329.0, 58, 278]]], 149: [['001', '002'], [[281.5, 313.5, 81, 225], [369.5, 330.0, 59, 274]]], 150: [['001', '002'], [[279.5, 315.0, 77, 226], [372.5, 330.5, 61, 271]]], 151: [['001', '002'], [[277.5, 316.5, 75, 227], [375.5, 329.0, 63, 264]]], 152: [['001', '001'], [[382.5, 328.5, 77, 267], [275.5, 317.0, 71, 228]]], 153: [['001', '001'], [[384.0, 330.0, 78, 264], [272.5, 317.0, 65, 230]]], 154: [['001', '001'], [[385.5, 330.5, 75, 261], [269.5, 317.5, 63, 231]]], 155: [['002', '001'], [[385.5, 330.5, 71, 261], [268.5, 316.5, 61, 237]]], 156: [['002', '001'], [[386.0, 330.5, 68, 261], [267.0, 315.0, 58, 242]]], 157: [['002', '001'], [[388.0, 330.0, 66, 260], [266.5, 310.5, 53, 223]]], 158: [['002', '001'], [[389.5, 329.0, 67, 258], [264.5, 310.5, 53, 225]]], 159: [['002', '001'], [[391.0, 329.5, 66, 259], [262.0, 311.0, 54, 226]]], 160: [['002', '001'], [[390.5, 328.5, 67, 255], [260.0, 307.5, 54, 233]]], 161: [['002', '001'], [[390.5, 328.5, 69, 255], [257.5, 313.0, 55, 244]]], 162: [['002', '001'], [[390.5, 328.5, 73, 253], [253.5, 309.5, 57, 243]]], 163: [['002', '001'], [[390.5, 328.5, 75, 255], [250.0, 312.5, 60, 237]]], 164: [['002', '001'], [[390.5, 328.5, 77, 253], [245.5, 313.0, 63, 238]]], 165: [['002', '001'], [[391.0, 328.5, 76, 251], [243.0, 313.0, 66, 240]]], 166: [['002', '001'], [[391.5, 328.5, 73, 249], [241.5, 315.0, 67, 244]]], 167: [['002', '001'], [[392.0, 328.5, 70, 249], [240.0, 315.5, 68, 245]]], 168: [['001', '002'], [[238.5, 316.0, 69, 246], [392.0, 329.0, 66, 250]]], 169: [['001', '002'], [[237.5, 316.5, 67, 247], [392.0, 329.5, 64, 251]]], 170: [['001', '001'], [[237.0, 316.0, 64, 248], [392.0, 329.5, 62, 251]]], 171: [['001', '001'], [[236.0, 316.0, 64, 248], [392.5, 329.0, 59, 250]]], 172: [['001', '002'], [[234.5, 315.0, 65, 248], [391.0, 328.0, 56, 244]]], 173: [['001', '002'], [[233.5, 315.0, 67, 248], [391.5, 327.0, 55, 240]]], 174: [['001', '001'], [[234.0, 315.0, 70, 248], [393.0, 323.5, 54, 239]]], 175: [['001', '001'], [[234.0, 314.0, 70, 248], [392.5, 322.0, 53, 236]]], 176: [['001', '001'], [[233.5, 313.5, 67, 249], [392.0, 323.5, 52, 241]]], 177: [['001', '002'], [[233.0, 313.5, 64, 251], [391.5, 322.5, 53, 241]]], 178: [['001', '002'], [[232.5, 313.5, 63, 253], [390.0, 322.0, 56, 230]]], 179: [['001', '002'], [[232.0, 314.0, 60, 254], [389.5, 321.0, 57, 230]]], 180: [['001', '002'], [[232.5, 314.5, 59, 255], [389.0, 320.5, 58, 231]]], 181: [['001', '002'], [[232.5, 315.0, 59, 256], [386.5, 320.5, 59, 231]]], 182: [['001', '002'], [[233.0, 314.5, 62, 253], [381.0, 317.5, 60, 239]]], 183: [['001', '002'], [[233.5, 315.0, 63, 252], [380.0, 319.0, 58, 232]]], 184: [['001', '002'], [[234.5, 315.0, 65, 250], [378.0, 318.5, 58, 231]]], 185: [['001', '002'], [[235.0, 316.0, 68, 248], [377.0, 318.5, 58, 231]]], 186: [['001', '002'], [[237.0, 316.5, 72, 249], [375.5, 318.0, 57, 228]]], 187: [['001', '002'], [[238.0, 317.0, 76, 250], [374.5, 317.0, 57, 224]]], 188: [['001', '002'], [[239.0, 317.5, 78, 251], [373.0, 316.0, 56, 224]]], 189: [['001', '002'], [[239.5, 318.5, 79, 251], [372.0, 316.0, 54, 226]]], 190: [['001', '002'], [[239.5, 318.5, 81, 253], [371.0, 316.0, 52, 224]]], 191: [['001'], [[239.5, 317.5, 83, 247]]], 192: [['001'], [[241.0, 319.5, 82, 253]]], 193: [[' ', ' '], [[242.0, 320.5, 82, 253], [369.5, 313.5, 49, 217]]], 194: [['002', ' '], [[244.5, 323.0, 75, 250], [363.5, 311.0, 51, 218]]], 195: [[' ', ' '], [[247.0, 323.5, 70, 251], [362.0, 312.5, 54, 221]]], 196: [[' ', ' '], [[253.5, 320.5, 69, 259], [361.0, 312.0, 60, 220]]], 197: [[' ', ' '], [[263.0, 317.5, 66, 261], [360.0, 311.5, 64, 219]]], 198: [['001', '002'], [[272.0, 322.0, 64, 260], [357.0, 312.5, 70, 211]]], 199: [['001', '002'], [[276.5, 324.5, 67, 267], [357.0, 314.0, 74, 210]]], 200: [['001', '002'], [[278.5, 324.0, 67, 266], [355.5, 313.0, 77, 208]]], 201: [[' ', ' '], [[279.5, 323.0, 71, 260], [353.5, 314.0, 81, 210]]], 202: [[' ', ' '], [[281.5, 324.0, 73, 262], [352.5, 314.0, 83, 212]]], 203: [[' ', ' '], [[285.5, 320.0, 81, 256], [352.5, 315.0, 79, 212]]], 204: [[' ', ' '], [[287.0, 320.0, 88, 258], [346.5, 314.5, 79, 221]]], 205: [[' ', ' '], [[288.5, 321.5, 91, 257], [353.5, 314.0, 73, 210]]], 206: [[' ', ' '], [[290.5, 323.5, 101, 259], [346.5, 312.0, 67, 204]]], 207: [[' ', ' '], [[294.0, 324.0, 108, 258], [344.0, 309.5, 56, 201]]], 208: [['001'], [[297.0, 326.0, 110, 258]]], 209: [['001'], [[299.5, 329.0, 107, 256]]], 210: [['001'], [[302.0, 330.0, 108, 264]]], 211: [['001'], [[302.5, 327.5, 103, 265]]], 212: [['001'], [[305.0, 326.5, 98, 265]]], 213: [[' '], [[307.0, 327.0, 90, 264]]], 214: [[' '], [[310.0, 327.5, 82, 265]]], 215: [[' '], [[314.5, 327.0, 79, 264]]], 216: [[' '], [[317.0, 328.5, 78, 263]]], 217: [[' '], [[320.0, 325.0, 84, 262]]], 218: [['001'], [[322.0, 325.0, 90, 262]]], 219: [['001'], [[328.5, 325.0, 91, 260]]], 220: [[' ', ' '], [[305.0, 326.0, 80, 248], [353.5, 317.5, 67, 255]]], 221: [[' ', ' '], [[352.5, 323.0, 77, 266], [298.5, 307.0, 65, 210]]], 222: [[' ', ' '], [[353.5, 325.5, 79, 267], [298.5, 308.5, 67, 209]]], 223: [[' ', ' '], [[354.0, 326.0, 84, 264], [297.5, 308.5, 63, 207]]], 224: [[' ', ' '], [[356.0, 328.5, 86, 269], [297.5, 312.0, 59, 202]]], 225: [[' ', ' '], [[360.0, 328.5, 84, 269], [294.0, 310.5, 56, 205]]], 226: [['001', '002'], [[362.5, 329.5, 81, 267], [286.0, 307.0, 56, 216]]], 227: [['001', '002'], [[365.0, 330.5, 78, 265], [283.5, 307.0, 61, 218]]], 228: [['001', '002'], [[367.5, 331.0, 75, 262], [283.5, 307.5, 67, 213]]], 229: [['001', '002'], [[369.5, 331.0, 73, 260], [281.0, 309.0, 76, 216]]], 230: [['001', '002'], [[372.0, 330.5, 70, 259], [279.5, 309.5, 83, 215]]], 231: [['002', '001'], [[276.5, 313.0, 87, 222], [375.5, 331.5, 67, 265]]], 232: [['002', '001'], [[274.5, 314.0, 89, 222], [377.0, 329.0, 64, 262]]], 233: [['002', '001'], [[272.0, 314.5, 90, 223], [378.5, 325.0, 61, 258]]], 234: [['002', '001'], [[268.5, 314.5, 89, 223], [385.0, 325.0, 68, 260]]], 235: [['002', '001'], [[267.0, 315.0, 90, 224], [386.5, 323.0, 69, 258]]], 236: [['002', '001'], [[264.5, 314.5, 87, 223], [388.0, 325.5, 66, 257]]], 237: [['002', '001'], [[260.0, 314.5, 84, 225], [388.5, 324.0, 65, 256]]], 238: [['002', '001'], [[257.0, 313.5, 80, 225], [389.5, 322.5, 65, 253]]], 239: [['002', '001'], [[256.5, 313.0, 77, 224], [390.0, 322.0, 66, 250]]], 240: [['002', '001'], [[256.0, 311.5, 74, 225], [394.0, 322.0, 66, 250]]], 241: [['001', '002'], [[399.5, 323.0, 67, 248], [255.5, 309.0, 69, 224]]], 242: [['001', '002'], [[401.0, 322.0, 70, 246], [253.0, 310.0, 66, 230]]], 243: [['001', '002'], [[399.0, 322.5, 66, 243], [252.5, 310.5, 63, 231]]], 244: [['001', '002'], [[397.0, 323.5, 68, 243], [251.0, 311.0, 62, 228]]], 245: [['001', '002'], [[396.0, 323.0, 70, 244], [248.0, 316.5, 62, 223]]], 246: [['001', '002'], [[396.0, 322.5, 70, 245], [245.0, 316.0, 66, 224]]], 247: [['001', '002'], [[397.5, 323.5, 69, 243], [244.5, 316.0, 65, 224]]], 248: [['001', '002'], [[401.5, 323.0, 67, 244], [244.0, 316.0, 64, 222]]], 249: [['001', '002'], [[404.5, 322.5, 67, 243], [243.5, 316.0, 63, 224]]], 250: [['001', '002'], [[405.5, 324.0, 65, 244], [243.5, 314.5, 61, 225]]], 251: [['001', '002'], [[405.5, 324.0, 63, 246], [244.0, 313.5, 62, 225]]], 252: [['001', '002'], [[404.5, 325.0, 61, 248], [245.5, 312.5, 61, 225]]], 253: [['001', '002'], [[405.0, 326.5, 60, 247], [246.5, 312.0, 61, 224]]], 254: [['001', '002'], [[406.5, 328.5, 59, 247], [247.5, 311.5, 61, 225]]], 255: [['001', '002'], [[407.0, 328.5, 58, 247], [248.0, 311.0, 62, 224]]], 256: [['001', '002'], [[407.0, 329.5, 58, 261], [248.0, 311.5, 64, 223]]], 257: [['001', '002'], [[408.5, 329.5, 59, 261], [248.5, 311.0, 65, 222]]], 258: [['001', '002'], [[409.5, 329.5, 61, 261], [248.0, 311.0, 66, 222]]], 259: [['001', '002'], [[410.0, 328.5, 62, 259], [248.0, 312.0, 66, 222]]], 260: [['001', '002'], [[410.0, 329.0, 64, 260], [247.0, 313.0, 66, 222]]], 261: [['001', '001'], [[410.0, 329.5, 64, 261], [246.5, 314.5, 65, 223]]], 262: [['001', '001'], [[409.0, 330.0, 62, 260], [246.0, 315.0, 64, 224]]], 263: [['001', '001'], [[406.5, 329.0, 61, 260], [245.0, 316.0, 62, 226]]], 264: [['001', '001'], [[403.5, 329.5, 59, 263], [248.0, 307.0, 56, 214]]], 265: [['001', '001'], [[400.5, 329.0, 57, 264], [249.5, 308.0, 53, 216]]], 266: [['001', '002'], [[398.0, 328.0, 56, 264], [251.5, 309.0, 51, 218]]], 267: [['001', '002'], [[395.5, 326.5, 55, 257], [252.5, 310.5, 49, 221]]], 268: [['001', '002'], [[395.5, 325.5, 55, 253], [254.5, 309.0, 53, 216]]], 269: [['001', '002'], [[394.0, 324.5, 56, 251], [258.0, 307.0, 58, 218]]], 270: [['001', '002'], [[391.5, 325.5, 59, 249], [258.0, 307.0, 64, 216]]], 271: [['001', '002'], [[388.0, 324.5, 66, 245], [260.5, 307.0, 71, 216]]], 272: [['001', '002'], [[377.0, 317.5, 72, 249], [260.0, 311.5, 76, 211]]], 273: [['001', '002'], [[371.0, 320.5, 88, 245], [262.0, 312.5, 78, 211]]], 274: [['001', '002'], [[371.0, 323.5, 96, 247], [265.0, 313.0, 80, 212]]], 275: [['001', '001'], [[369.0, 325.5, 96, 249], [267.5, 313.5, 85, 211]]], 276: [['001', '002'], [[366.5, 325.5, 95, 251], [269.0, 314.5, 86, 211]]], 277: [['001', '002'], [[365.5, 327.0, 95, 256], [269.0, 315.0, 84, 214]]], 278: [['001', '002'], [[363.0, 327.0, 92, 260], [271.5, 316.0, 81, 210]]], 279: [['001', '002'], [[362.0, 325.5, 88, 261], [273.0, 315.0, 76, 212]]], 280: [['001', '002'], [[359.0, 328.0, 88, 262], [273.0, 314.0, 74, 212]]], 281: [['001', '002'], [[355.0, 328.5, 84, 261], [276.0, 313.0, 66, 208]]], 282: [['001', '002'], [[350.5, 326.5, 81, 265], [279.5, 312.5, 59, 211]]], 283: [[' ', ' '], [[343.0, 324.0, 76, 262], [293.0, 308.5, 54, 215]]], 284: [['001'], [[334.0, 323.5, 74, 265]]], 285: [['001'], [[325.5, 324.5, 75, 267]]], 286: [['001'], [[323.0, 326.5, 78, 273]]], 287: [['001'], [[323.5, 327.0, 83, 274]]], 288: [[' '], [[321.0, 326.5, 90, 279]]], 289: [[' '], [[317.0, 327.0, 92, 282]]], 290: [[' '], [[315.0, 326.5, 98, 285]]], 291: [[' '], [[311.5, 327.5, 99, 281]]], 292: [[' '], [[307.5, 327.5, 99, 279]]], 293: [['001'], [[304.5, 328.0, 97, 278]]], 294: [['001'], [[303.5, 330.5, 97, 273]]], 295: [['001'], [[298.5, 329.5, 95, 269]]], 296: [[' '], [[292.0, 330.0, 88, 272]]], 297: [[' ', ' '], [[292.0, 329.0, 90, 276], [335.5, 305.0, 53, 202]]], 298: [[' ', ' '], [[294.5, 327.5, 85, 275], [340.5, 307.0, 55, 210]]], 299: [[' ', ' '], [[280.5, 333.0, 75, 268], [344.0, 303.0, 62, 204]]], 300: [[' ', ' '], [[277.0, 325.5, 70, 283], [346.0, 305.5, 66, 211]]], 301: [['001', '002'], [[274.0, 324.5, 68, 285], [349.5, 308.0, 67, 214]]], 302: [['001', '002'], [[270.0, 329.0, 66, 288], [351.0, 308.5, 76, 209]]], 303: [['001', '002'], [[263.0, 325.0, 72, 282], [351.5, 308.0, 79, 208]]], 304: [['001', '002'], [[259.0, 326.5, 78, 285], [352.5, 310.5, 81, 213]]], 305: [['001', '002'], [[256.5, 325.0, 83, 286], [354.0, 313.5, 82, 219]]], 306: [['001', '002'], [[254.0, 324.5, 86, 283], [355.5, 317.0, 81, 224]]], 307: [['001', '002'], [[251.5, 327.0, 89, 284], [359.0, 319.5, 80, 221]]], 308: [['001', '002'], [[250.0, 327.0, 92, 282], [361.5, 319.5, 77, 221]]], 309: [['001', '002'], [[248.5, 328.0, 91, 280], [362.5, 318.5, 71, 219]]], 310: [['001', '002'], [[246.0, 329.5, 86, 279], [363.0, 318.0, 66, 220]]], 311: [['001', '002'], [[245.5, 330.0, 83, 278], [364.5, 316.5, 61, 225]]], 312: [['001', '002'], [[245.5, 328.0, 79, 274], [367.0, 317.5, 60, 229]]], 313: [['001', '002'], [[244.5, 327.5, 75, 273], [367.5, 316.5, 59, 229]]], 314: [['001', '002'], [[244.0, 325.5, 74, 271], [369.5, 317.0, 59, 232]]], 315: [['001', '002'], [[243.0, 324.5, 74, 269], [371.0, 317.0, 60, 232]]], 316: [['001', '002'], [[243.5, 321.5, 73, 263], [373.0, 316.5, 60, 231]]], 317: [['001', '002'], [[242.5, 322.5, 73, 265], [374.5, 316.0, 61, 230]]], 318: [['001', '002'], [[242.0, 324.0, 74, 268], [376.0, 316.5, 62, 231]]], 319: [['001', '002'], [[241.5, 321.5, 75, 263], [377.5, 319.0, 63, 234]]], 320: [['001', '002'], [[240.5, 320.0, 75, 258], [379.0, 321.5, 66, 239]]], 321: [['001', '002'], [[241.0, 320.5, 74, 257], [379.5, 323.0, 65, 242]]], 322: [['001', '002'], [[240.5, 321.5, 73, 257], [379.0, 325.5, 64, 247]]], 323: [['001', '002'], [[240.5, 320.5, 73, 255], [379.5, 327.5, 63, 251]]], 324: [['001', '002'], [[240.5, 322.0, 73, 256], [380.0, 327.0, 64, 250]]], 325: [['001', '002'], [[240.5, 322.5, 75, 257], [381.5, 325.0, 67, 252]]], 326: [['001', '002'], [[240.5, 323.0, 77, 258], [383.0, 325.0, 68, 254]]], 327: [['001', '002'], [[242.0, 322.5, 78, 255], [386.5, 327.5, 71, 253]]], 328: [['001', '002'], [[243.5, 320.5, 79, 251], [389.5, 328.5, 67, 249]]], 329: [['001', '002'], [[244.5, 320.0, 77, 248], [391.0, 327.5, 62, 253]]], 330: [['001', '002'], [[245.0, 321.0, 74, 248], [392.5, 326.5, 57, 257]]], 331: [['001', '003'], [[245.5, 321.5, 71, 247], [393.5, 326.5, 55, 259]]], 332: [['001', '004'], [[246.5, 321.5, 65, 249], [393.5, 326.0, 55, 258]]], 333: [['001', '005'], [[245.0, 321.0, 58, 250], [393.5, 324.5, 55, 255]]]}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.save('./kalman.npy',[E.save])\n",
    "print(E.save)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_test_002_true,num_test_002_false,num_test_001_true,num_test_001_false=0,0,0,0\n",
    "path = './walkingworkspace/test2020'\n",
    "list_label,list_li,list_xia,list_other=[],[],[],[]\n",
    "for name in glob.glob(path+'/LI/*.jpg'):\n",
    "    list_li.append(os.path.basename(name))\n",
    "for name in glob.glob(path+'/XI/*.jpg'):\n",
    "    list_xia.append(os.path.basename(name))\n",
    "for name in glob.glob(path+'/other/*.jpg'):\n",
    "    list_other.append(os.path.basename(name))\n",
    "    \n",
    "for name in glob.glob('./walkingworkspace/action/*.jpg'):\n",
    "    name = os.path.basename(name) \n",
    "    if name in list_other:\n",
    "        list_label.append('003')\n",
    "    if name in list_xia:\n",
    "        list_label.append('001')   \n",
    "    if name in list_li:\n",
    "        list_label.append('002')\n",
    "\n",
    "list_label=list_label[(len(list_label)-len(E.label_test)):len(list_label)]\n",
    "print(len(E.label_test),len(list_label))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_label,label in  zip(E.label_test,list_label):\n",
    "    if label=='001':\n",
    "        if test_label==label:\n",
    "            num_test_001_true+=1\n",
    "        else:\n",
    "            num_test_001_false+=1\n",
    "    if label=='002':\n",
    "        if test_label==label:\n",
    "            num_test_002_true+=1\n",
    "        else:\n",
    "            num_test_002_false+=1\n",
    "print('the 001 C:%.2f'%(num_test_001_true/(num_test_001_true+num_test_001_false)))\n",
    "print('the 002 C:%.2f'%(num_test_002_true/(num_test_002_true+num_test_002_false)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA testdata rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HumanMaxNumber=2\n",
    "#size=(512,384)\n",
    "#E = efficientdet(0 ,512,HumanMaxNumber)\n",
    "#ids_bboxes = {}\n",
    "pca=PCA(dir_path='./walkingworkspace/train2020',NUM_EIGEN_FACES = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E.threadStart()\n",
    "#videopath='./testvideo/mc1.mp4'\n",
    "im_path='./walkingworkspace/action/'\n",
    "list_im=[]\n",
    "for im_name in glob.glob(im_path+'*.jpg'):\n",
    "    list_im.append(im_name.replace('\\\\','/'))\n",
    "list_W=[]\n",
    "list_=[]\n",
    "\n",
    "print(len(list_im))\n",
    "list_im1,list_im2,list_im3,list_im4=[],[],[],[]\n",
    "for im_name in list_im:  \n",
    "    #print(im_name)\n",
    "    im = cv2.imread(im_name)\n",
    "    im=cv2.resize(im,(64,128))\n",
    "    #if im_name.find('A')!=-1: \n",
    "    list_im1.append(im)\n",
    "    #if im_name.find('B')!=-1:\n",
    "    #    list_im2.append(im)\n",
    "    #if im_name.find('C')!=-1:\n",
    "        #list_im3.append(im)\n",
    "    #if im_name.find('D')!=-1:\n",
    "        #list_im4.append(im)\n",
    "distance1,w1,wcenter1= pca.compute_pca(list_im1)\n",
    "#pca=PCA(dir_path='./test_colors/train',basepath = './test_colors/source',NUM_EIGEN_FACES = 64)\n",
    "#distance2,w2,wcenter2= pca.compute_pca(list_im2)\n",
    "#data3= pca.compute_pca(list_im3)\n",
    "#data4= pca.compute_pca(list_im4)\n",
    "print(distance1)\n",
    "#print(len(distance2))\n",
    "#print(data2)\n",
    "#    X,Y,Z=data\n",
    "'''if im_name.find('A')!=-1:\n",
    "    set_A_x.append(X)\n",
    "    set_A_y.append(Y)\n",
    "    set_A_z.append(Z)\n",
    "if im_name.find('B')!=-1:\n",
    "    set_B_x.append(X)\n",
    "    set_B_y.append(Y)\n",
    "    set_B_z.append(Z)'''\n",
    "'''if im_name.find('O')!=-1:\n",
    "    set_O_x.append(X)\n",
    "    set_O_y.append(Y)\n",
    "    set_O_z.append(Z)\n",
    "if im_name.find('C')!=-1:\n",
    "    set_C_x.append(X)\n",
    "    set_C_y.append(Y)\n",
    "    set_C_z.append(Z)\n",
    "if im_name.find('E')!=-1:\n",
    "    set_E_x.append(X)\n",
    "    set_E_y.append(Y)\n",
    "    set_E_z.append(Z)  ''' \n",
    "#    list_W.append(W)\n",
    "    #pca.pca_class_dataset(im,im_name,output_path)\n",
    "#pca.test_meandyou()\n",
    "cv2.destroyAllWindows() \n",
    "#print(len(set_A_x),len(set_A_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data1.remove(max(data1))\n",
    "#data1.remove(min(data1))\n",
    "#data2.remove(max(data2))\n",
    "#data2.remove(min(data2))\n",
    "max_jiawei = max(data1)\n",
    "max_xiaobo = max(data2)\n",
    "print(max_jiawei,max_xiaobo)\n",
    "max_jiawei,max_xiaobo = float(max_jiawei),float(max_xiaobo)\n",
    "print((max_jiawei+max_xiaobo)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('I am distance')\n",
    "plt.xlabel('I am id')\n",
    "#plt.legend([L1,L2],['A','B'],loc='upper right')\n",
    "x1=range(0,len(distance1))\n",
    "#x2=range(0,len(distance2))\n",
    "x3=range(0,50)\n",
    "x4=range(0,50)\n",
    "plt.plot(x1,distance1,label='A',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='r',markersize=12)\n",
    "plt.show()\n",
    "#plt.plot(x2,distance2,label='B',linewidth=3,color='r',marker='o',\n",
    "#markerfacecolor='g',markersize=12)\n",
    "#plt.show()\n",
    "#plt.plot(x1,data3,label='C',linewidth=3,color='r',marker='o',\n",
    "#markerfacecolor='b',markersize=12)\n",
    "#plt.plot(x2,data4,label='D',linewidth=3,color='r',marker='o',\n",
    "#markerfacecolor='y',markersize=12)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语义分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "self.net = fcn_resnet101(pretrained=True,progress=False).cuda()\n",
    "_ = self.net.eval()\n",
    "def fcn_mask(self,im):\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    input_batch = torch.tensor(im,dtype=torch.float32).cuda()\n",
    "    input_batch = input_batch.permute(2,0,1)\n",
    "    input_batch = 2*input_batch/255.0-1.0\n",
    "    input_batch = input_batch.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = net(input_batch)['out'][0]\n",
    "    output_predictions = output.argmax(0).cpu()\n",
    "    output_predictions = np.where(output_predictions[:]==15,1,0)\n",
    "    return output_predictions\n",
    "\n",
    "def create_mask(self,im_bbox):\n",
    "    im_fcn = self.fcn_mask(im_bbox)\n",
    "    re = np.zeros(im_bbox.shape)*255\n",
    "    #im_fcn_=np.zeros((im_fcn.shape[0],im_fcn.shape[1],3))\n",
    "    re[:,:,0]=re[:,:,1]=re[:,:,2]=im_fcn\n",
    "    #re = np.where(re.all()!=[0,0,0], [0,0,0], [255,255,255])\n",
    "    re = re*im_bbox\n",
    "    re = re.astype(np.uint8)\n",
    "    cv2.imshow('mask',re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.figure()\n",
    "plt = fig.gca(projection='3d')\n",
    "plt.plot(set_A_x,set_A_y,set_A_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='w',markersize=12)\n",
    "plt.plot(set_B_x,set_B_y,set_B_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='b',markersize=12)\n",
    "plt.plot(set_O_x,set_O_y,set_O_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='g',markersize=12)\n",
    "plt.plot(set_C_x,set_C_y,set_C_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='y',markersize=12)\n",
    "plt.plot(set_C_x,set_C_y,set_C_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='y',markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,ConcatDataset\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0,1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    def __init__(self, fpath_peoject=[]):\n",
    "        \n",
    "        self.labels,self.images = [],[]\n",
    "        for i in fpath_peoject:\n",
    "            j = i[1]\n",
    "            np_im = np.load(i[0])\n",
    "            self.labels.append(j)\n",
    "            np_im = np_im.flatten()\n",
    "            #print(np_im.shape)\n",
    "            self.images.append(np_im)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.images[idx],self.labels[idx])\n",
    "classes=['A','B']\n",
    "def get_data(path):\n",
    "    list_train,list_val=[],[]\n",
    "    for name in glob.glob(path+'/*.npy'):\n",
    "        name_=name.replace('\\\\','/')\n",
    "        if name_.find('A')!=-1:\n",
    "            list_train.append([name_,0])\n",
    "        if name_.find('B')!=-1:\n",
    "            list_train.append([name_,1])\n",
    "    return list_train\n",
    "train = get_data('./miniclassify/train_max')  \n",
    "test = get_data('./miniclassify/test_max') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mytraindataset = DataLoader(train)\n",
    "mytestataset = DataLoader(test)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainloader = torch.utils.data.DataLoader(mytraindataset, batch_size=6,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(mytestataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(100,1000)\n",
    "        self.fc3 = nn.Linear(1000,2)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.99))\n",
    "PATH='./pytorchmodel/my_max.pth'\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device),data[1].to(device)\n",
    "        #print(inputs,labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 6 == 0:    # print every 2000 mini-batches\n",
    "            print('\\r [%d, %5d] loss: %.4f' %\n",
    "                  (epoch + 1, i + 1, running_loss/100),end=' ')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images=images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)),cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images,lables= dataiter.next()\n",
    "print(type(images))\n",
    "images,lables=images.to(device),lables.to(device)\n",
    "print(images.shape)\n",
    "outputs = net(images)\n",
    "print(images.shape)\n",
    "_, predicted = torch.max(outputs,1)\n",
    "print(predicted)\n",
    "imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "print('Predicted: ', ' '.join('%11s' % classes[predicted[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='./pytorchmodel/my_max.pth'\n",
    "mynet = torch.load(PATH)\n",
    "print(mynet['fc1.weight'].shape)\n",
    "print(mynet['fc3.weight'].shape)\n",
    "#print(mynet)\n",
    "#print(type(mynet))\n",
    "W = mynet['fc1.weight']\n",
    "W_weight=[]\n",
    "for i in range(0,100):\n",
    "    #print(W[:,i].shape)\n",
    "    W_weight.append(np.mean(abs(W[:,i]).cpu().numpy()))\n",
    "print(W_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1=range(0,100)\n",
    "plt.plot(x1,W_weight,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='blue',markersize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Number of EigenFaces\n",
    "NUM_EIGEN_FACES = 10\n",
    "\n",
    "# Maximum weight\n",
    "MAX_SLIDER_VALUE = 10\n",
    "\n",
    "# Directory containing images\n",
    "dirName = \"./pytorchdata/test\"\n",
    "\n",
    "# Read images\n",
    "images=[]\n",
    "for name in glob.glob(dirName+'/*.jpg'):\n",
    "    #print(name)\n",
    "    images.append(cv2.resize(cv2.imread(name.replace('\\\\','/')),(64,128)))\n",
    "    cv2.imshow('0-0',cv2.imread(name.replace('\\\\','/')))\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Size of images\n",
    "sz = images[0].shape\n",
    "\n",
    "# Create data matrix for PCA.\n",
    "data = createDataMatrix(images)\n",
    "\n",
    "# Compute the eigenvectors from the stack of images created\n",
    "print(\"Calculating PCA \", end=\"...\")\n",
    "mean, eigenVectors = cv2.PCACompute(data, mean=None, maxComponents=NUM_EIGEN_FACES)\n",
    "print(mean.shape, eigenVectors.shape)\n",
    "print (\"DONE\")\n",
    "\n",
    "averageFace = mean.reshape(sz)\n",
    "print(averageFace.shape)\n",
    "cv2.imshow('averageFace',averageFace)\n",
    "eigenFaces = []; \n",
    "\n",
    "for eigenVector in eigenVectors:\n",
    "    eigenFace = eigenVector.reshape(sz)\n",
    "    eigenFaces.append(eigenFace)\n",
    "\n",
    "# Create window for displaying Mean Face\n",
    "cv2.namedWindow(\"Result\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Display result at 2x size\n",
    "output = cv2.resize(averageFace, (0,0), fx=2, fy=2)\n",
    "cv2.imshow(\"Result\", output)\n",
    "\n",
    "# Create Window for trackbars\n",
    "cv2.namedWindow(\"Trackbars\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "sliderValues = []\n",
    "\n",
    "# Create Trackbars\n",
    "for i in range(0, NUM_EIGEN_FACES):\n",
    "    sliderValues.append(MAX_SLIDER_VALUE/2)\n",
    "    cv2.createTrackbar( \"Weight\" + str(i), \"Trackbars\", int(MAX_SLIDER_VALUE), MAX_SLIDER_VALUE, createNewFace)\n",
    "\n",
    "# You can reset the sliders by clicking on the mean image.\n",
    "cv2.setMouseCallback(\"Result\", createNewFace);\n",
    "\n",
    "print('''Usage:\n",
    "Change the weights using the sliders\n",
    "Click on the result window to reset sliders\n",
    "Hit ESC to terminate program.''')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "        #\n",
    "        # * self.notebook 记录发现新的图片的W\n",
    "        # * 保存数据的格式 self.save={'id':{'center':w,'LIB':[w1..wn]}}\n",
    "        #\n",
    "        color=[]\n",
    "        identities=[]\n",
    "        dths=[]\n",
    "        self.frame+=1\n",
    "        #维护LIB\n",
    "        self.manage_lib(self.frame)\n",
    "        if bbox_list!=[]:\n",
    "            for bbox,c in zip(bbox_list,confidences):\n",
    "                list_id,list_feature,list_distance,list_n=[],[],[],[]\n",
    "                \n",
    "                (x, y, w, h) = bbox\n",
    "                (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "                (x,y,w,h)=(x1+x2)*0.5,(y1+y2)*0.5,abs(x1-x2),abs(y1-y2)\n",
    "                im_=im[y1:y2,x1:x2]\n",
    "                #im_ = self.fill_im(im_)\n",
    "                im_ = cv2.resize(im_,(64,128))\n",
    "                featureVector = self.compute_feature(im_)\n",
    "                distance=0\n",
    "            #所有图片与LIB对比 判断是否是新的id 跟新center\n",
    "                for k,v in list(self.save.items()):\n",
    "                    if k=='000':\n",
    "                        continue\n",
    "                    if v['passage']==True:\n",
    "                        n=v['center']\n",
    "                        distance = self.compute_cos(n,featureVector)\n",
    "                        if distance <self.dth:\n",
    "                            list_distance.append(distance)\n",
    "                            list_id.append(k)\n",
    "                            list_feature.append(featureVector)\n",
    "                            list_n.append(n)\n",
    "                #判断有匹配的则进行更新\n",
    "                if len(list_distance)!=0:\n",
    "                    min_number=list_distance.index(min(list_distance))\n",
    "                    min_distance = list_distance[min_number]\n",
    "                    min_distance_id = list_id[min_number]\n",
    "                    min_distance_feature=list_feature[min_number]\n",
    "                    min_n = list_n[min_number]\n",
    "                    #dths.append(1-min(list_distance))\n",
    "                    dths.append(c)\n",
    "                     #检查除id_me外是否与数据库里的bbox重叠\n",
    "                    ret_bbox =self.check_bboxs(bbox_list,bbox)\n",
    "                    #检查重新回来的id的frame\n",
    "                    #ret_id_frame = self.check_frame_id(min_distance_id,min_distance_feature,self.frame)\n",
    "\n",
    "                    if ret_bbox==True :#and ret_id_frame==True:\n",
    "                        center = (min_distance_feature*0.5)+(min_n*0.5)\n",
    "                        self.save[min_distance_id]['center'] =center\n",
    "                        self.save[min_distance_id]['bbox'] =bbox\n",
    "                        self.save[min_distance_id]['frame'] =self.frame\n",
    "                        color_ = self.check_lib_add(min_distance_feature,min_distance_id)\n",
    "                        color.append(color_)\n",
    "                    identities.append(min_distance_id)\n",
    "\n",
    "                #没有匹配的图片出现\n",
    "                else:\n",
    "                    #检查与本帧的bbox是否重叠 和边缘是否重叠\n",
    "                    ret_bbox =self.check_bboxs(bbox_list,bbox)\n",
    "                    #ret_id =self.check_id(bbox_list,bbox,'#')\n",
    "                    ret_lib = self.check_lib(featureVector)\n",
    "                    if ret_bbox==True and ret_lib==' ':\n",
    "                            id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                            identities.append(id_)\n",
    "                            #dths.append(1-distance)\n",
    "                            dths.append(c)\n",
    "                            color.append(0)\n",
    "                    else:\n",
    "                        color.append(0)\n",
    "                        dths.append(c)\n",
    "                        identities.append(' ')  \n",
    "            identities = self.kalman_reid(identities,bbox_list)\n",
    "        self.frame+=1\n",
    "        \n",
    "        return identities,dths,color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "        #\n",
    "        # * self.notebook 记录发现新的图片的W\n",
    "        # * 保存数据的格式 self.save={'id':{'center':w,'LIB':[w1..wn]}}\n",
    "        #\n",
    "        color=[]\n",
    "        identities=[]\n",
    "        dths=[]\n",
    "        #维护LIB\n",
    "        self.manage_lib(self.frame)\n",
    "        list_id,list_feature,list_distance,list_n=[],[],[],[]\n",
    "        if bbox_list!=[]:\n",
    "            for bbox,c in zip(bbox_list,confidences):\n",
    "                (x, y, w, h) = bbox\n",
    "                (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "                (x,y,w,h)=(x1+x2)*0.5,(y1+y2)*0.5,abs(x1-x2),abs(y1-y2)\n",
    "                im_=im[y1:y2,x1:x2]\n",
    "                #im_ = self.fill_im(im_)\n",
    "                im_ = cv2.resize(im_,(64,128))\n",
    "                #第一帧的所有创建自己的组\n",
    "                #if self.frame==0:\n",
    "                #    featureVector = self.compute_feature(im_)\n",
    "                #    id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                #    identities.append(id_)\n",
    "                #    continue\n",
    "                #else: \n",
    "                featureVector = self.compute_feature(im_)\n",
    "                distance=0\n",
    "            #所有图片与LIB对比 判断是否是新的id 分别存储到不同的list\n",
    "                list_distance_buffer,list_id_buffer,list_feature_buffer,list_n_buffer=[],[],[],[]\n",
    "                for k,v in list(self.save.items()):\n",
    "                    if k=='000':\n",
    "                        continue\n",
    "                    n=v['center']\n",
    "                    if v['passage']==True:\n",
    "                        distance = self.compute_cos(n,featureVector)\n",
    "                        list_distance_buffer.append(distance)\n",
    "                        list_id_buffer.append(k)\n",
    "                        list_feature_buffer.append(featureVector)\n",
    "                        list_n_buffer.append(n)\n",
    "                if len(list_distance_buffer)>0 and min(list_distance_buffer)<self.dth:\n",
    "                    list_distance.append(list_distance_buffer)\n",
    "                    list_id+=list_id_buffer\n",
    "                    list_feature+=list_feature_buffer\n",
    "                    list_n+=list_n_buffer\n",
    "                else:\n",
    "                    #distance_ = min(list_distance_buffer)\n",
    "                    #检查与本帧的bbox是否重叠 和边缘是否重叠\n",
    "                    ret_bbox =self.check_bboxs(bbox_list,bbox)\n",
    "                    #ret_id =self.check_id(bbox_list,bbox,'#')\n",
    "                    ret_lib = self.check_lib(featureVector)\n",
    "                    if ret_bbox==True:\n",
    "                        if ret_lib==' ':\n",
    "                            id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                            identities.append(id_)\n",
    "                            #dths.append(1-distance_)\n",
    "                            dths.append(c)\n",
    "                            color.append(0)\n",
    "                        else:\n",
    "                            color.append(0)\n",
    "                            dths.append(c)\n",
    "                            #self.paassag_on(featureVector,bbox,self.frame,ret_lib)\n",
    "                            identities.append(' ')\n",
    "                    else:\n",
    "                        color.append(0)\n",
    "                        dths.append(c)\n",
    "                        identities.append(' ')  \n",
    "\n",
    "            if len(list_distance)>0 and len(bbox_list)>0:\n",
    "                list_center,list_min_n,list_identities=[],[],[]\n",
    "                np_distance=np.asarray(list_distance)\n",
    "                #print(np_distance)\n",
    "                #print(self.save.keys())\n",
    "                list_Hungary = self.computer_Hungary(np_distance)\n",
    "                #print(list_Hungary)\n",
    "                for number in list_Hungary:\n",
    "                    #number = number*0.00001\n",
    "                    min_distance = np_distance.flatten().tolist().index(number)\n",
    "                    list_identities.append(list_id[min_distance])\n",
    "                    list_center.append(list_feature[min_distance])\n",
    "                    list_min_n.append(list_n[min_distance])\n",
    "\n",
    "                #检查重新回来的id的frame\n",
    "                #ret_id_frame = self.check_frame_id(min_distance_id,min_distance_feature,self.frame)\n",
    "                for bbox,conter,min_n,id_,distance_ in zip(bbox_list,list_center,list_min_n,list_identities,list_Hungary):\n",
    "                     #检查除id_me外是否与数据库里的bbox重叠\n",
    "                    #if distance_<self.dth:\n",
    "                        ret_bbox =self.check_bboxs(bbox_list,bbox)\n",
    "                        if ret_bbox==True :#and ret_id_frame==True:\n",
    "                            center_ = (conter*0.5)+(min_n*0.5)\n",
    "                            self.save[id_]['center'] =center_\n",
    "                            self.save[id_]['bbox'] =bbox\n",
    "                            self.save[id_]['frame'] =self.frame\n",
    "                            color_ = self.check_lib_add(conter,id_,bbox)\n",
    "                            color.append(color_)\n",
    "                            dths.append(1-distance_)\n",
    "                            identities.append(id_)\n",
    "                        else:\n",
    "                            #self.save[id_]['bbox'] =bbox\n",
    "                            self.save[id_]['frame'] =self.frame\n",
    "                            color_ = self.check_lib_add(conter,id_,bbox)\n",
    "                            color.append(color_)\n",
    "                            dths.append(1-distance_)\n",
    "                            identities.append(' ')\n",
    "                    \n",
    "        self.frame+=1\n",
    "        #保存id\n",
    "        self.old_id=identities\n",
    "        return identities,dths,color"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
