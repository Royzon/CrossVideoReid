{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import copy\n",
    "import queue\n",
    "import glob\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.backends import cudnn\n",
    "from backbone import EfficientDetBackbone\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess,sirxiapreprocess\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class efficientdet:\n",
    "    def __init__(self,compound_coef,force_input_size = 1920,huamanNum=1,dir_path='./walkingworkspace/train_all',NUM_EIGEN_FACES= 128):\n",
    "        self.humanNum=huamanNum\n",
    "        cudnn.fastest = True\n",
    "        cudnn.benchmark = True\n",
    "        self.bbox_threshold=0.01#%bbox的阈值!<\n",
    "        self.probability_threshold=0.3#%人体识别概率的阈值!<\n",
    "        self.use_cuda = True \n",
    "        self.use_float16 = False\n",
    "        self.threshold = 0.2\n",
    "        self.iou_threshold = 0.2\n",
    "        self.obj_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "            'fire hydrant', '', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "            'cow', 'elephant', 'bear', 'zebra', 'giraffe', '', 'backpack', 'umbrella', '', '', 'handbag', 'tie',\n",
    "            'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "            'skateboard', 'surfboard', 'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "            'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
    "            'cake', 'chair', 'couch', 'potted plant', 'bed', '', 'dining table', '', '', 'toilet', '', 'tv',\n",
    "            'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "            'refrigerator', '', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "            'toothbrush']\n",
    "        #self.device = torch.device('cuda')\n",
    "        self.model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(self.obj_list))\n",
    "        self.model.load_state_dict(torch.load(f'weights/efficientdet-d{compound_coef}.pth'))\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.eval()\n",
    "        #self.model=nn.DataParallel(self.model)\n",
    "        self.model.cuda()\n",
    "        input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "        self.input_size =  force_input_size\n",
    "        self.t=time.time()\n",
    "        self.pca=PCA(dir_path,NUM_EIGEN_FACES)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.out = cv2.VideoWriter('output.avi',fourcc, 30.0, (640,480))\n",
    "    def init_video(self):\n",
    "        self.out.release()\n",
    "        self.pca.clear_id()\n",
    "        self.pca.frame=0\n",
    "        name = time.strftime('%Y.%m.%d',time.localtime(time.time()))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        self.out = cv2.VideoWriter(name+'.avi',fourcc, 30.0, (640,480))\n",
    "    def threadStart(self):\n",
    "        threadone=threading.Thread(target=self.mythread,args=())\n",
    "        threadone.start()\n",
    "      \n",
    "    def mythread(self):\n",
    "        global data_queue,out_queue\n",
    "        print('start thread ->>> efficientdet ')\n",
    "        while True:\n",
    "            self.t=time.time()\n",
    "            while(data_queue.qsize()<2):\n",
    "                time.sleep(0.01)\n",
    "                if time.time()-self.t>10:\n",
    "                    print('stop thread ->>> efficientdet ')\n",
    "                    break\n",
    "            out_queue.put(self.detector(data_queue.get()))\n",
    "                            ##################\n",
    "                            ####detector######\n",
    "                            ##################\n",
    "    def  detector(self,im):\n",
    "        ori_imgs, framed_imgs, framed_metas = sirxiapreprocess(im, max_size=self.input_size)\n",
    "        x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "        x = x.to(torch.float32 if not self.use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "        with torch.no_grad():\n",
    "            features, regression, classification, anchors = self.model(x)\n",
    "            regressBoxes = BBoxTransform()\n",
    "            clipBoxes = ClipBoxes()\n",
    "            out = postprocess(x,\n",
    "                              anchors, regression, classification,\n",
    "                              regressBoxes, clipBoxes,\n",
    "                              self.threshold, self.iou_threshold)\n",
    "            out = invert_affine(framed_metas, out)\n",
    "            bbox_list,c_list=self.update(out, ori_imgs)\n",
    "            #print(bbox_list,c_list)\n",
    "            #identities,bbox_xyxy = DeepSort.deep_sort(np.asarray(bbox_list),np.asarray(c_list),im)\n",
    "            identities,dths,color = self.pca.efficientdet_compute_pca(bbox_list,c_list,im)\n",
    "            im =self.display(bbox_list,c_list ,im,identities,dths,color)\n",
    "            self.out.write(im)\n",
    "            self.t=time.time()\n",
    "            cv2.waitKey(1)\n",
    "            #return identities,bbox_xyxy,c_list\n",
    "            #return bbox_list,c_list ,identities\n",
    "    #过滤\n",
    "    def update(self,preds, imgs):\n",
    "        save_list=[]\n",
    "        area_list=[]\n",
    "        score_list=[]\n",
    "        for i in range(len(imgs)):\n",
    "            if len(preds[i]['rois']) == 0:\n",
    "                continue\n",
    "            for j in range(len(preds[i]['rois'])):\n",
    "                if preds[i]['class_ids'][j]==0:#person\n",
    "                    score = float(preds[i]['scores'][j])#百分比\n",
    "                    H,W=imgs[i].shape[:2]\n",
    "                    (x1, y1, x2, y2) = preds[i]['rois'][j].astype(np.int)\n",
    "                    area = (x2-x1)*(y2-y1)\n",
    "                    if  (area/H*W)<self.bbox_threshold or score<self.probability_threshold:\n",
    "                        continue\n",
    "                    x,y,w,h=(x1+x2)/2,(y1+y2)/2,abs(x1-x2),abs(y1-y2)\n",
    "                    area_list.append(area)\n",
    "                    save_list.append([x,y,w,h]) \n",
    "                    score_list.append(score)\n",
    "        bbox_list,c_list=[],[]\n",
    "        if len(area_list)>self.humanNum:\n",
    "            \n",
    "            for i in range(self.humanNum):\n",
    "                one=save_list[area_list.index(max(area_list))]\n",
    "                two=score_list[area_list.index(max(area_list))]\n",
    "                bbox_list.append(copy.copy(one))\n",
    "                c_list.append(copy.copy(two))\n",
    "                save_list.remove(one)\n",
    "                score_list.remove(two)\n",
    "                area_list.remove(max(area_list))\n",
    "                 \n",
    "        else:\n",
    "            for i in range(len(area_list)):\n",
    "                one=save_list[area_list.index(max(area_list))]\n",
    "                two=score_list[area_list.index(max(area_list))]\n",
    "                bbox_list.append(copy.copy(one))\n",
    "                c_list.append(copy.copy(two))\n",
    "                save_list.remove(one)\n",
    "                score_list.remove(two)\n",
    "                area_list.remove(max(area_list))\n",
    "        return bbox_list,c_list\n",
    "    \n",
    "    def display(self,bbox_list,c_list,im,identities,dths,color):\n",
    "        #print(len(out_list))\n",
    "        for bbox,c,id_,dth,color_ in zip(bbox_list,c_list,identities,dths,color):\n",
    "            #(x1, y1, x2, y2) = bbox\n",
    "            (x, y, w, h) = bbox\n",
    "            (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "            cv2.rectangle(im, (x1, y1), (x2, y2), (color_, 0, 255-color_), 2)\n",
    "            #cv2.putText(im, ('%.2f'%c), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 250,0), 1)\n",
    "            cv2.putText(im, ('%.2f'%dth), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (color_, 0, 255-color_), 1)\n",
    "            cv2.putText(im, ('%s'%id_), (x1, y1+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (color_, 0, 255-color_), 1)\n",
    "        fps = 1/(time.time()-self.t)\n",
    "        cv2.putText(im, ('%.2f'%fps), (590, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.imshow('efficientdet', im)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet101\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "class PCA:\n",
    "    def __init__(self,dir_path='./test_colors/train',NUM_EIGEN_FACES = 64):\n",
    "        self.save={'000':{'center':[],'bbox':[],'lib':[],'frame':0,'passage':False}}\n",
    "        self.NUM_EIGEN_FACES = NUM_EIGEN_FACES\n",
    "        self.images = self.readImages(dir_path)\n",
    "        self.data = self.createDataMatrix(self.images)\n",
    "        #self.data = torch.from_numpy(self.data).cuda()\n",
    "        #torch.pca_lowrank(A, q=None, center=True, niter=2)\n",
    "        #self.mean, self.eigenVectors = torch.pca_lowrank(self.data, q=None, center=True, niter= self.NUM_EIGEN_FACES)\n",
    "        #self.means, self.eigenVectorses=[],[]\n",
    "        #print('the alldata %d'%len(self.eigenVectors))\n",
    "        #self.init_pca(basepath)\n",
    "        #self.notebook={'000':{'frame':[],'lib':[]}}\n",
    "        self.frame=0\n",
    "        self.flag_frame=[]\n",
    "        self.flag_line=[]\n",
    "        self.dth = 0.5#相似度距离0.6  / 欧氏距离25\n",
    "        self.Forget=10  #状态切换帧\n",
    "        self.testsave={}\n",
    "        self.models_mean = './models/mean.npy'\n",
    "        self.models_eigenVector = './models/eigenVector.npy'\n",
    "        #self.meta = threading.Lock()\n",
    "        if os.path.exists(self.models_mean)==False and os.path.exists(self.models_eigenVector)==False:\n",
    "            self.mean, self.eigenVectors = cv2.PCACompute(self.data, mean=None, maxComponents=self.NUM_EIGEN_FACES)\n",
    "            np.save(self.models_mean,self.mean)\n",
    "            np.save(self.models_eigenVector,self.eigenVectors)\n",
    "        else:\n",
    "            self.mean=np.load(self.models_mean)\n",
    "            self.eigenVectors=np.load(self.models_eigenVector)\n",
    "        \n",
    "    def createDataMatrix(self,images):\n",
    "        numImages = len(images)\n",
    "        sz = images[0].shape\n",
    "        data = np.zeros((numImages, sz[0] * sz[1] * sz[2]), dtype=np.float32)\n",
    "        for i in range(0, numImages):\n",
    "            image = images[i].flatten()\n",
    "            data[i,:] = image\n",
    "        #print(\"createData ok\")\n",
    "        return data\n",
    "\n",
    "    def readImages(self,path):\n",
    "        print(\"Reading images from \" + path, end=\"...\")\n",
    "        # Create array of array of images.\n",
    "        images = []\n",
    "        # List all files in the directory and read points from text files one by one\n",
    "        for name in glob.glob(path+'/*'):\n",
    "            for imagePath in glob.glob(name+'/*.jpg'):\n",
    "                    # Add to array of images\n",
    "                    im = cv2.imread(imagePath)\n",
    "                    im = cv2.resize(im,(64,128))\n",
    "                    if im is None :\n",
    "                        print(\"image:{} not read properly\".format(imagePath))\n",
    "                    else :\n",
    "                        # Convert image to floating point\n",
    "                        im = np.float32(im)/255.0\n",
    "                        # Add image to list\n",
    "                        images.append(im)\n",
    "                        # Flip image \n",
    "                        imFlip = cv2.flip(im, 1);\n",
    "                        # Append flipped image\n",
    "                        #images.append(imFlip)\n",
    "        numImages = int(len(images))\n",
    "        # Exit if no image found\n",
    "        if numImages == 0 :\n",
    "            print(\"No images found\")\n",
    "            sys.exit(0)\n",
    "        print(str(numImages) + \" files read.\")\n",
    "        return images\n",
    "#*\n",
    "#*\n",
    "#*      算法集合\n",
    "#*\n",
    "#*\n",
    "    def compute_cos(self,x,y):\n",
    "        x_,y_=x.flatten(),y.flatten()\n",
    "        dist =1- abs(np.dot(x_,y_)/(np.linalg.norm(x_)*np.linalg.norm(y_)))      \n",
    "        return abs(dist)\n",
    "    \n",
    "    def compute_dis(self,x,y):\n",
    "         return np.linalg.norm( x - y )\n",
    "    \n",
    "    def compute_Maha(self,x,y):\n",
    "        X=np.vstack([x,y])\n",
    "        XT=X.T\n",
    "        S=np.cov(X)   #两个维度之间协方差矩阵\n",
    "        SI = np.linalg.inv(S) #协方差矩阵的逆矩阵\n",
    "        #马氏距离计算两个样本之间的距离，此处共有10个样本，两两组合，共有45个距离。\n",
    "        n=XT.shape[0]\n",
    "        d1=[]\n",
    "        for i in range(0,n):\n",
    "            for j in range(i+1,n):\n",
    "                delta=XT[i]-XT[j]\n",
    "                d=np.sqrt(np.dot(np.dot(delta,SI),delta.T))\n",
    "                d1.append(d)\n",
    "        return d1\n",
    "    \n",
    "    def computer_Hungary(self,task_matrix):\n",
    "        b = task_matrix.copy()\n",
    "        # 行和列减0\n",
    "        for i in range(len(b)):\n",
    "            row_min = np.min(b[i])\n",
    "            for j in range(len(b[i])):\n",
    "                b[i][j] -= row_min\n",
    "        for i in range(len(b[0])):\n",
    "            col_min = np.min(b[:, i])\n",
    "            for j in range(len(b)):\n",
    "                b[j][i] -= col_min\n",
    "        line_count = 0\n",
    "        # 线数目小于矩阵长度时，进行循环\n",
    "        while (line_count < len(b)):\n",
    "            line_count = 0\n",
    "            row_zero_count = []\n",
    "            col_zero_count = []\n",
    "            for i in range(len(b)):\n",
    "                row_zero_count.append(np.sum(b[i] == 0))\n",
    "            for i in range(len(b[0])):\n",
    "                col_zero_count.append((np.sum(b[:, i] == 0)))\n",
    "            # 划线的顺序（分行或列）\n",
    "            line_order = []\n",
    "            row_or_col = []\n",
    "            for i in range(len(b[0]), 0, -1):\n",
    "                while (i in row_zero_count):\n",
    "                    line_order.append(row_zero_count.index(i))\n",
    "                    row_or_col.append(0)\n",
    "                    row_zero_count[row_zero_count.index(i)] = 0\n",
    "                while (i in col_zero_count):\n",
    "                    line_order.append(col_zero_count.index(i))\n",
    "                    row_or_col.append(1)\n",
    "                    col_zero_count[col_zero_count.index(i)] = 0\n",
    "            # 画线覆盖0，并得到行减最小值，列加最小值后的矩阵\n",
    "            delete_count_of_row = []\n",
    "            delete_count_of_rol = []\n",
    "            row_and_col = [i for i in range(len(b))]\n",
    "            for i in range(len(line_order)):\n",
    "                if row_or_col[i] == 0:\n",
    "                    delete_count_of_row.append(line_order[i])\n",
    "                else:\n",
    "                    delete_count_of_rol.append(line_order[i])\n",
    "                c = np.delete(b, delete_count_of_row, axis=0)\n",
    "                c = np.delete(c, delete_count_of_rol, axis=1)\n",
    "                line_count = len(delete_count_of_row) + len(delete_count_of_rol)\n",
    "                # 线数目等于矩阵长度时，跳出\n",
    "                if line_count == len(b):\n",
    "                    break\n",
    "                # 判断是否画线覆盖所有0，若覆盖，进行加减操作\n",
    "                if 0 not in c:\n",
    "                    row_sub = list(set(row_and_col) - set(delete_count_of_row))\n",
    "                    min_value = np.min(c)\n",
    "                    for i in row_sub:\n",
    "                        b[i] = b[i] - min_value\n",
    "                    for i in delete_count_of_rol:\n",
    "                        b[:, i] = b[:, i] + min_value\n",
    "                    break\n",
    "        row_ind, col_ind = linear_sum_assignment(b)\n",
    "        min_cost = task_matrix[row_ind, col_ind].sum()\n",
    "        best_solution = list(task_matrix[row_ind, col_ind])\n",
    "        return  best_solution\n",
    "     #计算两点近距离公式 \n",
    "    def distEclud(self,veA,vecA,veB,vecB):\n",
    "        lossA=veB-veA\n",
    "        lossB=vecB-vecA\n",
    "        return math.sqrt(pow(lossA,2)+pow(lossB,2))\n",
    "#*\n",
    "#*\n",
    "#*      功能函数\n",
    "#*\n",
    "#*\n",
    "    def clear_id(self):\n",
    "        self.save={'000':{'center':[],'bbox':[],'lib':[],'frame':0,'passage':False}}\n",
    "        \n",
    "    def manage_lib(self,frame):\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k=='000':#or v['passage']==False:\n",
    "                continue\n",
    "            lib = v['lib']\n",
    "            frame_lib=v['frame']\n",
    "            if frame-frame_lib>self.Forget:\n",
    "                self.save[k]['frame']=frame\n",
    "                #self.save[k]['lib'].pop(0)\n",
    "                if len(lib)<10:\n",
    "                    self.dele_lib_id(k)\n",
    "                if  k not in self.save:\n",
    "                    continue\n",
    "                if self.save[k]['passage']==True:\n",
    "                    center =self.save[k]['lib'][0]\n",
    "                    for lib_ in self.save[k]['lib']:\n",
    "                        center=center*0.5+lib_*0.5\n",
    "                    #self.save[k]['lib'].pop(0)\n",
    "                    self.passage_off(k,center)\n",
    "                    #self.flag_frame=[]\n",
    "                    \n",
    "    def paassag_on(self,feature,bbox,frame,id_):\n",
    "        self.save[id_]['center']=feature\n",
    "        self.save[id_]['bbox']=bbox\n",
    "        self.save[id_]['lib'].append(feature)\n",
    "        self.save[id_]['frame']=frame\n",
    "        self.save[id_]['passage']=True\n",
    "        print('%s passage is True'%id_)\n",
    "        \n",
    "    def passage_off(self,id_,center):\n",
    "        self.save[id_]['center']=center\n",
    "        self.save[id_]['passage']=False\n",
    "        print('%s passage is False'%id_)\n",
    "        \n",
    "    def update_frame(self,id_,frame):\n",
    "        self.save[id_]['frame']=frame\n",
    "        \n",
    "    def dele_lib_id(self,id_):\n",
    "        del self.save[id_]\n",
    "        print('the id %s Remove'%id_)\n",
    "        \n",
    "    def add_lib(self,feature,bbox,frame,passage=False):\n",
    "        save={'center':[],'bbox':[],'lib':[],'frame':0,'passage':False}\n",
    "        for n in  self.save.keys():\n",
    "            id_=n\n",
    "        self.id_new=('%03d'%(int(id_)+1))\n",
    "        save['center']=feature\n",
    "        save['bbox']=bbox\n",
    "        save['lib']=[feature]\n",
    "        save['frame']=frame\n",
    "        save['passage']=passage\n",
    "        self.save[self.id_new]=save\n",
    "        print('find id %s'%self.id_new)\n",
    "        return self.id_new\n",
    "    \n",
    "    def add_id(self,feature,bbox,frame):   \n",
    "        #print(len(self.save))\n",
    "        if frame!=0 and len(self.save)!=1:\n",
    "            id_ = self.check_lib_passage(feature)\n",
    "            #self.id_new = self.check_lib(feature)\n",
    "            if id_ == ' ':\n",
    "                self.flag_line=[]\n",
    "                if self.id_new in self.save:\n",
    "                    if frame-self.save[self.id_new]['frame']>1:\n",
    "                        self.flag_frame=[]\n",
    "                else:\n",
    "                    self.flag_frame=[]\n",
    "                if len(self.flag_frame)==0:\n",
    "                    self.id_new = self.add_lib(feature,bbox,frame)\n",
    "                self.flag_frame.append(frame)\n",
    "                self.save[self.id_new]['frame']=frame\n",
    "                #self.update_frame\n",
    "                if len(self.flag_frame)>=5:\n",
    "                    if np.mean(self.flag_frame)==self.flag_frame[2]:\n",
    "                        self.paassag_on(feature,bbox,frame,self.id_new)\n",
    "                        self.flag_frame=[]\n",
    "                    else:\n",
    "                        self.dele_lib_id(self.id_new)\n",
    "                        self.flag_frame=[]\n",
    "            else:\n",
    "                #if frame - self.save[id_]['frame'] >3:\n",
    "                self.flag_frame=[]\n",
    "                self.flag_line.append(frame)\n",
    "                self.save[id_]['frame']=frame\n",
    "                #self.update_frame\n",
    "                if len(self.flag_line)>=3:\n",
    "                    if np.mean(self.flag_line)==self.flag_line[1]:\n",
    "                        self.paassag_on(feature,bbox,frame,id_)\n",
    "                        self.flag_line=[]\n",
    "                    else:\n",
    "                        self.flag_line=[]\n",
    "                return id_\n",
    "        else:\n",
    "            self.id_new = self.add_lib(feature,bbox,frame,passage=True)\n",
    "        return self.id_new\n",
    "#*\n",
    "#*      检测集合\n",
    "#*                        \n",
    "    def check_frame_id(self,id_,feature,frame):\n",
    "        list_dis=[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            if k==id_:\n",
    "                if frame-(v['frame'])>=10:\n",
    "                        if k==id_:\n",
    "                            for lib_ in v['lib']:\n",
    "                                list_dis.append(self.compute_cos(lib_,feature))\n",
    "                            if min(list_dis)<self.dth:\n",
    "                                return True\n",
    "                            else:\n",
    "                                return False\n",
    "                else:\n",
    "                    return True\n",
    "        return False\n",
    "    #检查除id_me外是否与数据库里的bbox重叠\n",
    "    def check_bboxs(self,bbox_list,bbox):    \n",
    "        (xc, yc, wc, hc) =bbox\n",
    "        list_id,list_x=[],[]\n",
    "        ret=True\n",
    "        if len(bbox_list)!=1:\n",
    "        #if (5<(xc-(wc*0.5)) and(xc+(wc*0.5))<(im_w-10)) or (5<(yc-(hc*0.5)) and (yc+(hc*0.5))<(im_h-10)):\n",
    "            for i in range(len(bbox_list)):\n",
    "                for j in range(i+1,len(bbox_list)):\n",
    "                    (xa, ya, wa, ha) = bbox_list[i]\n",
    "                    (xb, yb, wb, hb) = bbox_list[j] \n",
    "                    distance = self.distEclud(xa,ya,xb,yb)\n",
    "                    if (distance/(wa+wb))>=0.5:\n",
    "                        continue\n",
    "                    if (distance/(wa+wb))<0.5:\n",
    "                        if xc==xa or xc==xb:#是不是因为重叠导致的\n",
    "                            ret=False\n",
    "        return ret\n",
    "    def check_lib_add(self,featureVector,min_distance_id):\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if  k==min_distance_id:\n",
    "                n=v['center']\n",
    "                lib = v['lib']\n",
    "                for lib_ in lib:\n",
    "                    list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "                if len(self.save[min_distance_id]['lib'])>255:\n",
    "                    num = list_dis.index(min(list_dis))\n",
    "                    self.save[min_distance_id]['lib'].pop(num)\n",
    "                    #self.save[min_distance_id]['lib'].pop(0)\n",
    "                if len(list_dis)>0 and np.mean(list_dis)>self.dth:\n",
    "                    self.save[min_distance_id]['lib'].append(featureVector)\n",
    "                    print('\\r%s lib len :%d'%(min_distance_id,len(lib)),end='')\n",
    "                break\n",
    "        return len(lib)\n",
    "    #检查就绪的\n",
    "    def check_lib(self,featureVector):\n",
    "        list_id,list_mean=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if k=='000'or v['passage']==False :\n",
    "                continue\n",
    "            lib = v['lib']\n",
    "            for lib_ in lib:\n",
    "                list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "            list_id.append(k)\n",
    "            list_mean.append(min(list_dis)) \n",
    "        if len(list_mean)>0 and min(list_mean) <self.dth:\n",
    "            return list_id[list_mean.index(min(list_mean))] \n",
    "        else:\n",
    "            #print( min(list_mean))\n",
    "            return ' '   \n",
    "    #检查未就绪\n",
    "    def check_lib_passage(self,featureVector):\n",
    "        list_id,list_mean=[],[]\n",
    "        for k,v in list(self.save.items()):\n",
    "            list_dis=[]\n",
    "            if k!='000' and v['passage']==False and len(v['lib'])>10:\n",
    "                lib = v['lib']\n",
    "                for lib_ in lib:\n",
    "                    list_dis.append(self.compute_cos(lib_,featureVector))\n",
    "                list_id.append(k)\n",
    "                list_mean.append(min(list_dis)) \n",
    "        if len(list_mean)>0 and min(list_mean) <self.dth:\n",
    "            return list_id[list_mean.index(min(list_mean))] \n",
    "        else:\n",
    "            #print( min(list_mean))\n",
    "            return ' '    \n",
    "   \n",
    "    #def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "    def efficientdet_compute_pca(self,bbox_list,confidences,im):\n",
    "        #\n",
    "        # * self.notebook 记录发现新的图片的W\n",
    "        # * 保存数据的格式 self.save={'id':{'center':w,'LIB':[w1..wn]}}\n",
    "        #\n",
    "        color=[]\n",
    "        identities=[]\n",
    "        dths=[]\n",
    "        #维护LIB\n",
    "        self.manage_lib(self.frame)\n",
    "        list_id,list_feature,list_distance,list_n=[],[],[],[]\n",
    "        if bbox_list!=[]:\n",
    "            for bbox,c in zip(bbox_list,confidences):\n",
    "                (x, y, w, h) = bbox\n",
    "                (x1, y1, x2, y2)=int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)\n",
    "                (x,y,w,h)=(x1+x2)*0.5,(y1+y2)*0.5,abs(x1-x2),abs(y1-y2)\n",
    "                im_=im[y1:y2,x1:x2]\n",
    "                #im_ = self.fill_im(im_)\n",
    "                im_ = cv2.resize(im_,(64,128))\n",
    "                #第一帧的所有创建自己的组\n",
    "                if self.frame==0:\n",
    "                    featureVector = self.compute_feature(im_)\n",
    "                    id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                    identities.append(id_)\n",
    "                    continue\n",
    "                else: \n",
    "                    featureVector = self.compute_feature(im_)\n",
    "                    distance=0\n",
    "                #所有图片与LIB对比 判断是否是新的id 分别存储到不同的list\n",
    "                    list_distance_buffer,list_id_buffer,list_feature_buffer,list_n_buffer=[],[],[],[]\n",
    "                    for k,v in list(self.save.items()):\n",
    "                        if k=='000':\n",
    "                            continue\n",
    "                        n=v['center']\n",
    "                        if v['passage']==True:\n",
    "                            distance = self.compute_cos(n,featureVector)\n",
    "                            list_distance_buffer.append(distance)\n",
    "                            list_id_buffer.append(k)\n",
    "                            list_feature_buffer.append(featureVector)\n",
    "                            list_n_buffer.append(n)\n",
    "                    if len(list_distance_buffer)>0 and min(list_distance_buffer)<self.dth:\n",
    "                        list_distance.append(list_distance_buffer)\n",
    "                        list_id+=list_id_buffer\n",
    "                        list_feature+=list_feature_buffer\n",
    "                        list_n+=list_n_buffer\n",
    "                    else:\n",
    "                        #distance_ = min(list_distance_buffer)\n",
    "                        #检查与本帧的bbox是否重叠 和边缘是否重叠\n",
    "                        ret_bbox =self.check_bboxs(bbox_list,bbox)\n",
    "                        #ret_id =self.check_id(bbox_list,bbox,'#')\n",
    "                        ret_lib = self.check_lib(featureVector)\n",
    "                        if ret_bbox==True and ret_lib==' ':\n",
    "                                id_ = self.add_id(featureVector,bbox,self.frame)\n",
    "                                identities.append(id_)\n",
    "                                #dths.append(1-distance_)\n",
    "                                dths.append(c)\n",
    "                                color.append(0)\n",
    "                        else:\n",
    "                            color.append(0)\n",
    "                            dths.append(c)\n",
    "                            identities.append(ret_lib)  \n",
    "\n",
    "            if len(list_distance)>0 and len(bbox_list)>0:\n",
    "                list_center,list_min_n,list_identities=[],[],[]\n",
    "                np_distance=np.asarray(list_distance)\n",
    "                #print(np_distance)\n",
    "                #print(self.save.keys())\n",
    "                list_Hungary = self.computer_Hungary(np_distance)\n",
    "                #print(list_Hungary)\n",
    "                for number in list_Hungary:\n",
    "                    #number = number*0.00001\n",
    "                    min_distance = np_distance.flatten().tolist().index(number)\n",
    "                    list_identities.append(list_id[min_distance])\n",
    "                    list_center.append(list_feature[min_distance])\n",
    "                    list_min_n.append(list_n[min_distance])\n",
    "\n",
    "                #检查重新回来的id的frame\n",
    "                #ret_id_frame = self.check_frame_id(min_distance_id,min_distance_feature,self.frame)\n",
    "                for bbox,conter,min_n,id_,distance_ in zip(bbox_list,list_center,list_min_n,list_identities,list_Hungary):\n",
    "                     #检查除id_me外是否与数据库里的bbox重叠\n",
    "                    if distance_<self.dth:\n",
    "                        ret_bbox =self.check_bboxs(bbox_list,bbox)\n",
    "                        if ret_bbox==True :#and ret_id_frame==True:\n",
    "                            center_ = (conter*0.5)+(min_n*0.5)\n",
    "                            self.save[id_]['center'] =center_\n",
    "                            self.save[id_]['bbox'] =bbox\n",
    "                            self.save[id_]['frame'] =self.frame\n",
    "                            color_ = self.check_lib_add(conter,id_)\n",
    "                            color.append(color_)\n",
    "                            dths.append(1-distance_)\n",
    "                            identities.append(id_)\n",
    "                    \n",
    "        self.frame+=1\n",
    "        return identities,dths,color\n",
    "    #输入图片计算，输出Feature\n",
    "    def compute_feature(self,im):\n",
    "        im_ = im\n",
    "        size=im_.shape\n",
    "        im_ = np.float32(im_)/255.0\n",
    "        Fim = im_.flatten()\n",
    "        Fmean = self.mean.reshape(Fim.shape)\n",
    "        Fdf = Fim-Fmean\n",
    "        Fdf= Fdf.reshape(24576,1)\n",
    "        W=[]\n",
    "        for i in range(len(self.eigenVectors)):\n",
    "            E = self.eigenVectors[i,:].reshape(1,24576)\n",
    "            W.append(np.dot(E,Fdf).flatten())\n",
    "        W = np.asarray(W)\n",
    "        return W\n",
    "    #每一帧图片的ims\n",
    "    def compute_pca(self,ims):\n",
    "        self.classes=['A','B','C','D']\n",
    "        #num=0\n",
    "        #if  self.frame==0:\n",
    "        print('initfeature')\n",
    "        #self.flag==True\n",
    "        featureVector = self.compute_feature(ims[0])\n",
    "        self.testsave[self.classes[0]]=featureVector\n",
    "            #self.frame+=1  \n",
    "        for k,v in self.testsave.items():\n",
    "            list_,list_W,list_w0=[],[],[]\n",
    "            list_mashi1,list_mashi2=[],[]\n",
    "            n = np.asarray(v)\n",
    "            for im in ims:\n",
    "                #im=self.fill_im(im)\n",
    "                #im=cv2.resize(im,(64,128))\n",
    "                featureVector = self.compute_feature(im)\n",
    "                list_W.append(featureVector)\n",
    "                n_ = n.reshape((128,2))\n",
    "                feature_ = featureVector.reshape((128,2))\n",
    "                list_.append(self.compute_Maha(n_,feature_))\n",
    "                #self.frame+=1\n",
    "                n =np.asarray(featureVector)*0.5+n*0.5#根据三比七的比重进行调节\n",
    "                #self.testsave[self.classes[0]]=n\n",
    "                list_w0.append(n)\n",
    "        #print('\\r %d'%self.frame,end ='')\n",
    "        for W in list_W:\n",
    "            self.createNewFace(W,self.frame)\n",
    "            self.frame+=1\n",
    "        return list_ , list_W ,list_w0\n",
    "    def createNewFace(self,W,num):\n",
    "        # Start with the mean image\n",
    "        output = self.mean.reshape(64,128,3)\n",
    "        w=W.tolist()\n",
    "        # Add the eigen faces with the weights\n",
    "        for i in range(0, self.NUM_EIGEN_FACES):\n",
    "            '''\n",
    "            OpenCV does not allow slider values to be negative. \n",
    "            So we use weight = sliderValue - MAX_SLIDER_VALUE / 2\n",
    "            ''' \n",
    "            #sliderValues[i] = cv2.getTrackbarPos(\"Weight\" + str(i), \"Trackbars\");\n",
    "            weight = w[i]\n",
    "            e = self.eigenVectors[i].reshape(64,128,3)\n",
    "            output = np.add(output, e * weight)\n",
    "\n",
    "        # Display Result at 2x size\n",
    "        #output = cv2.resize(output, (0,0), fx=2, fy=2)\n",
    "        output=output*255.0\n",
    "        cv2.imshow(\"Result\", output)\n",
    "        name=('%06d.jpg'%num)\n",
    "        cv2.imwrite('./walkingworkspace/output/'+name,output)\n",
    "        cv2.waitKey(1)\n",
    "    def pca_class_dataset(self,im,name,output_path):\n",
    "        identities = os.path.basename(name)\n",
    "        self.frame+=1\n",
    "        #testimage = self.im_creat(testimage)\n",
    "        im_ = im\n",
    "        #sz = self.images[0].shape\n",
    "        size=im_.shape\n",
    "        im_ = np.float32(im_)/255.0\n",
    "        Fim = im_.flatten()\n",
    "        Fmean = self.mean.reshape(Fim.shape)\n",
    "        Fdf = Fim-Fmean\n",
    "        Fdf= Fdf.reshape(24576,1)\n",
    "        W=[]\n",
    "        for i in range(len(self.eigenVectors)):\n",
    "            E = self.eigenVectors[i,:].reshape(1,24576)\n",
    "            #print(self.eigenVectors[i,:].reshape(1,24576).T.shape)\n",
    "            W.append(np.dot(E,Fdf).flatten())\n",
    "        W = np.asarray(W)\n",
    "        #print(W)\n",
    "        #cv2.imshow('build',build[0:])\n",
    "        name = ('/%s'%identities)\n",
    "        name = name.replace('jpg','npy')\n",
    "        np.save(output_path+name,W)\n",
    "        #cv2.imwrite(name+'.jpg',im)\n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efficientdet + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from ./walkingworkspace/train2020...1982 files read.\n"
     ]
    }
   ],
   "source": [
    "HumanMaxNumber=2\n",
    "size=(640,480)\n",
    "E = efficientdet(0 ,640,HumanMaxNumber,dir_path='./walkingworkspace/train2020',NUM_EIGEN_FACES = 256)\n",
    "#E = efficientdet(0 ,512,HumanMaxNumber,dir_path='./datasets/multi-query',NUM_EIGEN_FACES = 256)\n",
    "#从新构建models\n",
    "#E.init_PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2608.0\n",
      "find id 001\n",
      "001 lib len :15"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-503ed98791f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mnum\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6a38d8e5f574>\u001b[0m in \u001b[0;36mdetector\u001b[1;34m(self, im)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_float16\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[0mregressBoxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBBoxTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mclipBoxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClipBoxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\CrossvideoREID\\Myreid_EfficientDet\\backbone.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mregression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mclassification\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\CrossvideoREID\\Myreid_EfficientDet\\efficientdet\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\CrossvideoREID\\Myreid_EfficientDet\\efficientdet\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepthwise_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointwise_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\CrossvideoREID\\Myreid_EfficientDet\\efficientnet\\utils_extra.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 346\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "E.init_video()\n",
    "#videopath='./testvideo/liandxia.mp4'\n",
    "#videopath='./testvideo/two_rotation.mp4'\n",
    "videopath='./testvideo/test004.mp4'\n",
    "#videopath='./walkingvideo/two_rotationwalking.mp4'\n",
    "#videopath=0\n",
    "video = cv2.VideoCapture(videopath)\n",
    "video_fps = video.get(7)\n",
    "print(video_fps)\n",
    "num=0\n",
    "for i in range(int(video_fps-1)):\n",
    "#t=time.time()\n",
    "\n",
    "#while True:\n",
    "#    if (time.time()-t)>=5:\n",
    "#        if (time.time()-t)>=300:\n",
    "#            break \n",
    "        ret,im = video.read()\n",
    "        #im_=cv2.flip(im,0)\n",
    "        if ret:\n",
    "            if num%1==0:\n",
    "                E.detector(cv2.resize(im,size))\n",
    "        num+=1\n",
    "cv2.destroyAllWindows() \n",
    "E.out.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from ./walkingworkspace/train2020...1893 files read.\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(dir_path='./walkingworkspace/train2020',NUM_EIGEN_FACES = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2608.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "efficientdet_compute_pca() missing 1 required positional argument: 'im'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-5e3a7298c3e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0midentities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefficientdet_compute_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midentities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#cv2.waitKey(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: efficientdet_compute_pca() missing 1 required positional argument: 'im'"
     ]
    }
   ],
   "source": [
    "def display(bbox_list,identities,dths,im_):\n",
    "        #print(len(out_list))\n",
    "        for bbox,id_,dth in zip(bbox_list,identities,dths):\n",
    "            (x1, y1, x2, y2) =bbox\n",
    "            (x1, y1, x2, y2)=(int(x1), int(y1), int(x2), int(y2))\n",
    "            cv2.rectangle(im_, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "            #cv2.putText(im, ('%.2f'%c), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 250,0), 1)\n",
    "            cv2.putText(im_, ('%.2f'%dth), (x2+10, y1+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 250,0), 1)\n",
    "            cv2.putText(im_, ('%s'%id_), (x1, y1+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255,0), 1)\n",
    "        #fps = 1/(time.time()-t)\n",
    "        #cv2.putText(im, ('%.2f'%fps), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.imshow('efficientdet', im_)\n",
    "        cv2.waitKey(1)\n",
    "a = np.load('./yolov3_bboxs.npz',allow_pickle=True)['bboxes'].item()\n",
    "list_bboxs=[]\n",
    "for k in a.keys():\n",
    "    list_bboxs.append((a[k]))\n",
    "videopath='./testvideo/test004.mp4'\n",
    "video = cv2.VideoCapture(videopath)\n",
    "video_fps = video.get(7)\n",
    "print(video_fps)\n",
    "num=0\n",
    "for i in range(int(video_fps-1)):\n",
    "    #t=time.time()\n",
    "    ret,im_ = video.read()\n",
    "    bboxs=list_bboxs[i]\n",
    "    if len(bboxs) ==0:\n",
    "        continue\n",
    "    #    *0.9\n",
    "    #print(bboxs[:,0:4])\n",
    "    if ret:\n",
    "        if num%1==0:\n",
    "            identities,dths = pca.efficientdet_compute_pca(bboxs[:,0:4],im_)\n",
    "            display(bboxs[:,0:4],identities,dths,im_)\n",
    "    #cv2.waitKey(1)\n",
    "    num+=1\n",
    "cv2.destroyAllWindows() \n",
    "video.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA test an dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from ./walkingworkspace/train_all...1526 files read.\n"
     ]
    }
   ],
   "source": [
    "#HumanMaxNumber=2\n",
    "#size=(512,384)\n",
    "#E = efficientdet(0 ,512,HumanMaxNumber)\n",
    "#ids_bboxes = {}\n",
    "pca=PCA(dir_path='./walkingworkspace/train_all',NUM_EIGEN_FACES = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "initfeature\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-34fbca0eda48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m#if im_name.find('D')!=-1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m#list_im4.append(im)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mdistance1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwcenter1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_im1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;31m#pca=PCA(dir_path='./test_colors/train',basepath = './test_colors/source',NUM_EIGEN_FACES = 64)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#distance2,w2,wcenter2= pca.compute_pca(list_im2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-439b9f0db127>\u001b[0m in \u001b[0;36mcompute_pca\u001b[1;34m(self, ims)\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[0mn_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[0mfeature_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureVector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                 \u001b[0mlist_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_Maha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m                 \u001b[1;31m#self.frame+=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;31m#根据三比七的比重进行调节\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-439b9f0db127>\u001b[0m in \u001b[0;36mcompute_Maha\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mXT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#两个维度之间协方差矩阵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mSI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#协方差矩阵的逆矩阵\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;31m#马氏距离计算两个样本之间的距离，此处共有10个样本，两两组合，共有45个距离。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "#E.threadStart()\n",
    "#videopath='./testvideo/mc1.mp4'\n",
    "im_path='./walkingworkspace/action/'\n",
    "list_im=[]\n",
    "for path_name in glob.glob(im_path+'*'):\n",
    "    path_name = path_name.replace('\\\\','/')\n",
    "    for im_name in glob.glob(path_name+'/*.jpg'):\n",
    "        list_im.append(im_name.replace('\\\\','/'))\n",
    "#print(len(list_im))\n",
    "#output_path='./miniclassify/train_max'\n",
    "#video = cv2.VideoCapture(videopath)\n",
    "#video_fps = video.get(7)\n",
    "#print(video_fps)\n",
    "list_W=[]\n",
    "#set_A_x,set_B_x,set_O_x,set_C_x,set_A_y,set_B_y,set_O_y,set_C_y,set_A_z,set_B_z,set_O_z,set_C_z,set_E_x,set_E_y,set_E_z=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "list_=[]\n",
    "#for im_name in list_im:\n",
    "    #print(im_name)\n",
    "#    im = cv2.imread(im_name)\n",
    "    #data = pca.compute_pca(im)\n",
    "    #print(data)\n",
    "    #for i in data:\n",
    "#    if im_name.find('O')!=-1:\n",
    "        #im = cv2.imread(im_name)\n",
    "#    list_.append(im)\n",
    "#pca.add_id(list_)\n",
    "print(len(list_im))\n",
    "list_im1,list_im2,list_im3,list_im4=[],[],[],[]\n",
    "for im_name in list_im:  \n",
    "    #print(im_name)\n",
    "    im = cv2.imread(im_name)\n",
    "    im=cv2.resize(im,(64,128))\n",
    "    #if im_name.find('A')!=-1: \n",
    "    list_im1.append(im)\n",
    "    #if im_name.find('B')!=-1:\n",
    "    #    list_im2.append(im)\n",
    "    #if im_name.find('C')!=-1:\n",
    "        #list_im3.append(im)\n",
    "    #if im_name.find('D')!=-1:\n",
    "        #list_im4.append(im)\n",
    "distance1,w1,wcenter1= pca.compute_pca(list_im1)\n",
    "#pca=PCA(dir_path='./test_colors/train',basepath = './test_colors/source',NUM_EIGEN_FACES = 64)\n",
    "#distance2,w2,wcenter2= pca.compute_pca(list_im2)\n",
    "#data3= pca.compute_pca(list_im3)\n",
    "#data4= pca.compute_pca(list_im4)\n",
    "print(distance1)\n",
    "#print(len(distance2))\n",
    "#print(data2)\n",
    "#    X,Y,Z=data\n",
    "'''if im_name.find('A')!=-1:\n",
    "    set_A_x.append(X)\n",
    "    set_A_y.append(Y)\n",
    "    set_A_z.append(Z)\n",
    "if im_name.find('B')!=-1:\n",
    "    set_B_x.append(X)\n",
    "    set_B_y.append(Y)\n",
    "    set_B_z.append(Z)'''\n",
    "'''if im_name.find('O')!=-1:\n",
    "    set_O_x.append(X)\n",
    "    set_O_y.append(Y)\n",
    "    set_O_z.append(Z)\n",
    "if im_name.find('C')!=-1:\n",
    "    set_C_x.append(X)\n",
    "    set_C_y.append(Y)\n",
    "    set_C_z.append(Z)\n",
    "if im_name.find('E')!=-1:\n",
    "    set_E_x.append(X)\n",
    "    set_E_y.append(Y)\n",
    "    set_E_z.append(Z)  ''' \n",
    "#    list_W.append(W)\n",
    "    #pca.pca_class_dataset(im,im_name,output_path)\n",
    "#pca.test_meandyou()\n",
    "cv2.destroyAllWindows() \n",
    "#print(len(set_A_x),len(set_A_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-8cc890afe097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#data2.remove(max(data2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#data2.remove(min(data2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmax_jiawei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmax_xiaobo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_jiawei\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_xiaobo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#data1.remove(max(data1))\n",
    "#data1.remove(min(data1))\n",
    "#data2.remove(max(data2))\n",
    "#data2.remove(min(data2))\n",
    "max_jiawei = max(data1)\n",
    "max_xiaobo = max(data2)\n",
    "print(max_jiawei,max_xiaobo)\n",
    "max_jiawei,max_xiaobo = float(max_jiawei),float(max_xiaobo)\n",
    "print((max_jiawei+max_xiaobo)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-0ab0c52b533c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mx4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m plt.plot(x1,distance1,label='A',linewidth=3,color='r',marker='o',\n\u001b[1;32m---> 10\u001b[1;33m markerfacecolor='r',markersize=12)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#plt.plot(x2,distance2,label='B',linewidth=3,color='r',marker='o',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2761\u001b[0m     return gca().plot(\n\u001b[0;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[1;32m-> 2763\u001b[1;33m         is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m         \"\"\"\n\u001b[0;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \"non-matching shapes is deprecated.\")\n\u001b[0;32m    363\u001b[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[1;32m--> 364\u001b[1;33m                 for j in range(max(ncx, ncy))]\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\miniconda3\\envs\\reid\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \"non-matching shapes is deprecated.\")\n\u001b[0;32m    363\u001b[0m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[1;32m--> 364\u001b[1;33m                 for j in range(max(ncx, ncy))]\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('I am distance')\n",
    "plt.xlabel('I am id')\n",
    "#plt.legend([L1,L2],['A','B'],loc='upper right')\n",
    "x1=range(0,len(distance1))\n",
    "#x2=range(0,len(distance2))\n",
    "x3=range(0,50)\n",
    "x4=range(0,50)\n",
    "plt.plot(x1,distance1,label='A',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='r',markersize=12)\n",
    "plt.show()\n",
    "#plt.plot(x2,distance2,label='B',linewidth=3,color='r',marker='o',\n",
    "#markerfacecolor='g',markersize=12)\n",
    "#plt.show()\n",
    "#plt.plot(x1,data3,label='C',linewidth=3,color='r',marker='o',\n",
    "#markerfacecolor='b',markersize=12)\n",
    "#plt.plot(x2,data4,label='D',linewidth=3,color='r',marker='o',\n",
    "#markerfacecolor='y',markersize=12)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语义分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "self.net = fcn_resnet101(pretrained=True,progress=False).cuda()\n",
    "_ = self.net.eval()\n",
    "def fcn_mask(self,im):\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    input_batch = torch.tensor(im,dtype=torch.float32).cuda()\n",
    "    input_batch = input_batch.permute(2,0,1)\n",
    "    input_batch = 2*input_batch/255.0-1.0\n",
    "    input_batch = input_batch.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = net(input_batch)['out'][0]\n",
    "    output_predictions = output.argmax(0).cpu()\n",
    "    output_predictions = np.where(output_predictions[:]==15,1,0)\n",
    "    return output_predictions\n",
    "\n",
    "def create_mask(self,im_bbox):\n",
    "    im_fcn = self.fcn_mask(im_bbox)\n",
    "    re = np.zeros(im_bbox.shape)*255\n",
    "    #im_fcn_=np.zeros((im_fcn.shape[0],im_fcn.shape[1],3))\n",
    "    re[:,:,0]=re[:,:,1]=re[:,:,2]=im_fcn\n",
    "    #re = np.where(re.all()!=[0,0,0], [0,0,0], [255,255,255])\n",
    "    re = re*im_bbox\n",
    "    re = re.astype(np.uint8)\n",
    "    cv2.imshow('mask',re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.figure()\n",
    "plt = fig.gca(projection='3d')\n",
    "plt.plot(set_A_x,set_A_y,set_A_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='w',markersize=12)\n",
    "plt.plot(set_B_x,set_B_y,set_B_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='b',markersize=12)\n",
    "plt.plot(set_O_x,set_O_y,set_O_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='g',markersize=12)\n",
    "plt.plot(set_C_x,set_C_y,set_C_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='y',markersize=12)\n",
    "plt.plot(set_C_x,set_C_y,set_C_z,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='y',markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,ConcatDataset\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0,1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    def __init__(self, fpath_peoject=[]):\n",
    "        \n",
    "        self.labels,self.images = [],[]\n",
    "        for i in fpath_peoject:\n",
    "            j = i[1]\n",
    "            np_im = np.load(i[0])\n",
    "            self.labels.append(j)\n",
    "            np_im = np_im.flatten()\n",
    "            #print(np_im.shape)\n",
    "            self.images.append(np_im)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.images[idx],self.labels[idx])\n",
    "classes=['A','B']\n",
    "def get_data(path):\n",
    "    list_train,list_val=[],[]\n",
    "    for name in glob.glob(path+'/*.npy'):\n",
    "        name_=name.replace('\\\\','/')\n",
    "        if name_.find('A')!=-1:\n",
    "            list_train.append([name_,0])\n",
    "        if name_.find('B')!=-1:\n",
    "            list_train.append([name_,1])\n",
    "    return list_train\n",
    "train = get_data('./miniclassify/train_max')  \n",
    "test = get_data('./miniclassify/test_max') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mytraindataset = DataLoader(train)\n",
    "mytestataset = DataLoader(test)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainloader = torch.utils.data.DataLoader(mytraindataset, batch_size=6,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(mytestataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(100,1000)\n",
    "        self.fc3 = nn.Linear(1000,2)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.99))\n",
    "PATH='./pytorchmodel/my_max.pth'\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device),data[1].to(device)\n",
    "        #print(inputs,labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 6 == 0:    # print every 2000 mini-batches\n",
    "            print('\\r [%d, %5d] loss: %.4f' %\n",
    "                  (epoch + 1, i + 1, running_loss/100),end=' ')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images=images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.cpu() == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)),cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images,lables= dataiter.next()\n",
    "print(type(images))\n",
    "images,lables=images.to(device),lables.to(device)\n",
    "print(images.shape)\n",
    "outputs = net(images)\n",
    "print(images.shape)\n",
    "_, predicted = torch.max(outputs,1)\n",
    "print(predicted)\n",
    "imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "print('Predicted: ', ' '.join('%11s' % classes[predicted[j]]\n",
    "                              for j in range(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='./pytorchmodel/my_max.pth'\n",
    "mynet = torch.load(PATH)\n",
    "print(mynet['fc1.weight'].shape)\n",
    "print(mynet['fc3.weight'].shape)\n",
    "#print(mynet)\n",
    "#print(type(mynet))\n",
    "W = mynet['fc1.weight']\n",
    "W_weight=[]\n",
    "for i in range(0,100):\n",
    "    #print(W[:,i].shape)\n",
    "    W_weight.append(np.mean(abs(W[:,i]).cpu().numpy()))\n",
    "print(W_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1=range(0,100)\n",
    "plt.plot(x1,W_weight,label='Frist line',linewidth=3,color='r',marker='o',\n",
    "markerfacecolor='blue',markersize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Number of EigenFaces\n",
    "NUM_EIGEN_FACES = 10\n",
    "\n",
    "# Maximum weight\n",
    "MAX_SLIDER_VALUE = 10\n",
    "\n",
    "# Directory containing images\n",
    "dirName = \"./pytorchdata/test\"\n",
    "\n",
    "# Read images\n",
    "images=[]\n",
    "for name in glob.glob(dirName+'/*.jpg'):\n",
    "    #print(name)\n",
    "    images.append(cv2.resize(cv2.imread(name.replace('\\\\','/')),(64,128)))\n",
    "    cv2.imshow('0-0',cv2.imread(name.replace('\\\\','/')))\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Size of images\n",
    "sz = images[0].shape\n",
    "\n",
    "# Create data matrix for PCA.\n",
    "data = createDataMatrix(images)\n",
    "\n",
    "# Compute the eigenvectors from the stack of images created\n",
    "print(\"Calculating PCA \", end=\"...\")\n",
    "mean, eigenVectors = cv2.PCACompute(data, mean=None, maxComponents=NUM_EIGEN_FACES)\n",
    "print(mean.shape, eigenVectors.shape)\n",
    "print (\"DONE\")\n",
    "\n",
    "averageFace = mean.reshape(sz)\n",
    "print(averageFace.shape)\n",
    "cv2.imshow('averageFace',averageFace)\n",
    "eigenFaces = []; \n",
    "\n",
    "for eigenVector in eigenVectors:\n",
    "    eigenFace = eigenVector.reshape(sz)\n",
    "    eigenFaces.append(eigenFace)\n",
    "\n",
    "# Create window for displaying Mean Face\n",
    "cv2.namedWindow(\"Result\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Display result at 2x size\n",
    "output = cv2.resize(averageFace, (0,0), fx=2, fy=2)\n",
    "cv2.imshow(\"Result\", output)\n",
    "\n",
    "# Create Window for trackbars\n",
    "cv2.namedWindow(\"Trackbars\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "sliderValues = []\n",
    "\n",
    "# Create Trackbars\n",
    "for i in range(0, NUM_EIGEN_FACES):\n",
    "    sliderValues.append(MAX_SLIDER_VALUE/2)\n",
    "    cv2.createTrackbar( \"Weight\" + str(i), \"Trackbars\", int(MAX_SLIDER_VALUE), MAX_SLIDER_VALUE, createNewFace)\n",
    "\n",
    "# You can reset the sliders by clicking on the mean image.\n",
    "cv2.setMouseCallback(\"Result\", createNewFace);\n",
    "\n",
    "print('''Usage:\n",
    "Change the weights using the sliders\n",
    "Click on the result window to reset sliders\n",
    "Hit ESC to terminate program.''')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
